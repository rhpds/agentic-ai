{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# getting started\n",
    "\n",
    "I miss Marshall in this module will simply do some basic configuration of our Python virtual environment from now on referred to as our Vivy. We will start our.\n",
    "\n",
    "Steps\n",
    "\n",
    "* populate the Benny with dependences\n",
    "* start the LLM\n",
    "* run a simple inference i.e. a request to the large language model\n",
    "* \n",
    "\n",
    "\n",
    "\n",
    "### Resources\n",
    "\n",
    "Based on Module 2 of the Deep Learning course below (LangGraph)\n",
    "\n",
    "* [A simple Python implementation of the ReAct pattern for LLMs](https://arc.net/l/quote/duflzttq)\n",
    "  * Simon Willison Blog Article\n",
    "* [Deep Learning AI Course, AI Agents with LangGraph](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/1/introduction)\n",
    "\n",
    "Credits to examples here:\n",
    "* [OpenAI Documents](https://platform.openai.com/docs/overview)\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "* Pythons setup (I created a 3.11 venv)\n",
    "* OpenAI Key (Granite struggled but perhaps not a fair comparions ollama/grantite q4 8b v `gpt-4o`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c2522-09ff-439f-83c7-d752b6bbe7e7",
   "metadata": {},
   "source": [
    "Let's verify our environment - in a jupyer lab code cell preceding a command with `!` executes it eg `!pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7698fc46-06b6-476b-8b88-46b97241b854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dev/lab\n",
      "python is /home/dev/venv/bin/python\n",
      "Python 3.12.5\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!type python\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a0130-f86d-4ff1-8250-01850c957905",
   "metadata": {},
   "source": [
    "You should see that you are actually running this notebook from inside the venv which is a common \n",
    "practice and hear we can add dependencies etc and experiment safely with no consequesnced of interfering with our default Sustyem Python\n",
    "\n",
    "NOTE: Whilst python venvs are used extensively in development in Production we would effectively \"bake\" these into stronly versioned containers and run on OpenShift via GitOps - typically via helm charts and ArgoCD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b600f-406f-4ee6-acdb-ecf620c11e71",
   "metadata": {},
   "source": [
    "Next let's add the Python libraries we will need to get started.\n",
    "It is a good practice to isolate these in a `requirements.txt` along with their versions eg\n",
    "\n",
    "```\n",
    "head -5 requirements.txt\n",
    "annotated-types==0.7.0\n",
    "anyio==4.9.0\n",
    "appnope==0.1.4\n",
    "argon2-cffi==23.1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b19562-d870-4176-b5ae-2747129036df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types==0.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: async-lru==2.0.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: attrs==25.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: babel==2.17.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 10)) (4.13.4)\n",
      "Requirement already satisfied: bleach==6.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 11)) (6.2.0)\n",
      "Requirement already satisfied: certifi==2025.4.26 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 12)) (2025.4.26)\n",
      "Requirement already satisfied: cffi==1.17.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 13)) (1.17.1)\n",
      "Collecting charset-normalizer==3.4.1 (from -r requirements.txt (line 14))\n",
      "  Obtaining dependency information for charset-normalizer==3.4.1 from https://files.pythonhosted.org/packages/3e/a2/513f6cbe752421f16d969e32f3583762bfd583848b763913ddab8d9bfd4f/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting click==8.1.8 (from -r requirements.txt (line 15))\n",
      "  Obtaining dependency information for click==8.1.8 from https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 16)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.14 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 17)) (1.8.14)\n",
      "Requirement already satisfied: decorator==5.2.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 18)) (5.2.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 19)) (0.7.1)\n",
      "Requirement already satisfied: distro==1.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 20)) (1.9.0)\n",
      "Requirement already satisfied: executing==2.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 21)) (2.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 22)) (2.21.1)\n",
      "Requirement already satisfied: fqdn==1.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 23)) (1.5.1)\n",
      "Requirement already satisfied: h11==0.16.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 24)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 25)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 26)) (0.28.1)\n",
      "Requirement already satisfied: idna==3.10 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 27)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 28)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 29)) (9.2.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 30)) (1.1.1)\n",
      "Collecting ipywidgets==8.1.6 (from -r requirements.txt (line 31))\n",
      "  Obtaining dependency information for ipywidgets==8.1.6 from https://files.pythonhosted.org/packages/53/b8/62952729573d983d9433faacf62a52ee2e8cf46504418061ad1739967abe/ipywidgets-8.1.6-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: isoduration==20.11.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 32)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 34)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 35)) (0.9.0)\n",
      "Requirement already satisfied: json5==0.12.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 36)) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 37)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 38)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 39)) (2025.4.1)\n",
      "Requirement already satisfied: jupyter==1.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 40)) (1.1.1)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 41)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 42)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 43)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 44)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 45)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 46)) (2.15.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 47)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 48)) (4.4.1)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 49)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 50)) (2.27.3)\n",
      "Collecting jupyterlab_widgets==3.0.14 (from -r requirements.txt (line 51))\n",
      "  Obtaining dependency information for jupyterlab_widgets==3.0.14 from https://files.pythonhosted.org/packages/64/7a/f2479ba401e02f7fcbd3fc6af201eac888eaa188574b8e9df19452ab4972/jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting llama_stack_client==0.2.4 (from -r requirements.txt (line 52))\n",
      "  Obtaining dependency information for llama_stack_client==0.2.4 from https://files.pythonhosted.org/packages/14/85/9f8bf39a9201be82d32e1cdb03629b552bcc94bb3348e0f154c0e20a2c43/llama_stack_client-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_stack_client-0.2.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 53)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 54)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 55)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 56)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.1.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 57)) (3.1.3)\n",
      "Requirement already satisfied: nbclient==0.10.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 58)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 59)) (7.16.6)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 60)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 61)) (1.6.0)\n",
      "Requirement already satisfied: notebook==7.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 62)) (7.4.1)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 63)) (0.2.4)\n",
      "Collecting numpy==2.2.5 (from -r requirements.txt (line 64))\n",
      "  Obtaining dependency information for numpy==2.2.5 from https://files.pythonhosted.org/packages/b0/d9/7c338b923c53d431bc837b5b787052fef9ae68a56fe91e325aac0d48226e/numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai==1.76.2 (from -r requirements.txt (line 65))\n",
      "  Obtaining dependency information for openai==1.76.2 from https://files.pythonhosted.org/packages/00/5f/aecb820917e93ca9fcac408e998dc22ee0561c308ed58dc8f328e3f7ef14/openai-1.76.2-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.76.2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: overrides==7.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 66)) (7.7.0)\n",
      "Requirement already satisfied: packaging==25.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 67)) (25.0)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 68))\n",
      "  Obtaining dependency information for pandas==2.2.3 from https://files.pythonhosted.org/packages/38/f8/d8fddee9ed0d0c0f4a2132c1dfcf0e3e53265055da8df952a53e7eaf178c/pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandocfilters==1.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 69)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 70)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 71)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 72)) (4.3.7)\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 73)) (0.21.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 74)) (3.0.51)\n",
      "Requirement already satisfied: psutil==7.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 75)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 76)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 77)) (0.2.3)\n",
      "Collecting pyaml==25.1.0 (from -r requirements.txt (line 78))\n",
      "  Obtaining dependency information for pyaml==25.1.0 from https://files.pythonhosted.org/packages/69/c1/ec1930bc6c01754b8baf3c99420f340b920561f0060bccbf81809db354cc/pyaml-25.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pycparser==2.22 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 79)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 80)) (2.11.4)\n",
      "Requirement already satisfied: pydantic_core==2.33.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 81)) (2.33.2)\n",
      "Requirement already satisfied: Pygments==2.19.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 82)) (2.19.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 83)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==3.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 84)) (3.3.0)\n",
      "Collecting pytz==2025.2 (from -r requirements.txt (line 85))\n",
      "  Obtaining dependency information for pytz==2025.2 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 86)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 87)) (26.4.0)\n",
      "Requirement already satisfied: referencing==0.36.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 88)) (0.36.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 89)) (2.32.3)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 90)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 91)) (0.1.1)\n",
      "Requirement already satisfied: rich==14.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 92)) (14.0.0)\n",
      "Requirement already satisfied: rpds-py==0.24.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 93)) (0.24.0)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 94)) (1.8.3)\n",
      "Collecting setuptools==80.0.0 (from -r requirements.txt (line 95))\n",
      "  Obtaining dependency information for setuptools==80.0.0 from https://files.pythonhosted.org/packages/23/63/5517029d6696ddf2bd378d46f63f479be001c31b462303170a1da57650cb/setuptools-80.0.0-py3-none-any.whl.metadata\n",
      "  Downloading setuptools-80.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six==1.17.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 96)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 97)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 98)) (2.7)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 99)) (0.6.3)\n",
      "Collecting termcolor==3.1.0 (from -r requirements.txt (line 100))\n",
      "  Obtaining dependency information for termcolor==3.1.0 from https://files.pythonhosted.org/packages/4f/bd/de8d508070629b6d84a30d01d57e4a65c69aa7f5abe7560b8fad3b50ea59/termcolor-3.1.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: terminado==0.18.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 101)) (0.18.1)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 102)) (1.4.0)\n",
      "Requirement already satisfied: tornado==6.4.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 103)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 104)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 105)) (5.14.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 106)) (2.9.0.20241206)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 107)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 108)) (4.13.2)\n",
      "Collecting tzdata==2025.2 (from -r requirements.txt (line 109))\n",
      "  Obtaining dependency information for tzdata==2025.2 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: uri-template==1.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 110)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 111)) (2.4.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 112)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.11.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 113)) (24.11.1)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 114)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 115)) (1.8.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.14 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 116)) (4.0.14)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.3/145.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.0/214.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_stack_client-0.2.4-py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.7/292.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.76.2-py3-none-any.whl (661 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m146.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.0.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, termcolor, setuptools, pyaml, numpy, jupyterlab_widgets, click, charset-normalizer, pandas, openai, llama_stack_client, ipywidgets\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 80.3.1\n",
      "    Uninstalling setuptools-80.3.1:\n",
      "      Successfully uninstalled setuptools-80.3.1\n",
      "  Attempting uninstall: jupyterlab_widgets\n",
      "    Found existing installation: jupyterlab_widgets 3.0.15\n",
      "    Uninstalling jupyterlab_widgets-3.0.15:\n",
      "      Successfully uninstalled jupyterlab_widgets-3.0.15\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.2\n",
      "    Uninstalling charset-normalizer-3.4.2:\n",
      "      Successfully uninstalled charset-normalizer-3.4.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.77.0\n",
      "    Uninstalling openai-1.77.0:\n",
      "      Successfully uninstalled openai-1.77.0\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.7\n",
      "    Uninstalling ipywidgets-8.1.7:\n",
      "      Successfully uninstalled ipywidgets-8.1.7\n",
      "Successfully installed charset-normalizer-3.4.1 click-8.1.8 ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 llama_stack_client-0.2.4 numpy-2.2.5 openai-1.76.2 pandas-2.2.3 pyaml-25.1.0 pytz-2025.2 setuptools-80.0.0 termcolor-3.1.0 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a049faf1-8a5c-4b36-a85c-7f7627635c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201a5506-5b38-4fcb-a0c6-45e67a8ed5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = \"placeholder\"  # Can't be empty - otherwise will show an error In the interests of simplicity we will NOT use an api_key, in production on OpenShift AI etc there may be per user based keys\n",
    "# model = \"llama3.2:3b-instruct-fp16\"\n",
    "model = \"qwen3:32b\"\n",
    "base_url = \"http://localhost:11434/v1/\" #openai/v1/\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ad31f7-0caf-4925-a380-43d2e145abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to write a simple Python class called User. Let me think about what a User class might typically include. Well, a user usually has some basic attributes like a name, age, maybe an email. So I'll start by defining the __init__ method to initialize those attributes.\n",
      "\n",
      "Wait, should I make all of them required? Maybe name is required, but age and email could be optional. Hmm, but for simplicity since the user asked for a simple example, maybe just include name and age. Or maybe include email as well. Let me decide to include name, age, and email. Then, perhaps include some methods. Maybe a method to display the user's information.\n",
      "\n",
      "So the class would have __init__ that takes name, age, and email. Then a method like display_info that prints out those details. Let me think about the syntax. The class is called User, so:\n",
      "\n",
      "class User:\n",
      "    def __init__(self, name, age, email):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "        self.email = email\n",
      "\n",
      "    def display_info(self):\n",
      "        print(f\"Name: {self.name}, Age: {self.age}, Email: {self.email}\")\n",
      "\n",
      "Then, maybe create an instance of the User class. For example:\n",
      "\n",
      "user1 = User(\"Alice\", 30, \"alice@example.com\")\n",
      "user1.display_info()\n",
      "\n",
      "But wait, maybe the user wants the example to include some comments or additional methods. Or perhaps include type hints? But since it's a simple example, maybe keep it straightforward without type hints.\n",
      "\n",
      "Wait, the user didn't specify any particular features, just a simple example. So this should suffice. Let me check if there's anything else. Maybe include a default value for age? But if I do that, the parameters need to be ordered properly. Like if age is optional, then parameters after it would need to be keyword-only. But maybe all parameters are required for the example.\n",
      "\n",
      "Yes, that's fine. Let me go ahead and write the code with those three attributes and the display method. Maybe add a docstring to the class for clarity.\n",
      "\n",
      "So the class would be:\n",
      "\n",
      "class User:\n",
      "    \"\"\"A simple class representing a user with name, age, and email.\"\"\"\n",
      "    \n",
      "    def __init__(self, name, age, email):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "        self.email = email\n",
      "\n",
      "    def display_info(self):\n",
      "        \"\"\"Prints the user's information.\"\"\"\n",
      "        print(f\"Name: {self.name}, Age: {self.age}, Email: {self.email}\")\n",
      "\n",
      "Then, an example usage.\n",
      "\n",
      "I think that's good. Let me test this in my mind. Creating an instance with the example data and calling display_info would print the expected string. Yeah, this should work.\n",
      "</think>\n",
      "\n",
      "Here's a simple example of a `User` class in Python with basic attributes and a method to display information:\n",
      "\n",
      "```python\n",
      "class User:\n",
      "    \"\"\"A simple class representing a user with name, age, and email.\"\"\"\n",
      "    \n",
      "    def __init__(self, name, age, email):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "        self.email = email\n",
      "\n",
      "    def display_info(self):\n",
      "        \"\"\"Prints the user's information.\"\"\"\n",
      "        print(f\"Name: {self.name}, Age: {self.age}, Email: {self.email}\")\n",
      "\n",
      "\n",
      "# Example usage\n",
      "user1 = User(\"Alice\", 30, \"alice@example.com\")\n",
      "user1.display_info()\n",
      "```\n",
      "\n",
      "### Output:\n",
      "```\n",
      "Name: Alice, Age: 30, Email: alice@example.com\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **`__init__` method**: Initializes the user with `name`, `age`, and `email`.\n",
      "- **`display_info` method**: A method that prints the user's information.\n",
      "- The class is intentionally kept simple and includes a docstring for clarity.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful Python programming assistant .\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a simple Python example class called User\"}\n",
    "    ]\n",
    ")\n",
    "print(f\"{response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127c382-7143-41da-8723-898f392e5db1",
   "metadata": {},
   "source": [
    "# Chain of Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7476f-a86b-4f20-ae24-cf070b2493ec",
   "metadata": {},
   "source": [
    "A Chain of Thought (CoT) prompt is a prompting technique used with large language models (LLMs) where you explicitly guide the model to reason step-by-step before arriving at the final answer.\n",
    "\n",
    "Instead of asking the model to directly give you an answer, a CoT prompt encourages it to \"think aloud\"—breaking down the problem, analyzing it in stages, and only then giving a conclusion. This helps improve accuracy, especially for complex reasoning, math, logic, or multi-hop questions.\n",
    "\n",
    "Can be combined with few-shot prompting (i.e., giving multiple CoT examples before the actual question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112d49f4-f8d6-444b-8ecf-651efc85bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static example to demonstrate format (few-shot learning)\n",
    "prompt = \"\"\"\n",
    "You are a thoughtful and logical assistant. For every question, you will:\n",
    "- Think step-by-step under a “Thought” section.\n",
    "- Then write the final result under “Answer”.\n",
    "- Always follow the structure shown below.\n",
    "\n",
    "Use this format:\n",
    "Question: <the question>\n",
    "Thought: <your detailed reasoning>\n",
    "Answer: <final answer>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: If a train leaves at 2 PM and takes 3 hours to reach its destination, what time does it arrive?\n",
    "Thought: The train departs at 2 PM. If it travels for 3 hours, it will arrive at 2 + 3 = 5 PM.\n",
    "Answer: 5 PM\n",
    "\n",
    "Question: What is the capital of the country whose official language is French and borders Germany?\n",
    "Thought: France is a country that borders Germany and has French as its official language. The capital of France is Paris.\n",
    "Answer: Paris\n",
    "\n",
    "Question: What is the sum of the first three even numbers?\n",
    "Thought: The first three even numbers are 2, 4, and 6. Their sum is 2 + 4 + 6 = 12.\n",
    "Answer: 12\n",
    "\n",
    "Now answer the next question using the same format:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a50050-9798-44a8-82c5-82fdae00453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is elevation range for the area that the eastern sector of colorado orogeny extends into?\"\n",
    "#question = \"If Tom has 5 cookies and eats 2, how many does he have left?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396450d2-8b34-4b47-b297-0671cf892409",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e07f566-492c-4b77-9e0e-5a10eac67a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to figure out the elevation range for the area that the eastern sector of the Colorado orogeny extends into. First, I should recall what the Colorado orogeny is. From what I remember, the Colorado orogeny is a mountain-building event that occurred during the Proterozoic era, around 1.8 billion years ago. It's part of the larger Laramide orogeny, which I think mainly affected the western United States, creating structures like the Rocky Mountains.\n",
      "\n",
      "Wait, no, the Laramide orogeny is a different event, more recent, during the Cretaceous period. The Colorado orogeny is actually older. So the Colorado orogeny refers to earlier tectonic activity in the region that's now Colorado, leading to the formation of certain geological structures. The eastern sector of this orogeny would probably be the part that's extending towards the east part of Colorado.\n",
      "\n",
      "Now, to find the elevation range of the area affected by the eastern sector. I should think about the geography of Colorado. The Rocky Mountains are in the western part, and as you go east, the terrain generally becomes lower, transitioning into the Great Plains. The highest point in Colorado is Mount Elbert, over 14,000 feet. But the elevations decrease eastward.\n",
      "\n",
      "However, the Colorado orogeny's eastern sector might extend into parts of Colorado and maybe even into adjacent states like Kansas or Nebraska, which are part of the Great Plains. The Great Plains typically have elevations ranging from near sea level up to around 5,000 feet. But in Colorado, the eastern part might still have higher elevations compared to the central or western parts.\n",
      "\n",
      "Wait, maybe the eastern sector of the Colorado orogeny is associated with specific geological provinces. For example, the Front Range is part of the Rocky Mountains and is in the eastern part of Colorado. The Front Range has elevations that can go up to around 14,000 feet in the west, but the eastern parts of the Front Range might be lower, perhaps between 5,000 to 9,000 feet. The High Plains east of the Front Range have lower elevations, maybe 4,000 to 7,000 feet. The exact numbers might vary.\n",
      "\n",
      "I need to confirm typical elevation ranges for the areas affected by the Colorado orogeny's eastern part. If the eastern sector extends into the region that's part of the High Plains or the Colorado Piedmont, then the elevations would be in the moderate range. Also, considering that the orogeny's effects might include uplifts and basins, the elevation range could span from around 4,000 feet up to maybe 8,000 feet.\n",
      "\n",
      "Looking up some info: The Colorado orogeny's eastern sector is associated with the Central Colorado Embayment and the Denver Basin. The Denver Basin is a sedimentary basin that underlies the front range and the foothills, extending into the Great Plains. The area around Denver has elevations ranging from around 5,000 to 6,000 feet, with the foothills going higher. The Front Range itself can go up to 14,000 feet, but the eastern sector might refer to the foothills and adjacent plains. So the elevation range might be from about 4,000 feet to 8,000 feet. However, I should check a reliable source or geological survey for precise numbers.\n",
      "\n",
      "Another angle: The Colorado Plateau to the west has higher elevations, but the eastern sector is more towards the Great Plains. The transition area, like the Front Range and the foothills, would have a range. If I recall, the Front Range rises from about 4,000 feet to over 14,000 feet, but the specific sector in question might have a narrower range. For the eastern part of the orogeny, maybe 5,000 to 7,000 feet. Alternatively, if it includes the High Plains, it could be 4,000 to 7,000 feet. I'm not entirely sure, but I think the answer would be in that range.\n",
      "</think>\n",
      "\n",
      "The Colorado orogeny's eastern sector extends into the Denver Basin and adjacent foothill regions in eastern Colorado, which transition into the Great Plains. The elevation range in these areas typically varies from around 4,000 feet in the western Great Plains to approximately 7,000–8,000 feet in the eastern foothills of the Front Range. This range reflects the gradual uplift associated with the orogeny and the transition from plains to mountainous terrain.\n",
      "\n",
      "Answer: Approximate elevation range of 4,000 to 8,000 feet.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93353aa-5f03-46ba-bbaf-20a24e963403",
   "metadata": {},
   "source": [
    "# ReAct Style\n",
    "1. Encourages explicit reasoning, not just end answers\n",
    "1. Allows the model to interleave thoughts and actions\n",
    "1. Great for use with tools or plugins (e.g., search, code exec, database)\n",
    "1. Makes model behavior transparent and verifiable\n",
    "\n",
    "## Template\n",
    "\n",
    "1. Question: [user question]\n",
    "1. Thought: [model's internal reasoning]\n",
    "1. Action: [some action like Search(), Calculator(), API call]\n",
    "1. Observation: [result of the action]\n",
    "\n",
    "...repeat Thought → Action → Observation...\n",
    "\n",
    "Answer: [final response to the question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f08e9f4-90e1-4b76-acbb-bd7d20fcc411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static example to demonstrate format (few-shot learning)\n",
    "few_shot_example = (\n",
    "    \"Question: What is the capital of the country that borders Germany and has Vienna as its capital?\\n\"\n",
    "    \"Thought: I need to find which country has Vienna as its capital.\\n\"\n",
    "    \"Action:  Lookup('country with capital Vienna')\\n\"\n",
    "    \"Observation: Austria\\n\"\n",
    "    \"Thought: Now check if Austria borders Germany.\\n\"\n",
    "    \"Action:  Lookup('Does Austria border Germany?')\\n\"\n",
    "    \"Observation: Yes\\n\"    \n",
    "    \"Answer: The capital of Austria, which borders Germany, is Vienna.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b010564e-e856-4825-ab8d-9768b743dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is elevation range for the area that the eastern sector of colorado orogeny extends into?\"\n",
    "#question = \"If Tom has 5 cookies and eats 2, how many does he have left?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a734f30-5de2-41e7-8c2a-bd0ed0228147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine few-shot example with dynamic question\n",
    "prompt = f\"\"\"{few_shot_example}\n",
    "\n",
    "Question: {question}\n",
    "Thought:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d9bad-abda-43fc-a60b-1e9102095c0a",
   "metadata": {},
   "source": [
    "Note - \n",
    "- In the last example for CoT, the system prompt got the examples.\n",
    "- In this example, we keep pass the example data with each questions.\n",
    "It is just 2 different styles to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9866143-c99f-4780-82a7-4744dc42cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Answer questions using a ReAct format: Thought → Action → Observation → Answer.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee5e962-da45-489e-97ad-2aace3c4809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Colorado Orogeny refers to a mountain-building event, and the eastern sector typically extends into parts of the Great Plains. I need to determine the elevation range of these areas.\n",
      "\n",
      "Action: Lookup('elevation range Great Plains')\n",
      "Observation: The elevation of the Great Plains generally ranges from about 500 to 2,000 meters (1,640 to 6,560 feet) above sea level as they extend eastward from the Rocky Mountains.\n",
      "\n",
      "Answer: The eastern sector of the Colorado Orogeny extends into the Great Plains, where the elevation ranges from approximately 500 to 2,000 meters (1,640 to 6,560 feet) above sea level.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb73119-e961-49b4-a0c4-89513c22bd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "783e86f2-6d0b-4d01-9a61-c0cbe078eb20",
   "metadata": {},
   "source": [
    "# Chain of Thought (CoT) vs ReAct (Reasoning + Acting)\n",
    "\n",
    "## Chain of Thought (CoT)\n",
    "What it is:\n",
    "Just reasoning — step-by-step thoughts leading to an answer.\n",
    "\n",
    "\n",
    "|Strengths|Limitations|\n",
    "|---|---|\n",
    "|Good for pure reasoning tasks (math, logic, factual multi-step questions).|Doesn’t interact with external tools or sources.|\n",
    "|Easy to implement.|Limited when answers need fresh data, search, or database queries.|\n",
    "|Transparent: you can see the reasoning path.||\n",
    "\n",
    "\n",
    "## ReAct (Reasoning + Acting)\n",
    "What it is:\n",
    "A prompt style that combines reasoning (like CoT) with actions, such as calling tools, web searches, or internal functions. Often used with agents.\n",
    "\n",
    "\n",
    "|Strengths|Limitations|\n",
    "|---|---|\n",
    "|Perfect for agent workflows, e.g., answering based on tool output, RAG systems, browsing, calling APIs.|More complex to implement (you need tool handlers or agents).|\n",
    "|Enables decision-making with dynamic data.|Harder to debug if the chain gets too long or recursive.|\n",
    "|You can plug in your own tools, like databases, vector search, etc.||\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8eb9c-fe97-4ebe-9c72-566bd0f3a975",
   "metadata": {},
   "source": [
    "# ReAct Agent Prompt with real actions and Agents\n",
    "\n",
    "We spoke that ReAct approach fits in well when some actions are involved. While we showed some examples of lookup actions, below, we get more real with actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782dd43b-0161-4d16-b5d0-f0e463a18522",
   "metadata": {},
   "source": [
    "Once again, we are setting up a system prompt for ReACT.\n",
    "Notice, we talk about available actions here - which we did not do for CoTs as they were not applicable\n",
    "And also give examples - as we did for CoTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049bda6e-d2b2-4b99-9ab9-5471161a8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run through one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "get_provision_status:\n",
    "e.g. get_provision_status: guid\n",
    "returns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\n",
    "\n",
    "log_error:\n",
    "e.g log_error: status\n",
    "When a guid has a provision_status ERROR call this with the return value of get_provision_status\n",
    "\n",
    "log_status:\n",
    "e.g log_status: status\n",
    "When a guid does not have an ERROR status call this with the return value of get_provision_status\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the staus of cloud deployment with guid <guid>\n",
    "Thought: I should look up the status with get_provision_status \n",
    "Action: get_provision_status: guid \n",
    "PAUSE:\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: Guid status \"SUCCESS: Completed\"\n",
    "\n",
    "You then call any necessary logging tools before outputing the status:\n",
    "\n",
    "Answer: Guid status \"SUCCESS: Completed\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6578f5-07f9-41cb-aed0-b6e50a15564b",
   "metadata": {},
   "source": [
    "### PAUSE\n",
    "\n",
    "It is very important.\n",
    "- After an Action (e.g., lookup, calculation, API call), the model stops (pause) to wait for the result.\n",
    "- It does not hallucinate the result.\n",
    "- It needs real information from the environment (tools, web, database, code, etc.).\n",
    "- Only after the result (Observation) comes back does it continue reasoning.\n",
    "- Without the pause, the model would guess the observation — which can lead to wrong or invented answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76eb490-6a3d-4c8c-b36c-0c0de31380e6",
   "metadata": {},
   "source": [
    "Here is a simple agent definition\n",
    "Note - the roles: system, user, assistant\n",
    "\n",
    "In the OpenAI SDK, when you're calling models like gpt-4, gpt-4o, or gpt-3.5-turbo using the chat/completions endpoint, the roles used are:\n",
    "\n",
    "|Role | Purpose|\n",
    "|---|---|\n",
    "|system | Sets the behavior, identity, style, or rules of the assistant. (e.g., \"You are a helpful assistant.\")|\n",
    "|user | Represents input/questions from the human user.|\n",
    "|assistant | Represents the model's previous responses.|\n",
    "\n",
    "\n",
    "- system: Optional, but powerful. Sets context at the start. You usually have one.\n",
    "- user: Each time a person talks, you add a user message.\n",
    "- assistant: Each time the model replies, its response is logged as an assistant message.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fff260b-2ee5-4ae9-b66b-4c313d5df9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8af50d-1c7e-4cab-93de-01d7a0942cb4",
   "metadata": {},
   "source": [
    "Next, we define the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f2cf93-87b3-430e-9a4b-0bec9eb9e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "First of the *fake* functions to test if the LLM/Prompt will ReAct correctly\n",
    "taking different paths on different results\n",
    "'''\n",
    "\n",
    "def get_provision_status(guid):\n",
    "\n",
    "    #// call to MCP Server AAP2 Controller\n",
    "    # // foo = bar()\n",
    "    \n",
    "    status_messages = [\n",
    "        \"INFO: Initializing\",\n",
    "        \"INFO: In progress\",\n",
    "        \"ERROR: Failed\",\n",
    "        \"ERROR: API Timeout\",\n",
    "        \"ERROR: Rate Limited\",\n",
    "        \"WARNING: Minor errors\",\n",
    "        \"SUCCESS: Completed\"\n",
    "    ]\n",
    "        # \"INFO: Finalizing\",\n",
    "    # return random.choice(f\"{guid} status: {status_messages}\")\n",
    "    status = random.choice(status_messages)\n",
    "    return f\"{guid} status: {status}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc6f2d9-80c9-4ad6-9165-d0158c049954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(status):\n",
    "    print(f\"{status} Logged stateus to Slack.\")\n",
    "    print(f\"{status} Opened Jira Ticket with Status.\")\n",
    "    return 0\n",
    "\n",
    "def log_status(status):\n",
    "    print(f\"{status} Logged status to Slack.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d41d31-7186-474d-b405-9a5396221d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_actions = {\n",
    "   \"log_status\": log_status,\n",
    "   \"log_error\": log_error,\n",
    "   \"get_provision_status\": get_provision_status,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24f68d-edf5-4e74-8d87-4fb509133082",
   "metadata": {},
   "source": [
    "Now we call the agent with to set up the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d47df89b-5030-4e6a-a3bd-d16e72655bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)\n",
    "# Run the cell below with this line commented. \n",
    "# And then once again run it with this line uncommented\n",
    "# See where the flow stops ?\n",
    "\n",
    "#abot(\"I have a deployments running with guid: 1adr4 what is its status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df37b053-6f9e-42ef-aa18-915bd47d6f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: App -> LLM:\n",
      "\n",
      "Role: system\n",
      "Content:\n",
      "\n",
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run through one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "get_provision_status:\n",
      "e.g. get_provision_status: guid\n",
      "returns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\n",
      "\n",
      "log_error:\n",
      "e.g log_error: status\n",
      "When a guid has a provision_status ERROR call this with the return value of get_provision_status\n",
      "\n",
      "log_status:\n",
      "e.g log_status: status\n",
      "When a guid does not have an ERROR status call this with the return value of get_provision_status\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: What is the staus of cloud deployment with guid <guid>\n",
      "Thought: I should look up the status with get_provision_status \n",
      "Action: get_provision_status: guid \n",
      "PAUSE:\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "You then call any necessary logging tools before outputing the status:\n",
      "\n",
      "Answer: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, message in  enumerate(abot.messages):\n",
    "    if message[\"role\"] != \"assistant\":\n",
    "        print(f\"Step {i}: App -> LLM:\\n\")\n",
    "    else:\n",
    "        print(f\"Step {i}: App <- LLM:\\n\")\n",
    "    print(f\"Role: {message['role']}\\nContent:\\n\\n{message['content']}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57606abf-1465-4c3d-a8fa-787d64da0826",
   "metadata": {},
   "source": [
    "## Now Let's automate all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d47413ee-c8e3-4a25-9df4-cd4a8c803796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/61/bmwhyqss6rjdhl37b33pbz9m0000gn/T/ipykernel_26604/2177360788.py:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  action_re = re.compile(\"^Action: (\\w+): (.*)$\")\n"
     ]
    }
   ],
   "source": [
    "action_re = re.compile(\"^Action: (\\w+): (.*)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a22524-fb84-4803-a9e3-c9504378d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    print(\"Step 0\")\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a)\n",
    "            for a in result.split('\\n')\n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            print(f\"\\nStep {i}\")\n",
    "            # print(f\"Actions:\\n\\n{actions}\")\n",
    "            action, action_inputs = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(f\"Unknown action: {action}: -- running {action} {action_inputs}\")\n",
    "            observation = known_actions[action](action_inputs)\n",
    "            print(f\"Observation: {observation}\")\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98d9646e-eea8-41bb-a2ea-fad299ffebff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Thought: I should look up the status of the deployment using the provided guid.\n",
      "Action: get_provision_status: 1adr4 \n",
      "PAUSE.\n",
      "\n",
      "Step 1\n",
      "Observation: 1adr4  status: ERROR: Rate Limited\n",
      "Thought: Since the status of the deployment is \"ERROR: Rate Limited\", I should log this error.\n",
      "Action: log_error: ERROR: Rate Limited\n",
      "PAUSE.\n",
      "\n",
      "Step 2\n",
      "ERROR: Rate Limited Logged stateus to Slack.\n",
      "ERROR: Rate Limited Opened Jira Ticket with Status.\n",
      "Observation: 0\n",
      "Answer: The status of the deployment with guid 1adr4 is \"ERROR: Rate Limited\".\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "I have a deployments running with guid: 1adr4 what is its status\n",
    "\"\"\"\n",
    "\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb3bd2e-d259-4351-a7a0-4a57c2cbd5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Thought: I will start by checking the provision status of each deployment using their respective guids. I will then log the status accordingly and finally output the results in both a table and JSON format.\n",
      "\n",
      "Action: get_provision_status: 1adr4\n",
      "PAUSE\n",
      "\n",
      "Step 1\n",
      "Observation: 1adr4 status: INFO: In progress\n",
      "Action: log_status: INFO: In progress\n",
      "PAUSE\n",
      "\n",
      "Step 2\n",
      "INFO: In progress Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: aabf5\n",
      "PAUSE\n",
      "\n",
      "Step 3\n",
      "Observation: aabf5 status: WARNING: Minor errors\n",
      "Action: log_status: WARNING: Minor errors\n",
      "PAUSE\n",
      "\n",
      "Step 4\n",
      "WARNING: Minor errors Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: 45663\n",
      "PAUSE\n",
      "\n",
      "Step 5\n",
      "Observation: 45663 status: INFO: In progress\n",
      "Action: log_status: INFO: In progress\n",
      "PAUSE\n",
      "\n",
      "Step 6\n",
      "INFO: In progress Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: 45ghb\n",
      "PAUSE\n",
      "\n",
      "Step 7\n",
      "Observation: 45ghb status: INFO: In progress\n",
      "Action: log_status: INFO: In progress\n",
      "PAUSE\n",
      "\n",
      "Step 8\n",
      "INFO: In progress Logged status to Slack.\n",
      "Observation: 0\n",
      "Answer:\n",
      "\n",
      "Here is the status of each deployment in a table format:\n",
      "\n",
      "| GUID  | Status                  | Logging Service |\n",
      "|-------|-------------------------|-----------------|\n",
      "| 1adr4 | INFO: In progress       | log_status      |\n",
      "| aabf5 | WARNING: Minor errors   | log_status      |\n",
      "| 45663 | INFO: In progress       | log_status      |\n",
      "| 45ghb | INFO: In progress       | log_status      |\n",
      "\n",
      "And here is the same information in JSON format:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"guid\": \"1adr4\",\n",
      "    \"status\": \"INFO: In progress\",\n",
      "    \"logging_service\": \"log_status\"\n",
      "  },\n",
      "  {\n",
      "    \"guid\": \"aabf5\",\n",
      "    \"status\": \"WARNING: Minor errors\",\n",
      "    \"logging_service\": \"log_status\"\n",
      "  },\n",
      "  {\n",
      "    \"guid\": \"45663\",\n",
      "    \"status\": \"INFO: In progress\",\n",
      "    \"logging_service\": \"log_status\"\n",
      "  },\n",
      "  {\n",
      "    \"guid\": \"45ghb\",\n",
      "    \"status\": \"INFO: In progress\",\n",
      "    \"logging_service\": \"log_status\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"\"\"\n",
    "I have deployments running with guids: 1adr4, aabf5, 45663, and 45ghb\n",
    "First get each provision status and log to any services that need to know\n",
    "Once finished with all deployments output their guids, status, and logging services:\n",
    "\n",
    "* In a simple table\n",
    "* As JSON \n",
    "\"\"\"\n",
    "\n",
    "query(question, max_turns=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf3a34-156a-408b-ae9a-e47eaafc1005",
   "metadata": {},
   "source": [
    "# Reasoning\n",
    "Capabilities are improving every day. The o3-mini accepts a reasoning_effort parameter and can reason without sophisticated prompt injections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d04ad974-c477-4338-a068-abbb6a4a5ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-BQJqSm2ZXRF3L2s1oT5JJj409CeBd'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Below is one acceptable solution. Save this script (for example as transpose.sh), then run it with the matrix string as an argument.\\n\\n#!/bin/bash\\n# This script takes a matrix represented as a string (e.g. \"[1,2],[3,4],[5,6]\")\\n# and prints its transpose in the same format.\\n#\\n# Usage: ./transpose.sh \"[1,2],[3,4],[5,6]\"\\n\\nif [ \"$#\" -ne 1 ]; then\\n  echo \"Usage: $0 \\\\\"[1,2],[3,4],[5,6]\\\\\"\"\\n  exit 1\\nfi\\n\\n# Get the input string.\\nmatrix_string=\"$1\"\\n\\n# Remove the outermost square brackets from the first and last row.\\nmatrix_string=\"${matrix_string#\\\\[}\"\\nmatrix_string=\"${matrix_string%\\\\]}\"\\n\\n# The rows are separated by \\'],[\\' so we replace that with a semicolon for easier splitting.\\nmatrix_string=\"${matrix_string//],[/;}\"\\n\\n# Split the rows into an array.\\nIFS=\\';\\' read -r -a rows &lt;&lt;&lt; \"$matrix_string\"\\n\\nnum_rows=${#rows[@]}\\n\\n# Assume that the first row gives the number of columns.\\nIFS=\\',\\' read -r -a first_row &lt;&lt;&lt; \"${rows[0]}\"\\nnum_cols=${#first_row[@]}\\n\\n# We’ll use a 2D array (associative array) to store the transposed elements.\\ndeclare -A transpose\\n\\n# Parse the input matrix and store the element in the transposed location.\\nfor (( i=0; i&lt;num_rows; i++ )); do\\n  IFS=\\',\\' read -r -a elements &lt;&lt;&lt; \"${rows[i]}\"\\n  for (( j=0; j&lt;num_cols; j++ )); do\\n    transpose[$j,$i]=\"${elements[j]}\"\\n  done\\ndone\\n\\n# Construct the transposed matrix string.\\n# The transposed matrix will have \\'num_cols\\' rows and \\'num_rows\\' columns.\\nresult=\"\"\\nfor (( i=0; i&lt;num_cols; i++ )); do\\n  row_str=\"[\"\\n  for (( j=0; j&lt;num_rows; j++ )); do\\n    row_str+=\"${transpose[$i,$j]}\"\\n    if (( j &lt; num_rows - 1 )); then\\n      row_str+=\",\"\\n    fi\\n  done\\n  row_str+=\"]\"\\n  if (( i &lt; num_cols - 1 )); then\\n    row_str+=\",\"\\n  fi\\n  result+=\"$row_str\"\\ndone\\n\\n# Print the transposed matrix.\\necho \"$result\"\\n\\n----------------------------------------------------------------\\nExplanation:\\n\\n1. The script first removes the very first \"[\" and the very last \"]\", then replaces the delimiter “],[” with a semicolon so that we can use bash’s IFS splitting to get the rows.\\n\\n2. It determines the number of rows and columns by inspecting the rows split.\\n\\n3. It then loops over each element and stores it in an associative array (using keys “col,row”) so that element (i,j) goes to position (j,i) in the transposed matrix.\\n\\n4. Finally, it reconstructs the output in the same format (each row enclosed by square brackets and separated by commas) and prints it.\\n\\nExample:\\n\\n% ./transpose.sh \"[1,2],[3,4],[5,6]\"\\n[1,3,5],[2,4,6]\\n\\nAny correct solution that produces the expected output is acceptable.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1745612512</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'o3-mini-2025-01-31'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_9e9a8feebe'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2128</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2172</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1088</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-BQJqSm2ZXRF3L2s1oT5JJj409CeBd'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Below is one acceptable solution. Save this script \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfor example as transpose.sh\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, then run it with the matrix string as an argument.\\n\\n#!/bin/bash\\n# This script takes a matrix represented as a string \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. \"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1,2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3,4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5,6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n# and prints its transpose in the same format.\\n#\\n# Usage: ./transpose.sh \"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1,2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3,4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5,6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\\n\\nif \u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"$#\" -ne 1 \u001b[0m\u001b[32m]\u001b[0m\u001b[32m; then\\n  echo \"Usage: $0 \\\\\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1,2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3,4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5,6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\\\\"\"\\n  exit 1\\nfi\\n\\n# Get the input string.\\\u001b[0m\u001b[32mnmatrix_string\u001b[0m\u001b[32m=\"$1\"\\n\\n# Remove the outermost square brackets from the first and last row.\\\u001b[0m\u001b[32mnmatrix_string\u001b[0m\u001b[32m=\"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmatrix_string#\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\\u001b[0m\u001b[32mnmatrix_string\u001b[0m\u001b[32m=\"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmatrix_string%\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n\\n# The rows are separated by \\'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\' so we replace that with a semicolon for easier splitting.\\\u001b[0m\u001b[32mnmatrix_string\u001b[0m\u001b[32m=\"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmatrix_string//\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m/;\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n\\n# Split the rows into an array.\\\u001b[0m\u001b[32mnIFS\u001b[0m\u001b[32m=\\';\\' read -r -a rows <<< \"$matrix_string\"\\n\\\u001b[0m\u001b[32mnnum_rows\u001b[0m\u001b[32m=$\u001b[0m\u001b[32m{\u001b[0m\u001b[32m#rows\u001b[0m\u001b[32m[\u001b[0m\u001b[32m@\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n# Assume that the first row gives the number of columns.\\\u001b[0m\u001b[32mnIFS\u001b[0m\u001b[32m=\\',\\' read -r -a first_row <<< \"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mrows\u001b[0m\u001b[32m[\u001b[0m\u001b[32m0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\\u001b[0m\u001b[32mnnum_cols\u001b[0m\u001b[32m=$\u001b[0m\u001b[32m{\u001b[0m\u001b[32m#first_row\u001b[0m\u001b[32m[\u001b[0m\u001b[32m@\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n# We’ll use a 2D array \u001b[0m\u001b[32m(\u001b[0m\u001b[32massociative array\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to store the transposed elements.\\ndeclare -A transpose\\n\\n# Parse the input matrix and store the element in the transposed location.\\nfor \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m; i<num_rows; i++ \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do\\n  \u001b[0m\u001b[32mIFS\u001b[0m\u001b[32m=\\',\\' read -r -a elements <<< \"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mrows\u001b[0m\u001b[32m[\u001b[0m\u001b[32mi\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n  for \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m; j<num_cols; j++ \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do\\n    transpose\u001b[0m\u001b[32m[\u001b[0m\u001b[32m$j,$i\u001b[0m\u001b[32m]\u001b[0m\u001b[32m=\"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32melements\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n  done\\ndone\\n\\n# Construct the transposed matrix string.\\n# The transposed matrix will have \\'num_cols\\' rows and \\'num_rows\\' columns.\\\u001b[0m\u001b[32mnresult\u001b[0m\u001b[32m=\"\"\\nfor \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m; i<num_cols; i++ \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do\\n  \u001b[0m\u001b[32mrow_str\u001b[0m\u001b[32m=\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"\\n  for \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m; j<num_rows; j++ \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do\\n    row_str+=\"$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtranspose\u001b[0m\u001b[32m[\u001b[0m\u001b[32m$i,$j\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n    if \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m j < num_rows - 1 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; then\\n      row_str+=\",\"\\n    fi\\n  done\\n  row_str+=\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\\n  if \u001b[0m\u001b[32m(\u001b[0m\u001b[32m(\u001b[0m\u001b[32m i < num_cols - 1 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; then\\n    row_str+=\",\"\\n  fi\\n  result+=\"$row_str\"\\ndone\\n\\n# Print the transposed matrix.\\necho \"$result\"\\n\\n----------------------------------------------------------------\\nExplanation:\\n\\n1. The script first removes the very first \"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\" and the very last \"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\", then replaces the delimiter “\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m” with a semicolon so that we can use bash’s IFS splitting to get the rows.\\n\\n2. It determines the number of rows and columns by inspecting the rows split.\\n\\n3. It then loops over each element and stores it in an associative array \u001b[0m\u001b[32m(\u001b[0m\u001b[32musing keys “col,row”\u001b[0m\u001b[32m)\u001b[0m\u001b[32m so that element \u001b[0m\u001b[32m(\u001b[0m\u001b[32mi,j\u001b[0m\u001b[32m)\u001b[0m\u001b[32m goes to position \u001b[0m\u001b[32m(\u001b[0m\u001b[32mj,i\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in the transposed matrix.\\n\\n4. Finally, it reconstructs the output in the same format \u001b[0m\u001b[32m(\u001b[0m\u001b[32meach row enclosed by square brackets and separated by commas\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and prints it.\\n\\nExample:\\n\\n% ./transpose.sh \"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1,2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3,4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5,6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1,3,5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2,4,6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nAny correct solution that produces the expected output is acceptable.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   │   │   │   \u001b[0m\u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcreated\u001b[0m=\u001b[1;36m1745612512\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmodel\u001b[0m=\u001b[32m'o3-mini-2025-01-31'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_9e9a8feebe'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m2128\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m44\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m2172\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m1088\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Below is one acceptable solution. Save this script (for example as transpose.sh), then run it with the matrix string as an argument.\n",
      "\n",
      "#!/bin/bash\n",
      "# This script takes a matrix represented as a string (e.g. \"[1,2],[3,4],[5,6]\")\n",
      "# and prints its transpose in the same format.\n",
      "#\n",
      "# Usage: ./transpose.sh \"[1,2],[3,4],[5,6]\"\n",
      "\n",
      "if [ \"$#\" -ne 1 ]; then\n",
      "  echo \"Usage: $0 \\\"[1,2],[3,4],[5,6]\\\"\"\n",
      "  exit 1\n",
      "fi\n",
      "\n",
      "# Get the input string.\n",
      "matrix_string=\"$1\"\n",
      "\n",
      "# Remove the outermost square brackets from the first and last row.\n",
      "matrix_string=\"${matrix_string#\\[}\"\n",
      "matrix_string=\"${matrix_string%\\]}\"\n",
      "\n",
      "# The rows are separated by '],[' so we replace that with a semicolon for easier splitting.\n",
      "matrix_string=\"${matrix_string//],[/;}\"\n",
      "\n",
      "# Split the rows into an array.\n",
      "IFS=';' read -r -a rows <<< \"$matrix_string\"\n",
      "\n",
      "num_rows=${#rows[@]}\n",
      "\n",
      "# Assume that the first row gives the number of columns.\n",
      "IFS=',' read -r -a first_row <<< \"${rows[0]}\"\n",
      "num_cols=${#first_row[@]}\n",
      "\n",
      "# We’ll use a 2D array (associative array) to store the transposed elements.\n",
      "declare -A transpose\n",
      "\n",
      "# Parse the input matrix and store the element in the transposed location.\n",
      "for (( i=0; i<num_rows; i++ )); do\n",
      "  IFS=',' read -r -a elements <<< \"${rows[i]}\"\n",
      "  for (( j=0; j<num_cols; j++ )); do\n",
      "    transpose[$j,$i]=\"${elements[j]}\"\n",
      "  done\n",
      "done\n",
      "\n",
      "# Construct the transposed matrix string.\n",
      "# The transposed matrix will have 'num_cols' rows and 'num_rows' columns.\n",
      "result=\"\"\n",
      "for (( i=0; i<num_cols; i++ )); do\n",
      "  row_str=\"[\"\n",
      "  for (( j=0; j<num_rows; j++ )); do\n",
      "    row_str+=\"${transpose[$i,$j]}\"\n",
      "    if (( j < num_rows - 1 )); then\n",
      "      row_str+=\",\"\n",
      "    fi\n",
      "  done\n",
      "  row_str+=\"]\"\n",
      "  if (( i < num_cols - 1 )); then\n",
      "    row_str+=\",\"\n",
      "  fi\n",
      "  result+=\"$row_str\"\n",
      "done\n",
      "\n",
      "# Print the transposed matrix.\n",
      "echo \"$result\"\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Explanation:\n",
      "\n",
      "1. The script first removes the very first \"[\" and the very last \"]\", then replaces the delimiter “],[” with a semicolon so that we can use bash’s IFS splitting to get the rows.\n",
      "\n",
      "2. It determines the number of rows and columns by inspecting the rows split.\n",
      "\n",
      "3. It then loops over each element and stores it in an associative array (using keys “col,row”) so that element (i,j) goes to position (j,i) in the transposed matrix.\n",
      "\n",
      "4. Finally, it reconstructs the output in the same format (each row enclosed by square brackets and separated by commas) and prints it.\n",
      "\n",
      "Example:\n",
      "\n",
      "% ./transpose.sh \"[1,2],[3,4],[5,6]\"\n",
      "[1,3,5],[2,4,6]\n",
      "\n",
      "Any correct solution that produces the expected output is acceptable.\n"
     ]
    }
   ],
   "source": [
    "model = \"o3-mini\"\n",
    "prompt = \"\"\"\n",
    "Write a bash script that takes a matrix represented as a string with \n",
    "format '[1,2],[3,4],[5,6]' and prints the transpose in the same format.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = model,\n",
    "    reasoning_effort=\"medium\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "pprint(response)\n",
    "print('-----------------')\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78716910-84ca-42b6-9f2b-faa39f4df1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
