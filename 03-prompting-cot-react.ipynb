{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7cc9910",
   "metadata": {},
   "source": [
    "# Understanding AI Prompts: Chain of Thought (CoT) vs. ReAct\n",
    "\n",
    "This guide explores two techniques for \"prompting\" Large Language Models (LLMs), which are AI systems trained on vast amounts of text data to understand and generate human-like language. We'll compare \"Chain of Thought\" (CoT) and \"ReAct\" (Reason+Act) prompting. Think of prompting as how you ask the AI to do something. The way you frame your request can significantly change the quality and accuracy of its response.\n",
    "\n",
    "For an Ops professional, understanding these techniques can be valuable when:\n",
    "* Integrating AI into monitoring or automation scripts.\n",
    "* Building tools that use AI to summarize logs or incidents.\n",
    "* Evaluating AI solutions for operational tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c54443-8ecc-420a-9292-ccc44b7b4c3d",
   "metadata": {},
   "source": [
    "### Verifying Python Software Installation (optional)\n",
    "\n",
    "The following `pip install` command ensures all necessary Python software components (dependencies) are present.\n",
    "\n",
    "It's safe to run for verification, even if you've already completed Module 02 (which should have handled this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f1ea62-58fb-46eb-874b-acb92cb2e060",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types==0.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: async-lru==2.0.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: attrs==25.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: babel==2.17.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 9)) (2.17.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 10)) (4.13.4)\n",
      "Requirement already satisfied: bleach==6.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 11)) (6.2.0)\n",
      "Requirement already satisfied: certifi==2025.4.26 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 12)) (2025.4.26)\n",
      "Requirement already satisfied: cffi==1.17.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 13)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 14)) (3.4.1)\n",
      "Requirement already satisfied: click==8.1.8 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 15)) (8.1.8)\n",
      "Requirement already satisfied: colorama==0.4.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.14 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 18)) (1.8.14)\n",
      "Requirement already satisfied: decorator==5.2.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 19)) (5.2.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 20)) (0.7.1)\n",
      "Requirement already satisfied: distro==1.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 21)) (1.9.0)\n",
      "Requirement already satisfied: executing==2.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 22)) (2.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 23)) (2.21.1)\n",
      "Requirement already satisfied: fqdn==1.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 24)) (1.5.1)\n",
      "Requirement already satisfied: griffe==1.7.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 25)) (1.7.3)\n",
      "Requirement already satisfied: h11==0.16.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 26)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 27)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 28)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 29)) (0.4.0)\n",
      "Requirement already satisfied: idna==3.10 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 30)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 31)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 32)) (9.2.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 33)) (1.1.1)\n",
      "Requirement already satisfied: ipywidgets==8.1.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 34)) (8.1.6)\n",
      "Requirement already satisfied: isoduration==20.11.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 35)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 36)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 37)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 38)) (0.9.0)\n",
      "Requirement already satisfied: json5==0.12.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 39)) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 40)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 41)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 42)) (2025.4.1)\n",
      "Requirement already satisfied: jupyter==1.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 43)) (1.1.1)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 44)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 45)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 46)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 47)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 48)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 49)) (2.15.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 50)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 51)) (4.4.1)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 52)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 53)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.14 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 54)) (3.0.14)\n",
      "Requirement already satisfied: llama_stack_client==0.2.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 55)) (0.2.4)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 56)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 57)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 58)) (0.1.7)\n",
      "Requirement already satisfied: mcp==1.8.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 59)) (1.8.1)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 60)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.1.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 61)) (3.1.3)\n",
      "Requirement already satisfied: nbclient==0.10.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 62)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.6 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 63)) (7.16.6)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 64)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 65)) (1.6.0)\n",
      "Requirement already satisfied: notebook==7.4.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 66)) (7.4.1)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 67)) (0.2.4)\n",
      "Requirement already satisfied: numpy==2.2.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 68)) (2.2.5)\n",
      "Requirement already satisfied: openai==1.76.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 69)) (1.76.2)\n",
      "Requirement already satisfied: openai-agents==0.0.13 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 70)) (0.0.13)\n",
      "Requirement already satisfied: overrides==7.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 71)) (7.7.0)\n",
      "Requirement already satisfied: packaging==25.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 72)) (25.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 73)) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 74)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 75)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 76)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 77)) (4.3.7)\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 78)) (0.21.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 79)) (3.0.51)\n",
      "Requirement already satisfied: psutil==7.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 80)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 81)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 82)) (0.2.3)\n",
      "Requirement already satisfied: pyaml==25.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 83)) (25.1.0)\n",
      "Requirement already satisfied: pycparser==2.22 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 84)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 85)) (2.11.4)\n",
      "Requirement already satisfied: pydantic-settings==2.9.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 86)) (2.9.1)\n",
      "Requirement already satisfied: pydantic_core==2.33.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 87)) (2.33.2)\n",
      "Requirement already satisfied: Pygments==2.19.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 88)) (2.19.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 89)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 90)) (1.1.0)\n",
      "Requirement already satisfied: python-json-logger==3.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 91)) (3.3.0)\n",
      "Requirement already satisfied: python-multipart==0.0.20 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 92)) (0.0.20)\n",
      "Requirement already satisfied: pytz==2025.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 93)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 94)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 95)) (26.4.0)\n",
      "Requirement already satisfied: referencing==0.36.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 96)) (0.36.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 97)) (2.32.3)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 98)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 99)) (0.1.1)\n",
      "Requirement already satisfied: rich==14.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 100)) (14.0.0)\n",
      "Requirement already satisfied: rpds-py==0.24.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 101)) (0.24.0)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 102)) (1.8.3)\n",
      "Requirement already satisfied: setuptools==80.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 103)) (80.0.0)\n",
      "Requirement already satisfied: six==1.17.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 104)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 105)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.7 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 106)) (2.7)\n",
      "Requirement already satisfied: sse-starlette==2.3.5 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 107)) (2.3.5)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 108)) (0.6.3)\n",
      "Requirement already satisfied: starlette==0.46.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 109)) (0.46.2)\n",
      "Requirement already satisfied: termcolor==3.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 110)) (3.1.0)\n",
      "Requirement already satisfied: terminado==0.18.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 111)) (0.18.1)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 112)) (1.4.0)\n",
      "Requirement already satisfied: tornado==6.4.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 113)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 114)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 115)) (5.14.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 116)) (2.9.0.20241206)\n",
      "Requirement already satisfied: types-requests==2.32.0.20250328 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 117)) (2.32.0.20250328)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 118)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 119)) (4.13.2)\n",
      "Requirement already satisfied: tzdata==2025.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 120)) (2025.2)\n",
      "Requirement already satisfied: uri-template==1.3.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 121)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.4.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 122)) (2.4.0)\n",
      "Requirement already satisfied: uvicorn==0.34.2 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 123)) (0.34.2)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 124)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.11.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 125)) (24.11.1)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 126)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 127)) (1.8.0)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.14 in /home/dev/venv/lib64/python3.12/site-packages (from -r requirements.txt (line 128)) (4.0.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bdeb7",
   "metadata": {},
   "source": [
    "## Getting Started: Setting Up Our AI Connection\n",
    "\n",
    "This first code block is about setting up the connection to an AI model. In a real-world Ops scenario, this might involve connecting to a centrally managed AI service, ensuring credentials are secure, and understanding the endpoint (the address of the AI service). (We've deeply commented the code for those interested.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d30311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Imports complete, Client initialized, Model setup</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m Imports complete, Client initialized, Model setup\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary Python libraries\n",
    "import openai         # The official library for interacting with OpenAI models (or compatible APIs)\n",
    "import re             # Stands for 'regular expression', a tool for pattern matching in text\n",
    "import httpx          # A modern HTTP client library, used for making web requests (how we talk to the AI model)\n",
    "import os                # Provides ways to interact with the operating system (e.g., environment variables for API keys)\n",
    "from rich import print   # A library for creating rich text and beautiful formatting in the terminal (helps make output clearer)\n",
    "import json              # For working with JSON data, a common format for APIs\n",
    "\n",
    "# Specifically import the OpenAI client class\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Configuration for Connecting to the AI Model ---\n",
    "# Ops Perspective: These would typically be managed via configuration files,\n",
    "# environment variables, or a secrets management system in a production environment.\n",
    "\n",
    "# API Key: This is like a password that gives us access to the AI model.\n",
    "# IMPORTANT: Never hardcode real API keys in your scripts. This is a placeholder.\n",
    "api_key = \"placeholder\"  \n",
    "\n",
    "# Model Name: Specifies which AI model we want to use.\n",
    "# Different models have different capabilities (e.g., speed, accuracy, cost).\n",
    "# \"mistral-small:latest\" and \"qwen3:32b\" are examples of other specific model versions.\n",
    "\n",
    "model = \"llama3.2:3b-instruct-fp16\" \n",
    "\n",
    "# Base URL: This is the network address where the AI model is hosted.\n",
    "# In this case, \"http://localhost:11434/v1/\" suggests it's running locally on your machine\n",
    "# (perhaps using a tool like Ollama or a local inference server).\n",
    "# In an enterprise setup, this would be a secure, managed API endpoint.\n",
    "base_url = \"http://localhost:11434/v1/\"\n",
    "\n",
    "# --- Initialize the AI Client ---\n",
    "# This creates an 'object' (an instance of the OpenAI class) that we'll use\n",
    "# to send requests to the AI model and get responses.\n",
    "# It's configured with the URL and API key we defined above.\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Print a confirmation message\n",
    "# print(\"Python libraries imported and AI Client connection configured.\")\n",
    "print(\"[green] Imports complete, Client initialized, Model setup[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a4f78",
   "metadata": {},
   "source": [
    "**Ops Focus & Python/AI for Beginners:**\n",
    "\n",
    "* **`import` statements:** These lines bring in pre-written code (libraries) that provide useful functions. For example, `openai` helps talk to AI models, and `os` can help manage things like API keys (passwords for services).\n",
    "* **`api_key`:** This is like a password for the AI service. In real systems, you'd never type it directly into the code. You'd use secure methods like environment variables or a secrets vault.\n",
    "* **`model`:** AI services offer different \"models\" (like different versions of software). Some are faster, some are better at specific tasks. Choosing the right one is like picking the right tool for a job.\n",
    "* **`base_url`:** This is the web address of the AI service. `localhost` means it's running on the same machine as this script. In a company, this would be a central, managed service address.\n",
    "* **`client = OpenAI(...)`:** This line creates a \"client\" object. Think of it as setting up a dedicated communication channel to the AI service, using the address and password we specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53681d",
   "metadata": {},
   "source": [
    "# Chain of Thought (CoT) Prompting\n",
    "\n",
    "## What is Chain of Thought?\n",
    "\n",
    "Imagine you're trying to solve a complex problem. You wouldn't just jump to the answer. You'd think it through, step by step. **Chain of Thought (CoT) prompting** is a way to ask an AI model to do the same thing: show its work before giving the final answer.\n",
    "\n",
    "Instead of just asking:\n",
    "`\"What's 5 + 3 * 2?\"` (which could be ambiguous)\n",
    "\n",
    "You might guide it with CoT:\n",
    "`\"First, tell me the order of operations. Then calculate 3 * 2. Finally, add 5 to that result. What's the final answer?\"`\n",
    "\n",
    "**Why is this useful, especially in Ops?**\n",
    "\n",
    "* **Better Accuracy for Complex Tasks:** If an AI needs to diagnose a multi-step failure or parse a complex log, forcing it to \"think step-by-step\" can lead to more accurate results.\n",
    "* **Transparency & Debugging:** You can see *how* the AI reached its conclusion. If it makes a mistake, you can often pinpoint where its reasoning went wrong. This is crucial for trusting AI in operational tasks.\n",
    "* **Reduces \"Hallucinations\":** Sometimes AI models confidently make up incorrect information (called \"hallucinations\"). CoT can help reduce this by making the reasoning process more explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c62494",
   "metadata": {},
   "source": [
    "### Few-Shot Learning (A Quick Detour)\n",
    "\n",
    "The example below uses a concept called **\"few-shot prompting.\"**\n",
    "\n",
    "* **Zero-Shot:** You ask the AI a question directly without any examples.\n",
    "    * `\"Translate 'hello' to French.\"`\n",
    "* **One-Shot:** You give the AI one example before asking your question.\n",
    "    * `\"English: goodbye -> French: au revoir. Now, English: hello -> French: ?\"`\n",
    "* **Few-Shot:** You give the AI several examples. This helps the AI better understand the pattern, format, or type of reasoning you expect. The CoT example below uses few-shot prompting by providing multiple question/thought/answer examples.\n",
    "\n",
    "From an Ops perspective, if you're trying to get an AI to classify alerts or summarize incident reports in a specific format, providing a few good examples (few-shot) can drastically improve its performance and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d65d695",
   "metadata": {},
   "source": [
    "### CoT Example:\n",
    "\n",
    "This code shows how to use CoT. We give the AI a \"system prompt\" which is like setting the rules for how it should behave. Then we ask our actual question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4877fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Question: If Tom has </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> cookies and eats </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">, how many does he have left?</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m Question: If Tom has \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m cookies and eats \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m, how many does he have left?\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: If Tom has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> cookies and eats <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, how many does he have left?\n",
       "Thought: To find out how many cookies Tom has left, we need to subtract the number of cookies he ate from the total\n",
       "number of cookies he had. So, we will subtract <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"font-weight: bold\">(</span>the number of cookies eaten<span style=\"font-weight: bold\">)</span> from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> <span style=\"font-weight: bold\">(</span>the initial number of \n",
       "cookies<span style=\"font-weight: bold\">)</span>.\n",
       "Answer: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: If Tom has \u001b[1;36m5\u001b[0m cookies and eats \u001b[1;36m2\u001b[0m, how many does he have left?\n",
       "Thought: To find out how many cookies Tom has left, we need to subtract the number of cookies he ate from the total\n",
       "number of cookies he had. So, we will subtract \u001b[1;36m2\u001b[0m \u001b[1m(\u001b[0mthe number of cookies eaten\u001b[1m)\u001b[0m from \u001b[1;36m5\u001b[0m \u001b[1m(\u001b[0mthe initial number of \n",
       "cookies\u001b[1m)\u001b[0m.\n",
       "Answer: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the \"system prompt\" - instructions for the AI.\n",
    "# It tells the AI to always provide a \"Thought\" process before the \"Answer\".\n",
    "# It also includes several examples (few-shot learning) to show the desired format.\n",
    "\n",
    "cot_system_prompt = \"\"\"\n",
    "You are a thoughtful and logical assistant. For every question, you will:\n",
    "- Think step-by-step under a “Thought” section.\n",
    "- Then write the final result under “Answer”.\n",
    "- Always follow the structure shown below.\n",
    "\n",
    "Use this format:\n",
    "Question: <the question>\n",
    "Thought: <your detailed reasoning>\n",
    "Answer: <final answer>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: If a train leaves at 2 PM and takes 3 hours to reach its destination, what time does it arrive?\n",
    "Thought: The train departs at 2 PM. If it travels for 3 hours, it will arrive at 2 + 3 = 5 PM.\n",
    "Answer: 5 PM\n",
    "\n",
    "Question: What is the capital of the country whose official language is French and borders Germany?\n",
    "Thought: France is a country that borders Germany and has French as its official language. The capital of France is Paris.\n",
    "Answer: Paris\n",
    "\n",
    "Question: What is the sum of the first three even numbers?\n",
    "Thought: The first three even numbers are 2, 4, and 6. Their sum is 2 + 4 + 6 = 12.\n",
    "Answer: 12\n",
    "\n",
    "Now answer the next question using the same format:\n",
    "\"\"\"\n",
    "\n",
    "# This is the actual question we want the AI to answer.\n",
    "user_question_cot = \"If Tom has 5 cookies and eats 2, how many does he have left?\"\n",
    "\n",
    "# --- Preparing the request for the AI ---\n",
    "# AI models often work with a \"conversation history\" or a list of messages.\n",
    "# \"system\" role: Sets the overall behavior of the AI.\n",
    "# \"user\" role: Represents what the human user is asking.\n",
    "messages_for_cot = [\n",
    "    {\"role\": \"system\", \"content\": cot_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_question_cot}\n",
    "]\n",
    "\n",
    "# --- Sending the request to the AI and getting the response ---\n",
    "# `client.chat.completions.create(...)` is the function call to the AI.\n",
    "# - `model=model`: Tells it which AI model to use (that we configured earlier).\n",
    "# - `messages=messages_for_cot`: Passes our structured request.\n",
    "completion_cot = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages_for_cot,\n",
    ")\n",
    "\n",
    "# --- Displaying the AI's response ---\n",
    "# The AI's answer is typically nested within the 'completion' object.\n",
    "# `completion_cot.choices[0].message.content` accesses the text of the AI's reply.\n",
    "\n",
    "print(f\"[green] Question: {user_question_cot}[/green] \\n\")\n",
    "print(completion_cot.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6c7ee",
   "metadata": {},
   "source": [
    "**Ops Focus & Python/AI for Beginners:**\n",
    "\n",
    "* **`cot_system_prompt` (String):** This is a multi-line piece of text (a \"string\" in Python) that acts as the main instruction or persona for the AI. Notice the `\"\"\"triple quotes\"\"\"` which allow text to span multiple lines.\n",
    "* **Placeholders like `<the question>`:** These aren't code; they're part of the instructions to the AI, showing it the desired output format.\n",
    "* **`messages_for_cot` (List of Dictionaries):** This is how we structure the conversation for the AI.\n",
    "    * A Python `list` is an ordered collection of items, enclosed in `[]`.\n",
    "    * A Python `dictionary` is a collection of `key: value` pairs, enclosed in `{}`. Here, keys are like `\"role\"` and `\"content\"`.\n",
    "    * `\"role\": \"system\"`: Sets the overall context or rules for the AI.\n",
    "    * `\"role\": \"user\"`: Contains the specific question from the user.\n",
    "* **`client.chat.completions.create(...)`:** This is the command to \"run\" the AI with our prompt.\n",
    "* **`completion_cot.choices[0].message.content`:** The AI's response comes back in a structured format. This specific path navigates through that structure to get the actual text of the AI's answer. It might seem complex, but it's a standard way APIs return data. You usually get a primary response (the \"choice\"), and within that, the message, and then the content of that message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57c8af",
   "metadata": {},
   "source": [
    "# ReAct (Reason + Act) Prompting\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "**ReAct** takes CoT a step further. It stands for **Reason + Act**.\n",
    "\n",
    "While CoT is about the AI *thinking* step-by-step, ReAct allows the AI to:\n",
    "1.  **Reason (Thought):** Decide what it needs to know or do.\n",
    "2.  **Act (Action):** Propose an action to get that information, like using a tool (e.g., a search engine, a calculator, or even an internal company API to check a server's status).\n",
    "3.  **Observe (Observation):** Get the result from that action.\n",
    "4.  Repeat this Thought -> Action -> Observation cycle until it has enough information.\n",
    "5.  **Answer:** Provide the final answer.\n",
    "\n",
    "**Why is ReAct powerful for Ops?**\n",
    "\n",
    "* **Interacting with the Real World:** This is key! An Ops AI needs to interact with systems. ReAct provides a framework for the AI to say, \"I need to check the current CPU load on server X\" (Thought), then specify an action like `execute_command('get_cpu_load serverX')` (Action). Your system would then run this command and feed the result back to the AI (Observation).\n",
    "* **Using Tools:** You can give the AI \"tools\" – these could be scripts, API calls, or database queries. For instance:\n",
    "    * `LookupKnowledgeBase('error code 123')`\n",
    "    * `GetCurrentOnCall('web_team')`\n",
    "    * `QueryMetrics('database_latency_p99', 'last_1_hour')`\n",
    "* **Dynamic Problem Solving:** For problems where the AI needs to gather information incrementally (like troubleshooting a complex outage), ReAct is much more powerful than CoT alone.\n",
    "* **Transparency:** Like CoT, you see the AI's \"thinking\" process, including what tools it tried to use and what results it got. This is invaluable for verifying its actions and for auditing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3af70b",
   "metadata": {},
   "source": [
    "> ### ReAct vs. React (the JavaScript library)\n",
    ">\n",
    ">It's important to note: **ReAct prompting** for LLMs is different from **React**, the popular JavaScript library for building user interfaces. The names are similar, but the concepts are unrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723fe42",
   "metadata": {},
   "source": [
    "### ReAct Template:\n",
    "\n",
    "The general flow of a ReAct prompt looks like this:\n",
    "\n",
    "1.  **Question:** \\[The user's initial question]\n",
    "2.  **Thought:** \\[The AI's internal reasoning about what it needs to do next]\n",
    "3.  **Action:** \\[The AI proposes an action, often involving a tool, e.g., `Search('topic')`, `Calculator(2+2)`, `APICall('get_status')`]\n",
    "4.  **Observation:** \\[The result of that action, fed back to the AI]\n",
    "    * *(...The Thought -> Action -> Observation cycle can repeat multiple times...)*\n",
    "5.  **Thought:** \\[Final reasoning before giving the answer]\n",
    "6.  **Answer:** \\[The AI's final response to the question]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f522a",
   "metadata": {},
   "source": [
    "### ReAct Example:\n",
    "\n",
    "In this example, we simulate the \"Action\" and \"Observation\" parts. In a real system, your code would actually *execute* the action (e.g., perform a web search if the action is `Search(...)`) and then provide the real result as the observation.\n",
    "\n",
    "Here, we are still using **few-shot prompting** by giving an example of the ReAct flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d091cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Sending ReAct Prompt based request to the LLM. This might take a few moments...</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m Sending ReAct Prompt based request to the LLM. This might take a few moments\u001b[0m\u001b[32m...\u001b[0m\n",
       "\u001b[32m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: I need to find out what primary services can be deployed with Kubernetes.\n",
       "Action: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Lookup</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Kubernetes primary services'</span><span style=\"font-weight: bold\">)</span>\n",
       "Observation: Deployment, Scaling, Load Balancing.\n",
       "\n",
       "Thought: I'm waiting for more results to provide a comprehensive answer.\n",
       "Action: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Lookup</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'use cases for Kubernetes deployment'</span><span style=\"font-weight: bold\">)</span>\n",
       "Observation: \n",
       "  - Web Applications\n",
       "  - Microservices\n",
       "  - Big Data Analytics\n",
       "  - Machine Learning\n",
       "  - Containerized Applications\n",
       "\n",
       "Observation: Continuous Integration and Deployment, Configuration Management.\n",
       "\n",
       "Thought: I want to list the primary services that can be deployed with Kubernetes.\n",
       "Action: Create <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">List</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'primary services of Kubernetes'</span><span style=\"font-weight: bold\">)</span>\n",
       "Observation:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Deploy\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Scale\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Load Balance\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: I need to find out what primary services can be deployed with Kubernetes.\n",
       "Action: \u001b[1;35mLookup\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Kubernetes primary services'\u001b[0m\u001b[1m)\u001b[0m\n",
       "Observation: Deployment, Scaling, Load Balancing.\n",
       "\n",
       "Thought: I'm waiting for more results to provide a comprehensive answer.\n",
       "Action: \u001b[1;35mLookup\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'use cases for Kubernetes deployment'\u001b[0m\u001b[1m)\u001b[0m\n",
       "Observation: \n",
       "  - Web Applications\n",
       "  - Microservices\n",
       "  - Big Data Analytics\n",
       "  - Machine Learning\n",
       "  - Containerized Applications\n",
       "\n",
       "Observation: Continuous Integration and Deployment, Configuration Management.\n",
       "\n",
       "Thought: I want to list the primary services that can be deployed with Kubernetes.\n",
       "Action: Create \u001b[1;35mList\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'primary services of Kubernetes'\u001b[0m\u001b[1m)\u001b[0m\n",
       "Observation:\n",
       "\u001b[1;36m1\u001b[0m. Deploy\n",
       "\u001b[1;36m2\u001b[0m. Scale\n",
       "\u001b[1;36m3\u001b[0m. Load Balance\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a few-shot example demonstrating the ReAct format.\n",
    "# Notice the Thought -> Action -> Observation flow.\n",
    "react_few_shot_example = (\n",
    "    \"Question: What is the capital of the country that borders Germany and has Vienna as its capital?\\n\"\n",
    "    \"Thought: I need to find which country has Vienna as its capital.\\n\"\n",
    "    \"Action: Lookup('country with capital Vienna')\\n\"  # The AI suggests an action\n",
    "    \"Observation: Austria\\n\"  # This would be the *result* of running the Lookup tool\n",
    "    \"Thought: Now I need to check if Austria borders Germany.\\n\"\n",
    "    \"Action: Lookup('Does Austria border Germany?')\\n\"\n",
    "    \"Observation: Yes\\n\"\n",
    "    \"Answer: The capital of Austria, which borders Germany, is Vienna.\"\n",
    ")\n",
    "\n",
    "# A more complex question that might benefit from the ReAct approach\n",
    "# (requiring the AI to \"look up\" information in stages).\n",
    "\n",
    "# Sample question you can experiment with\n",
    "# user_question_react = \"What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\"\n",
    "# \n",
    "\n",
    "user_question_react = \"List the primary services and use cases I can deploy with Kubernetes. When finished also output as a list\" \n",
    "\n",
    "# --- Assembling the Prompt ---\n",
    "# In this ReAct example, the few-shot example is combined with the new question.\n",
    "# The `f\"\"` syntax is an \"f-string\" in Python. It lets you embed variables directly in a string.\n",
    "# We're telling the AI: \"Here's an example of how to think, act, and observe. Now, do the same for this new question.\"\n",
    "# The prompt ends with \"Thought:\" to encourage the AI to start its reasoning process.\n",
    "\n",
    "react_prompt_for_user = f\"\"\"{react_few_shot_example}\n",
    "\n",
    "Question: {user_question_react}\n",
    "Thought:\"\"\" # We explicitly ask the AI to start with a thought.\n",
    "\n",
    "# --- Preparing the request for the AI ---\n",
    "# System Prompt: Sets the overall ReAct behavior.\n",
    "# User Prompt: Contains the few-shot example and the new question.\n",
    "messages_for_react = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that answers questions using a ReAct format: Thought -> Action -> Observation -> Answer. You can use a `Lookup('query')` action to find information.\"},\n",
    "    {\"role\": \"user\", \"content\": react_prompt_for_user}\n",
    "]\n",
    "\n",
    "# --- Sending the request to the AI ---\n",
    "# This will take a bit longer because the AI is generating a more complex, multi-step response.\n",
    "# In a Jupyter Notebook, you'd see a [*] next to the cell while it's processing.\n",
    "print(\"[green] Sending ReAct Prompt based request to the LLM. This might take a few moments...\\n [/green]\")\n",
    "completion_react = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages_for_react,\n",
    ")\n",
    "\n",
    "# --- Displaying the AI's response ---\n",
    "print(completion_react.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa29f5",
   "metadata": {},
   "source": [
    "**Ops Focus & Python/AI for Beginners:**\n",
    "\n",
    "* **`react_few_shot_example` (String):** Again, a multi-line string providing an example. The key here is the `Action:` and `Observation:` parts.\n",
    "* **Simulated Actions:** In this notebook, `Thought: ('...')` **isn't actually running a search**. The AI is *generating text* that looks like it's planning to run a search. In a real ReAct system (often called an \"AI Agent\"), you'd have Python code that:\n",
    "    1.  Parses the AI's \"Action\" (e.g., sees `Thought: I need to find the primary services provided by Kubernetes.`)\n",
    "    3.  Actually *executes* that lookup (e.g., queries a database or a web search API).\n",
    "    4.  Takes the result and feeds it back to the AI as the \"Observation.\"\n",
    "* **`f\"\"\"...\"\"\"` (f-string):** This is a convenient way in Python to build strings that include the values of variables. ` {react_few_shot_example}` and `{user_question_react}` insert the content of those variables into the main string.\n",
    "* **`\"role\": \"system\", \"content\": \"Answer questions using a ReAct format...\"`:** This system message is crucial. It explicitly tells the AI to use the Thought-Action-Observation pattern and even suggests a tool (`Lookup`).\n",
    "* **Prompt Engineering:** The way `react_prompt_for_user` is constructed is a simple example of **prompt engineering** – carefully crafting the input to the AI to guide it towards the desired output format and reasoning process. This is a critical skill when working with LLMs. You're essentially programming the AI through the instructions you give it.\n",
    "\n",
    "**Note on the ReAct Example Style:**\n",
    "* In the CoT example, the few-shot examples were part of the *system prompt*.\n",
    "* In this ReAct example, the few-shot example is passed along with the *user's question*.\n",
    "These are just different ways to structure the information for the AI. Experimenting with how you provide examples and instructions is part of prompt engineering. For Ops, consistency in how you format these prompts can be important for predictable AI behavior.\n",
    "\n",
    "The output from the ReAct cell shows the AI trying to break down the problem:\n",
    "1.  Identify it needs info on \"Colorado Orogeny\" and its \"Eastern Extension.\"\n",
    "2.  Propose `Action: Lookup(...)` for these.\n",
    "3.  (Simulated) `Observation:` gets facts about the orogeny.\n",
    "4.  Then it reasons it needs elevation data for specific states.\n",
    "5.  Proposes another `Action: Lookup(...)` for elevations.\n",
    "6.  (Simulated) `Observation:` gets elevation ranges.\n",
    "7.  Finally, it synthesizes this into an `Answer:`.\n",
    "\n",
    "This iterative process is what makes ReAct powerful for complex queries that require external knowledge or tool use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00695f9f",
   "metadata": {},
   "source": [
    "## Chain of Thought (CoT) vs. ReAct (Reasoning + Acting): A Comparison\n",
    "\n",
    "Here’s a summary to help you decide which approach might be better for different operational tasks.\n",
    "\n",
    "### Chain of Thought (CoT)\n",
    "\n",
    "* **What it is:** Purely a reasoning process. The AI \"thinks aloud\" step-by-step before giving an answer. It doesn't interact with external tools or live data sources on its own during this process.\n",
    "* **Analogy for Ops:** Like a senior engineer verbalizing their troubleshooting steps based on their existing knowledge and documentation they've already read, without actively querying a live system during that specific explanation.\n",
    "\n",
    "| Strengths                                                                | Limitations                                                                 |\n",
    "| :----------------------------------------------------------------------- | :-------------------------------------------------------------------------- |\n",
    "| Good for tasks requiring pure logical deduction (e.g., interpreting complex configuration logic, simple math, multi-step factual recall from its training data). | Cannot interact with external tools or live systems (e.g., can't check current server status, query a live database, or get real-time alerts). |\n",
    "| Relatively easy to implement; you're just asking the model to explain its reasoning. | Limited if the answer depends on up-to-the-minute data or information not in its training. |\n",
    "| Transparent: You can see the reasoning path, which helps in understanding and debugging the AI's output. | Not suitable for tasks requiring actions in the real world or data retrieval. |\n",
    "\n",
    "### ReAct (Reasoning + Acting)\n",
    "\n",
    "* **What it is:** Combines CoT-style reasoning with the ability to take **Actions** (like calling tools, performing web searches, or executing functions) and then incorporating the **Observations** (results of those actions) into its next thought process.\n",
    "* **Analogy for Ops:** Like an automated runbook or a sophisticated troubleshooting script. The system reasons what to check next (`Thought`), executes a command or API call to check it (`Action`), gets the result (`Observation`), and then decides the next step based on that new information.\n",
    "\n",
    "| Strengths                                                                 | Limitations                                                                  |\n",
    "| :------------------------------------------------------------------------ | :--------------------------------------------------------------------------- |\n",
    "| Excellent for building \"AI Agents\" that can interact with your environment (e.g., querying monitoring systems, interacting with ticketing systems, looking up internal documentation via an API). | More complex to implement. You need to build the \"tools\" the AI can call and the framework to handle the Action/Observation loop. |\n",
    "| Enables decision-making with dynamic, real-time data.                   | Debugging can be harder if the chain of thoughts and actions becomes very long or if tools produce unexpected results. |\n",
    "| You can integrate your own custom tools, scripts, and data sources (e.g., access a CMDB, query a log aggregation platform, interact with cloud provider APIs). | Requires careful design of available tools and permissions to ensure safety and prevent unintended actions. (Ops concern: security and control are paramount). |\n",
    "| Highly effective for Retrieval Augmented Generation (RAG) systems, where the AI first \"looks up\" relevant documents before answering a question. |                                                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044aae5",
   "metadata": {},
   "source": [
    "## Summary: Which to Choose?\n",
    "\n",
    "* **Use CoT when:**\n",
    "    * The problem can be solved by reasoning alone, based on the information the AI was trained on or information provided directly in the prompt.\n",
    "    * You need to understand the AI's thought process for a relatively self-contained task.\n",
    "    * Examples: Summarizing a provided text in detail, solving a logic puzzle, explaining a concept based on general knowledge.\n",
    "    * **Ops Example:** Asking an AI to explain the potential consequences of a specific configuration change, assuming it has been given the relevant documentation or context in the prompt.\n",
    "\n",
    "* **Use ReAct when:**\n",
    "    * The AI needs to interact with external systems, tools, or dynamic data sources to answer the question or complete a task.\n",
    "    * You are building an \"AI agent\" that needs to perform actions.\n",
    "    * The problem requires information gathering from multiple steps or sources.\n",
    "    * Examples: Answering \"What's the current weather in London?\" (needs a weather API), \"Summarize the latest critical alerts from our production environment\" (needs to query a monitoring system).\n",
    "    * **Ops Examples:**\n",
    "        * Building an AI assistant that can check the health of a service by querying its metrics endpoint.\n",
    "        * Creating an AI that can look up troubleshooting steps in an internal knowledge base when given an error code.\n",
    "        * Automating the initial information gathering steps for an incident ticket by having an AI query logs, metrics, and recent deployments.\n",
    "\n",
    "For many advanced Ops use cases where AI needs to interact with your infrastructure or internal data, **ReAct (or similar agent-based architectures)** will be the more powerful and practical approach. However, understanding CoT is a good foundation, as the \"Reasoning\" part of ReAct is essentially a Chain of Thought process.\n",
    "\n",
    "This notebook has shown simple, simulated examples. Building a robust ReAct system involves:\n",
    "1.  Defining the tools the AI can use.\n",
    "2.  Writing Python (or other language) functions that implement those tools.\n",
    "3.  Creating a loop that:\n",
    "    * Sends the prompt to the AI.\n",
    "    * Parses the AI's response to see if it wants to take an \"Action.\"\n",
    "    * If yes, executes the tool and gets the \"Observation.\"\n",
    "    * Feeds the \"Observation\" back to the AI for its next \"Thought.\"\n",
    "    * Repeats until the AI provides a final \"Answer.\"\n",
    "\n",
    "This area is rapidly evolving, with frameworks like LangChain and LlamaIndex providing higher-level tools to build such agentic systems. However, understanding these fundamental prompting techniques is key to effectively using and operationalizing LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcf4ef-93d7-4fe1-9997-c9fb475f8b1a",
   "metadata": {},
   "source": [
    "In the next Module we will move onto Tool Calling - a core underlying enabler of Agentic AI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
