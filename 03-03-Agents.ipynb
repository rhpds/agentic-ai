{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# Tools, API & Microservices\n",
    "\n",
    "Now that we have seen the power of prompts and a look how they come together in a simple agent, lets explore formally a few other concepts.\n",
    "\n",
    "1. Function calling\n",
    "2. Tool Calling\n",
    "3. Introduction to Agents\n",
    "4. Agents calling tools\n",
    "5. Agentic Patterns\n",
    "6. Agents and Microservices\n",
    "\n",
    "_Each module is typically dependent on the prior modules having been completed successfully_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bd7a3d-b43b-4bc2-91b0-b0a0403ea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "# import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "# from agents import Agent, ModelSettings, function_tool,Runner\n",
    "# from rich.pretty import pprint\n",
    "\n",
    "#model = \"phi4\"\n",
    "#model=\"mistral-small:latest\"\n",
    "# model = \"llama3.2:3b-instruct-fp16\"\n",
    "\n",
    "api_key = \"placeholder\" \n",
    "model = \"qwen3:32b\"\n",
    "base_url = \"http://localhost:11434/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b841d14-dc51-46a4-8bee-cfcecc4b122e",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "Agents are the heart of complex AI applications. They combine inference, memory, safety, and tool usage into coherent workflows. At its core, an agent follows a sophisticated execution loop that enables multi-step reasoning, tool usage, and safety checks.\n",
    "Ref: https://llama-stack.readthedocs.io/en/latest/building_applications/agent_execution_loop.html\n",
    "\n",
    "An Agentic-AI eco system is much larger than the LLM/s which it uses. While LLMs are being used, the agentic structure helps us to automate using those sophisticated prompts that we talked about.  The power of agentic AI is not only in the model, but in the orchestration—how you structure the workflow to get durable, repeatable outcomes without hand-holding.\n",
    "\n",
    "\n",
    "### Goal-Oriented Looping\n",
    "\n",
    "- A raw LLM gives one-shot answers. An agent keeps trying, planning multiple steps, checking for errors, adapting.\n",
    "- Think of it as: “Try → Check → Revise → Retry → Finish” or \"Thought → Action → Observation → Repeat → Answer\"\n",
    "- The loop itself enforces discipline and depth.\n",
    "- Without that structure, the LLM might shortcut the process.\n",
    "\n",
    "### Memory & Scratchpad\n",
    "\n",
    "Agents can keep track of:\n",
    "- What they’ve tried\n",
    "- What the intermediate results were\n",
    "- What the user originally wanted\n",
    "- LLM alone doesn’t track history or outcomes unless explicitly given.\n",
    "\n",
    "### Tool Use\n",
    "\n",
    "- Agents can call APIs, browse docs, or query databases. LLM alone hallucinates data. An agent says: “I don’t know—let me look it up.”\n",
    "\n",
    "### Decomposition\n",
    "\n",
    "- Agents break big tasks into smaller ones.\n",
    "- LLMs can do this, but often need a prompt to do so.\n",
    "- Agents automate that “thinking out loud.”\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d35782-20e8-430b-9b5d-e2fdc63cb5f6",
   "metadata": {},
   "source": [
    "## Agent calling tools\n",
    "1. Simply demonstrates an agent using a tool.\n",
    "1. Look at the brevity of the code compared to doing a function calling all on our own.\n",
    "1. Play with the question that can be asked to agent to see how it can handle questions that may or may not require the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74024ca-e0c2-43f2-ab80-7f068df322ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, ModelSettings, function_tool, Runner,AsyncOpenAI,OpenAIChatCompletionsModel\n",
    "\n",
    "# Configure the model\n",
    "# model = OpenAIChatCompletionsModel( \n",
    "#     model=\"qwen3:32b\",\n",
    "#     openai_client=AsyncOpenAI(base_url=\"http://localhost:11434/v1\",api_key = api_key)\n",
    "# )\n",
    "\n",
    "\n",
    "model = OpenAIChatCompletionsModel( \n",
    "    model=model,\n",
    "    openai_client=AsyncOpenAI(base_url=base_url, api_key=api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8930b6ed-c347-4d00-bcf6-eb8e43f28be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type OpenAIChatCompletionsModel is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[33m'\u001b[39m\u001b[33mcurrent\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtemperature_2m\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m agent = Agent(\n\u001b[32m     10\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mBlaster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mAnswer the question asked very precisely. Please think before answering\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     model= model,\n\u001b[32m     13\u001b[39m     tools=[get_weather],\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(agent, \u001b[33m\"\u001b[39m\u001b[33mwhich is warmer now: Paris or Manila?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.final_output)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#uncomment the line below to see the detailed interactions including automatic tool calling\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#pprint(result)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/agents/run.py:218\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    213\u001b[39m logger.debug(\n\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m )\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m    221\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    222\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    223\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    224\u001b[39m             context_wrapper,\n\u001b[32m    225\u001b[39m         ),\n\u001b[32m    226\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    227\u001b[39m             agent=current_agent,\n\u001b[32m    228\u001b[39m             all_tools=all_tools,\n\u001b[32m    229\u001b[39m             original_input=original_input,\n\u001b[32m    230\u001b[39m             generated_items=generated_items,\n\u001b[32m    231\u001b[39m             hooks=hooks,\n\u001b[32m    232\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    233\u001b[39m             run_config=run_config,\n\u001b[32m    234\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    235\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    236\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/agents/run.py:757\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    755\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    758\u001b[39m     agent,\n\u001b[32m    759\u001b[39m     system_prompt,\n\u001b[32m    760\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    761\u001b[39m     output_schema,\n\u001b[32m    762\u001b[39m     all_tools,\n\u001b[32m    763\u001b[39m     handoffs,\n\u001b[32m    764\u001b[39m     context_wrapper,\n\u001b[32m    765\u001b[39m     run_config,\n\u001b[32m    766\u001b[39m     tool_use_tracker,\n\u001b[32m    767\u001b[39m     previous_response_id,\n\u001b[32m    768\u001b[39m )\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    771\u001b[39m     agent=agent,\n\u001b[32m    772\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    781\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    782\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/agents/run.py:916\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    913\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    914\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    917\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    918\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    919\u001b[39m     model_settings=model_settings,\n\u001b[32m    920\u001b[39m     tools=all_tools,\n\u001b[32m    921\u001b[39m     output_schema=output_schema,\n\u001b[32m    922\u001b[39m     handoffs=handoffs,\n\u001b[32m    923\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    924\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    925\u001b[39m     ),\n\u001b[32m    926\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    927\u001b[39m )\n\u001b[32m    929\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/agents/models/openai_chatcompletions.py:61\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     47\u001b[39m     system_instructions: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     previous_response_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     55\u001b[39m ) -> ModelResponse:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n\u001b[32m     57\u001b[39m         model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n\u001b[32m     58\u001b[39m         model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n\u001b[32m     59\u001b[39m         disabled=tracing.is_disabled(),\n\u001b[32m     60\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     62\u001b[39m             system_instructions,\n\u001b[32m     63\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     64\u001b[39m             model_settings,\n\u001b[32m     65\u001b[39m             tools,\n\u001b[32m     66\u001b[39m             output_schema,\n\u001b[32m     67\u001b[39m             handoffs,\n\u001b[32m     68\u001b[39m             span_generation,\n\u001b[32m     69\u001b[39m             tracing,\n\u001b[32m     70\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     71\u001b[39m         )\n\u001b[32m     73\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     74\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mReceived model response\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/agents/models/openai_chatcompletions.py:239\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, span, tracing, stream)\u001b[39m\n\u001b[32m    233\u001b[39m store = ChatCmplHelpers.get_store_param(\u001b[38;5;28mself\u001b[39m._get_client(), model_settings)\n\u001b[32m    235\u001b[39m stream_options = ChatCmplHelpers.get_stream_options_param(\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_client(), model_settings, stream=stream\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_client().chat.completions.create(\n\u001b[32m    240\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    241\u001b[39m     messages=converted_messages,\n\u001b[32m    242\u001b[39m     tools=converted_tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    243\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    244\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    245\u001b[39m     frequency_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.frequency_penalty),\n\u001b[32m    246\u001b[39m     presence_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.presence_penalty),\n\u001b[32m    247\u001b[39m     max_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    248\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    249\u001b[39m     response_format=response_format,\n\u001b[32m    250\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    251\u001b[39m     stream=stream,\n\u001b[32m    252\u001b[39m     stream_options=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(stream_options),\n\u001b[32m    253\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(store),\n\u001b[32m    254\u001b[39m     reasoning_effort=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(reasoning_effort),\n\u001b[32m    255\u001b[39m     extra_headers={ **HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {}) },\n\u001b[32m    256\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    257\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    258\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    259\u001b[39m )\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, ChatCompletion):\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2028\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1985\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   2026\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2027\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2030\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2031\u001b[39m             {\n\u001b[32m   2032\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2033\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2034\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2035\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2036\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2037\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2038\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2039\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2040\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2041\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2042\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2043\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2044\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2045\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2046\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2047\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2048\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2049\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2050\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2051\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2052\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2053\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2054\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2055\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2056\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2057\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2059\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2060\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2061\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2062\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2063\u001b[39m             },\n\u001b[32m   2064\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2065\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2066\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2067\u001b[39m         ),\n\u001b[32m   2068\u001b[39m         options=make_request_options(\n\u001b[32m   2069\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2070\u001b[39m         ),\n\u001b[32m   2071\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2072\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2073\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2074\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/openai/_base_client.py:1473\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1470\u001b[39m options = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1472\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1476\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/openai/_base_client.py:535\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    532\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mextensions\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33msni_hostname\u001b[39m\u001b[33m\"\u001b[39m: prepared_url.host.replace(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)}\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# TODO: report this error to httpx\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore[reportUnknownMemberType]\u001b[39;49;00m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNotGiven\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `Query` type that we use is incompatible with qs'\u001b[39;49;00m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Params` type as it needs to be typed as `Mapping[str, object]`\u001b[39;49;00m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# so that passing a `TypedDict` doesn't cause an error.\u001b[39;49;00m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# https://github.com/microsoft/pyright/issues/3526#event-6715453066\u001b[39;49;00m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstringify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_given\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/httpx/_client.py:378\u001b[39m, in \u001b[36mBaseClient.build_request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, timeout, extensions)\u001b[39m\n\u001b[32m    372\u001b[39m     timeout = (\n\u001b[32m    373\u001b[39m         \u001b[38;5;28mself\u001b[39m.timeout\n\u001b[32m    374\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, UseClientDefault)\n\u001b[32m    375\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m Timeout(timeout)\n\u001b[32m    376\u001b[39m     )\n\u001b[32m    377\u001b[39m     extensions = \u001b[38;5;28mdict\u001b[39m(**extensions, timeout=timeout.as_dict())\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/httpx/_models.py:408\u001b[39m, in \u001b[36mRequest.__init__\u001b[39m\u001b[34m(self, method, url, params, headers, cookies, content, data, files, json, stream, extensions)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     content_type: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mself\u001b[39m.headers.get(\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     headers, stream = \u001b[43mencode_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_multipart_boundary_from_content_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare(headers)\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/httpx/_content.py:216\u001b[39m, in \u001b[36mencode_request\u001b[39m\u001b[34m(content, data, files, json, boundary)\u001b[39m\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_urlencoded_data(data)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {}, ByteStream(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages/httpx/_content.py:177\u001b[39m, in \u001b[36mencode_json\u001b[39m\u001b[34m(json)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_json\u001b[39m(json: Any) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], ByteStream]:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     body = \u001b[43mjson_dumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m     content_length = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(body))\n\u001b[32m    181\u001b[39m     content_type = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type OpenAIChatCompletionsModel is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# from agents import Agent, ModelSettings, function_tool, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
    "\n",
    "@function_tool\n",
    "def get_weather(latitude:str, longitude:str) ->str:\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Blaster\",\n",
    "    instructions=\"Answer the question asked very precisely. Please think before answering\",\n",
    "    model= model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"which is warmer now: Paris or Manila?\")\n",
    "print(result.final_output)\n",
    "#uncomment the line below to see the detailed interactions including automatic tool calling\n",
    "#pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077ab16-b9e5-4699-a46e-6b64278cbda4",
   "metadata": {},
   "source": [
    "# Tools\n",
    "- We are definining tools with an adornment here.\n",
    "- MCP Servers are formalizing this much more and everyone is adopting this.\n",
    "- This is covered in another lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ee407-2c3e-4f48-8f28-9110ba975f01",
   "metadata": {},
   "source": [
    "# Agentic Patterns\n",
    "\n",
    "\n",
    "We explore below 3 agentic paradigms which are widely used\n",
    "\n",
    "1. Agents collaborating with each other to improve the quality of the output\n",
    "   ![Collaboration Pattern](resources/images/agent_collaborate.png)\n",
    "3. Agents routing traffic to the correct agent\n",
    "   ![pattern-1](resources/images/agent_supervisor_pattern.png)  \n",
    "   ![pattern-2](resources/images/agent_hierarchical.png) \n",
    "5. Agents running a workflow\n",
    "   ![Workflow Pattern](resources/images/agent_plan_execute.png)\n",
    "\n",
    "There are other agentic patterns as well which we do not cover here. But these basic concepts should help adopting other patterns much simpler.\n",
    "\n",
    "_The graphics have been used from [langraph tutorial](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c11e8b-6396-499b-abec-a8b674bdf312",
   "metadata": {},
   "source": [
    "## Agents Collaborating\n",
    "1. Simply demonstrates an agent reviewing the work of another agent - much like a human being.\n",
    "1. This is one of the primary reasons while the agents can help increase accuracty of the answer and smaller models using agents can outperform larger models without agents.\n",
    "1. This pattern can be used in lots of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e676d7f-a94f-4add-84e2-e7d8074bfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows the agents collaborating or one agent reveiwing the work of another and giving feedback. \n",
    "The first agent generates an outline for a story.\n",
    "The second agent judges the outline and provides feedback. \n",
    "We loop until the judge is satisfied with the outline.\n",
    "\"\"\"\n",
    "\n",
    "story_outline_generator = Agent(\n",
    "    name=\"story_outline_generator\",\n",
    "    instructions=(\n",
    "        \"You generate a very short story outline based on the user's input.\"\n",
    "        \"If there is any feedback provided, use it to improve the outline.\"\n",
    "    ),\n",
    "    model= model,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvaluationFeedback:\n",
    "    feedback: str\n",
    "    score: Literal[\"pass\", \"needs_improvement\", \"fail\"]\n",
    "\n",
    "\n",
    "evaluator = Agent(\n",
    "    name=\"evaluator\",\n",
    "    instructions=(\n",
    "        \"You evaluate a story outline and decide if it's good enough.\"\n",
    "        \"If it's not good enough, you provide feedback on what needs to be improved.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=EvaluationFeedback,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4743ed-e4a6-4bb3-9a6c-22df7787f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What kind of story would you like to hear?  about a cloud day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story outline generated\n",
      "Evaluator score: needs_improvement\n",
      "Re-running with feedback\n",
      "Story outline generated\n",
      "Evaluator score: fail\n",
      "Re-running with feedback\n",
      "Story outline generated\n",
      "Evaluator score: fail\n",
      "Maximum number of iterations exceeded, exiting.\n",
      "Final story outline: <think>\n",
      "Okay, so the user wants me to refine the story outline further, especially focusing on the sibling dynamics. Let me start by reviewing the previous feedback and what's already been done. The latest outline from the assistant included a subplot where Lila and her brother Leo have a strained relationship due to an accident. They reconcile by combining their different approaches to the clouds.\n",
      "\n",
      "The user's feedback says the revised outline is good but suggests adding more to the sibling dynamic for emotional stakes. The user mentions that the siblings' conflict and reconciliation are strong, but there's room to delve deeper. Maybe they want more specific instances where their relationship impacts the plot and their internal growth.\n",
      "\n",
      "I need to think about how to weave their interactions into key plot points. For example, maybe Leo's injury isn't just a backstory event but plays a role in their journey. Perhaps Lila feels guilty, and that guilt drives some of her actions, while Leo feels responsible for holding her back. Their teamwork could mirror the theme of merging old and new—Leo's traditional methods vs. Lila's creative intuition.\n",
      "\n",
      "Also, considering emotional beats—maybe a scene where Lila helps Leo overcome his fear of the clouds, symbolizing their reconciliation. The resolution could have them each making sacrifices, showing their growth. For instance, maybe Lila has to let go of her need for answers, and Leo has to embrace change, strengthening their bond.\n",
      "\n",
      "I should also tie their personal journey to the town's theme. Their reconciliation could be the key to restoring balance, showing that harmony in their family leads to harmony in the town. Maybe the ritual requires both their strengths, symbolically uniting tradition and progress.\n",
      "\n",
      "I need to add specific details about their interactions, maybe a shared memory or a moment of vulnerability. The conflict should be resolved through their combined efforts, highlighting their unity. The assistant should ensure that their relationship isn435;t just a subplot but integral to the main conflict.\n",
      "\n",
      "Including elements like their shared notebook, which Leo might have previously dismissed, becoming a bridge between them. Or Leo using his knowledge of the mill to complement Lila's cloud-reading. Their dialogue should reflect their growth—Leo becoming more open to her perspective, and Lila learning to respect structure.\n",
      "\n",
      "The resolution should show how their bond affects the outcome, perhaps their combined action is necessary to perform the ritual. Maybe Leo's physical sacrifice or Lila's emotional release triggers the healing of the Veil. The ending could have them parting ways but connected by their shared experience, echoing the story's central theme.\n",
      "</think>\n",
      "\n",
      "**Final Refined Outline: *The Day the Sky Held Its Breath***  \n",
      "\n",
      "**Setting:** A mist-shrouded town where cloud-shapes dictate harvest cycles, marriage rites, and even political alliances. The elders consult \"Cloud Whispers\" to decide when to trade, build, or mourn. Recent industrial changes (like the new mill) have strained this balance, creating tension between tradition and progress.  \n",
      "\n",
      "**Protagonist:** Lila, 12, whose sketches of clouds are dismissed as childish fancy by her pragmatic elder brother, Leo, 15. Their strained dynamic stems from an accident during which Leo, as an apprentice weather-predictor, nearly died chasing a \"rogue cloud trail\" while Lila insisted the clouds looked like a warning. Guilt haunts both: Leo resents Lila’s \"foolishness\"; Lila blames herself for not being taken seriously.  \n",
      "\n",
      "**Subplot: Sibling Dynamic**  \n",
      "- **Conflict:** Their differing worldviews clash: Leo adheres to ancestral rituals and logic; Lila believes the clouds *need* to change with the times. A key scene shows Leo destroying one of Lila’s notebooks (filled with cloud patterns he dismisses as \"nonsense\"), triggering her to vow to prove him wrong.  \n",
      "- **Catalyst:** After Leo’s accident, their mother urges him to guard their bond: “Clouds shift, but the sky holds because the storms balance each other.” This memory haunts Leo as he and Lila unravel the mystery.  \n",
      "- **Growth Arcs:**  \n",
      "  - **Leo** learns to trust Lila’s intuitive “seeing” during the ritual, recognizing her sketches as the missing key to the ritual.  \n",
      "  - **Lila** grows to respect Leo’s wisdom, using his knowledge of the old rites to stabilize the mill’s machinery.  \n",
      "- **Emotional Beats:**  \n",
      "  - A silent, wordless moment in the cavern where Lila traces his calloused hands, and Leo lets her—a symbol of trust.  \n",
      "  - The final sacrifice: Lila must let go of her need to “control” the clouds, while Leo accepts that some mysteries require more than rules.  \n",
      "\n",
      "**Plot Enhancements:**  \n",
      "- **Clouds as Daily Influence:** The town’s river-dwellers row only when a “bridge cloud” forms overhead, believing it ensures safe passage. Now, with the clouds frozen, the river is stagnant, and families argue over whether to follow the old ways or risk rebellion.  \n",
      "- **The Mill’s Role:** Lila’s idea to use the mill isn’t just pragmatic—it’s symbolic. The mill, a relic of modernity, is repurposed using Leo’s tools to channel energy into the cavern, merging his ancestral knowledge with her modern thinking.  \n",
      "- **The Cloud Veil’s Message:** The frozen shapes are not a warning but a plea—the clouds wanted the town to *listen*, not just obey. Lila realizes the ritual should be a dialogue, not an act of submission.  \n",
      "\n",
      "**Climax & Resolution:**  \n",
      "- **Ritual:** To save the weather-predictor and the town, Lila sketches a new cloud formation (a spiral, symbolizing unity) while Leo plays the old cloud-trance chants through the mill’s gears, syncing them to the cavern’s hum. The Veil opens, and the weather-predictor is freed—but only because they offered *dialogue* (Lila’s sketch) and *tradition* (Leo’s chant).  \n",
      "- **Aftermath:** The town forgets the crisis, but their traditions subtly shift: elders begin sketching clouds in their ledgers; the mill is rebuilt with “listening holes” in the walls, and Lila/Leo part ways.  \n",
      "- **Final Image:** Leo, now a craftsman, etches a spiral into the mill’s gears. Lila, traveling alone, opens her notebook to a newly glowing sketch: the bridge cloud. The camera pans to the sky, where a single cloud begins shifting.  \n",
      "\n",
      "**Thematic Consequences:**  \n",
      "- **The Town:** Their future balances innovation and reverence (e.g., the mill’s new design respects wind patterns).  \n",
      "- **The Siblings:** Their bond remains unspoken but sacred. Leo’s spiral etchings and Lila’s glowing sketch suggest the Veil is now permeable—mysteries endure, but they’re met with curiosity, not fear.  \n",
      "- **The Clouds:** No longer just “messengers”—they’re partners, and the town’s willingness to evolve ensures their presence remains.  \n",
      "\n",
      "**Theme:** True harmony lies in embracing change while honoring the roots that sustain it. Relationships—like ecosystems—flourish when they balance structure and intuition.  \n",
      "\n",
      "Let me know if you'd like to refine the sibling dynamics further or expand on specific scenes!\n"
     ]
    }
   ],
   "source": [
    "msg = input(\"What kind of story would you like to hear? \")\n",
    "input_items: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "latest_outline: str | None = None\n",
    "\n",
    "with trace(\"Collaboration\"):\n",
    "        i = 0\n",
    "        while True:\n",
    "            story_outline_result = await Runner.run(\n",
    "                story_outline_generator,\n",
    "                input_items,\n",
    "            )\n",
    "\n",
    "            input_items = story_outline_result.to_input_list()\n",
    "            latest_outline = ItemHelpers.text_message_outputs(story_outline_result.new_items)\n",
    "            print(\"Story outline generated\")\n",
    "\n",
    "            evaluator_result = await Runner.run(evaluator, input_items)\n",
    "            result: EvaluationFeedback = evaluator_result.final_output\n",
    "\n",
    "            print(f\"Evaluator score: {result.score}\")\n",
    "\n",
    "            if result.score == \"pass\":\n",
    "                print(\"Story outline is good enough, exiting.\")\n",
    "                break\n",
    "            if i == 2:\n",
    "                print(\"Maximum number of iterations exceeded, exiting.\")\n",
    "                break\n",
    "            print(\"Re-running with feedback\")\n",
    "\n",
    "            input_items.append({\"content\": f\"Feedback: {result.feedback}\", \"role\": \"user\"})\n",
    "            i += 1\n",
    "\n",
    "print(f\"Final story outline: {latest_outline}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af63f69-2d06-40f9-9fa5-cc490cf11768",
   "metadata": {},
   "source": [
    "## Agents routing\n",
    "1. Simply demonstrates an agent routing work to other agents.\n",
    "1. This is a very common agentic pattern.\n",
    "1. Ask the question in German and see what happens! In real life when we use a routing pattern, we must have a fallback agent that gracefully handles all things unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa28f4d9-5ab4-41f8-8658-ece1d3e31de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "\n",
    "#from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows the handoffs/routing pattern. The triage agent receives the first message, and\n",
    "then hands off to the appropriate agent based on the language of the request. Responses are\n",
    "streamed to the user.\n",
    "\"\"\"\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You only speak French\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English. Answer the question you recieved.\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "# experiment by removing  from the instructions the sentence below.\n",
    "#So answer in English even if you understand the language that is being used.\n",
    "#And then ask say (German) : Wie geht es dir\n",
    "know_all_agent = Agent(\n",
    "    name=\"know_all_agent\",\n",
    "    instructions=\"You only speak English. So answer in English even if you understand the language that is being used. \\\n",
    "        State that you do not understand the user question and ask them to repeat it one of the languages you understand. \\\n",
    "        Those languages are English, French and Spanish .\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request. If you do not know what to do, hand if off to know_all.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent, know_all_agent],\n",
    "    model = model,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bbe4d0-3806-4b29-9f28-6e10361abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi! We speak French, Spanish and English. How can I help?  mon ami Hastings!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "<think>\n",
      "Okay, the user called out \"mon ami Hastings!\" which is French for \"my friend Hastings!\" So they're addressing someone named Hastings in French. The previous message had an assistant transferring to a French agent. Now, I need to respond in French.\n",
      "\n",
      "First, I should greet them back in French. Since they used \"mon ami,\" I can reply with \"Bonjour, mon ami Hastings!\" to be friendly. Then, maybe offer help. The user might need assistance with something in French. I can ask, \"Comment puis-je vous aider aujourd'hui ?\" which means \"How can I assist you today?\" That should be polite and open for them to ask anything. \n",
      "\n",
      "I need to make sure the response is all in French and friendly. Also, check for any typos. Let me put it all together.\n",
      "</think>\n",
      "\n",
      "Bonjour, mon ami Hastings ! Comment puis-je vous aider aujourd'hui ? 😊\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "<think>\n",
      "Okay, the user wrote \"monami Hastings!\" in French. Let me check if that's a name or a phrase.\n",
      "\n",
      "\"Monami\" isn't a standard French word. Maybe they meant \"mon ami\" which is \"my friend\". But \"Hastings\" is likely the last name from the TV show \"Bridgerton\". So, the user might be referring to the character Hastings from the show. \n",
      "\n",
      "I need to acknowledge the greeting. Since \"monami\" could be a misspelling, I'll respond in a friendly way, assuming they're addressing me as Hastings. I should keep the reply in French and offer help. \n",
      "\n",
      "Make sure to keep the response simple and welcoming, confirming understanding and offering assistance. Avoid any complex structures since the user might be learning.\n",
      "</think>\n",
      "\n",
      "Bonjour! Je suis Hastings. Comment puis-je vous aider aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "with trace(\"Router\"):\n",
    "    story_outline_result = await Runner.run(triage_agent,inputs)\n",
    "    #uncomment this to see the details\n",
    "    #pprint(story_outline_result)\n",
    "    print(\"--------------------------\")\n",
    "    print(story_outline_result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660bec5-d54d-473f-9f03-0604120fdbd1",
   "metadata": {},
   "source": [
    "## Agents Deterministic Workflow\n",
    "1. Simply demonstrates agents calling other agents to complete a well defined workflow.\n",
    "1. This is a very common agentic pattern.\n",
    "1. This pattern or its variants can be put to lot of practical use and it could be combined with the collaborative pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef7aa00-e4b1-4b50-ba19-c428c6dbb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows how different agents are used to compelete a deterministic workflow.\n",
    "In this case it is: \n",
    "planner agent -> writer agent -> editor agent \n",
    "Given an essay topic, the essay moves through these stages to finally produce an output.\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Planner:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Writer:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Editor:\n",
    "    body: str\n",
    "\n",
    "\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"planner_agent\",\n",
    "    instructions=(\n",
    "        \"Take a user's theme/topic request.\"\n",
    "        \"Create a brief outline of the essay with points that need to be covered.\"\n",
    "        \"Make sure that references are given to actual source materials.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Planner,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"writer_agent\",\n",
    "    instructions=(\n",
    "        \"Take the outline given in the input.\"\n",
    "        \"Expands it into a complete essay.\"\n",
    "        \"Give adequate references and make sure things are not made up!\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Writer,\n",
    ")\n",
    "\n",
    "editor_agent = Agent(\n",
    "    name=\"editor_agent\",\n",
    "    instructions=(\n",
    "        \"You Review the draft given in the input.\"\n",
    "        \"Polish the language, fixes inconsistencies, and improve the flow.\"\n",
    "        \"And make sure it is logical coherent.\"\n",
    "        \"Give adequate references and make sure things are not made up!\"\n",
    "        \"Return the final story to the user.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Editor,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c2656ad-540c-4049-892e-a0dde674962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi! I am AI Researcher. Give me any topic and I will write a well researched essay about it.  History of agents in AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Planner Output----------\n",
      "Sure, I can help with developing an essay outline on the history of agents in AI. An agent, in the context of artificial intelligence, is any entity that perceives its environment through sensors and acts upon it through actuators to achieve a goal effectively. Here's an outline you could follow, along with some points and references:\n",
      "\n",
      "### Essay Title: The Evolution of Agents in Artificial Intelligence\n",
      "\n",
      "#### I. Introduction\n",
      "   - Definition of an intelligent agent.\n",
      "   - Importance of agents in the field of AI.\n",
      "   - Brief overview of the historical progression of AI agents (from rule-based systems to modern AI).\n",
      "   - References: [Russell & Norvig, 2003] [Nilsson, 2009]\n",
      "\n",
      "#### II. Early Foundations of AI Agents\n",
      "   - The concept of thinking machines: Alan Turing's \"Computing Machinery and Intelligence\" (1950) introducing the Turing Test.\n",
      "   - Early rule-based systems like Newell and Simon's General Problem Solver (GPS) from 1959.\n",
      "   - The emergence of logic programming in the 1970s with Prolog, which laid the ground for reasoning in agents.\n",
      "   - References: [Turing, 1950] [Newell & Simon, 1959] [Kowalski, 1979]\n",
      "\n",
      "#### III. The Rise of Symbolic AI and Autonomous Agents\n",
      "   - The focus on symbolic AI during the 1970s and 1980s, which relied on knowledge-based systems and expert systems.\n",
      "   - Introduction of autonomous agents in the 1980s, as demonstrated by Maes's work on BDI agents (Belief-Desire-Intention agents) and the development of agent-based architectures.\n",
      "   - Early multi-agent systems like Jennings' work in 1993 exploring cooperative and competitive behaviors among agents.\n",
      "   - References: [Newell & Simon, 1972] [Maes, 1989] [Jennings, 1993]\n",
      "\n",
      "#### IV. Emergence of Learning Agents and Machine Learning Integration\n",
      "   - In the 1990s and early 2000s, the integration of machine learning into agents allowed for the development of learning agents that could adapt to new information.\n",
      "   - Reinforcement learning techniques were introduced to train agents to make decisions under uncertainty, such as in the case of Deep Q-Networks (DQN) later on.\n",
      "   - The transition from hard-coded behaviors to learned ones marked a significant shift in agent design.\n",
      "   - References: [Sutton & Barto, 1998] [Mnih et al., 2015]\n",
      "\n",
      "#### V. The Modern Era: Intelligent, Autonomous, and Collaborative Agents\n",
      "   - Development of intelligent agents capable of natural language processing, computer vision, and other perception tasks.\n",
      "   - Application of agents in robotics, digital assistants, autonomous vehicles, and game AI.\n",
      "   - Emergence of collaborative and swarm agents in complex problem-solving scenarios and large-scale simulations.\n",
      "   - References: [Russell & Norvig, 2010] [LeCun et al., 2015] [Goodfellow et al., 2016]\n",
      "\n",
      "#### VI. Challenges and Future Directions in Agent Technology\n",
      "   - Ethical considerations: accountability, transparency, and explainability of agents.\n",
      "   - Scalability of multi-agent systems and interoperability in decentralized environments.\n",
      "   - Integration of agents with the Internet of Things (IoT) and edge computing technologies.\n",
      "   - Future research in cognitive agents, emotional intelligence, and human-centric AI interactions.\n",
      "   - References: [Floridi, 2015] [Brundage et al., 2018] [Russell, 2021]\n",
      "\n",
      "\n",
      "### Conclusion\n",
      "   - Summary of the journey from early rule-based agents to modern intelligent, autonomous agents.\n",
      "   - Reflection on the impact of agent technology across different domains.\n",
      "   - Outlook on the future potential of agents in AI and their societal implications.\n",
      "\n",
      "### References\n",
      "- Russell, S. J., & Norvig, P. (2003). Artificial Intelligence: A Modern Approach.\n",
      "- Nilsson, N. J. (2009). The Physical Symbol System Hypothesis.\n",
      "- Kowalski, R. A. (1979). Logic for Problem Solving.\n",
      "- Jennings, N. R. (1993). An Agent-Based Approach for Building Complex Software Systems.\n",
      "- Sutton, R. S., & Barto, A. G. (1998). Introduction to Reinforcement Learning.\n",
      "- Mnih, V., et al. (2015). Human-Level Control Through Deep Reinforcement Learning.\n",
      "\n",
      "**Note**: The references above may be actual sources but may require you to look up their full citations and ensure they are accurate for your essay. For academic writing, it's imperative to verify the correct editions, publication sources, etc., for the citations provided.\n",
      "----------Writer Output----------\n",
      "Okay, the user wants me to expand the given essay outline into a complete essay. They provided a detailed outline with sections on the history of agents in AI. First, I need to make sure I understand each section and the key points mentioned. The title is about the evolution of AI agents, so the essay should follow a chronological structure, starting from early foundations to modern applications and future directions. The user also emphasized using accurate references and not making things up, so I need to be careful with the citations and ensure they are correctly applied to the content. Let me start by outlining each section and filling in the details based on the outline points. For example, the introduction needs to define an intelligent agent and its importance. Then, each historical section should highlight major developments and key figures. I'll need to connect the eras to show progression. I should also check that the references mentioned in the outline are properly integrated into the discussion. Since the user provided specific references by authors and years, I'll need to ensure those are included in the essay and cited correctly. Maybe use footnotes or a reference list at the end, but the user mentioned references in the outline, so I should follow that structure. Also, in the conclusion, summarize the journey and reflect on the impact and future. I should avoid any technical inaccuracies and stick to what's in the outline. Let me go through each section one by one, elaborate the points, and maintain a logical flow. Ensure that each part transitions smoothly into the next, showing the evolution over time. Also, check for any gaps in the outline and fill them with logical connections between the developments mentioned. The user included specific technologies like Deep Q-Networks, so I need to explain those correctly. Make sure the essay is comprehensive but concise, as per the outline's structure. Finally, review the essay to ensure all references are correctly cited and the information aligns with the provided sources. Avoid any markdown formatting and keep the language clear and academic. Alright, let's start drafting each section with detailed explanations and proper citations.\n",
      "----------Editor Output----------\n",
      "Okay, the user wants me to expand the given essay outline into a complete essay. They provided a detailed outline with sections on the history of agents in AI. First, I need to make sure I understand each section and the key points mentioned. The title is about the evolution of AI agents, so the essay should follow a chronological structure, starting from early foundations to modern applications and future directions. The user also emphasized using accurate references and not making things up, so I need to be careful with the citations and ensure they are correctly applied to the content. Let me start by outlining each section and filling in the details based on the outline points. For example, the introduction needs to define an intelligent agent and its importance. Then, each historical section should highlight major developments and key figures. I'll need to connect the eras to show progression. I Should also check that the references mentioned in the outline are properly integrated into the discussion. Since the user provided specific references by authors and years, I'll need to ensure those are included in the essay and cited correctly. Maybe use footnotes or a reference list at the end, but the user mentioned references in the outline, so I should follow that structure. Also, in the conclusion, summarize the journey and reflect on the impact and future. I should avoid any technical inaccuracies and stick to what's in the outline. Let me go through each section one by one, elaborate the points, and maintain a logical flow. Ensure that each part transitions smoothly into the next, showing the evolution over time. Also, check for any gaps in the outline and fill them with logical connections between the developments mentioned. The user included specific technologies like Deep Q-Networks, so I need to explain those correctly. Make sure the essay is comprehensive but concise, as per the outline's structure. Finally, review the essay to ensure all references are correctly cited and the information aligns with the provided sources. Avoid any markdown formatting and keep the language clear and academic. Alright, let me start drafting each section with detailed explanations and proper citations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Planner Output----------\n",
      "Sure!  Creating an essay on the concept of agents in artificial intelligence through time involves tracing the evolution from early theoretical ideas to modern-day autonomous systems. Here’s a brief outline you can follow, including the key points and references to source materials.\n",
      "----------Writer Output----------\n",
      "Okay, the user wants me to take the outline they provided and turn it into a complete essay about the concept of agents in AI over time. They also want references and accurate information. Let me start by understanding the outline they mentioned. The outline includes tracing the evolution from early theories to modern autonomous systems. They probably expect sections on different time periods or key developments, such as classical AI, reactive agents, utility-based agents, learning agents, multi-agent systems, and maybe ethical or future considerations. They mentioned John McCarthy, Russell and Norvig, and maybe some other researchers like Minsky or Newell. I need to make sure each section has enough detail, connects the progression, and cites reliable sources. Let me recall the key papers and books. McCarthy's work in the 1950s, the 1995 Russell and Norvig book on rational agents, the 1980s expert systems, the 1990s DART papers by Wooldridge and Jennings on agent-based systems, and recent work like reinforcement learning and ethics frameworks. I need to check if the user wants specific references or just general ones. The example response they provided uses specific paper titles and years, so I should follow that. Also, make sure to mention how the definition of agents expanded over time—maybe starting with Turing's imitation game as an early concept. Wait, Turing is more about the Turing test, which relates to intelligence, but agents are a bit different. Maybe start with the 1950s and McCarthy's advice taker, which is a classic example. Then move to the 1980s with expert systems and the shift to more autonomous agents. The 1995 Russell and Norvig book is a pivotal point. Then mention the development of different architectures: reactive, utility-based, learning. Then multi-agent systems in the 2000s with Wooldridge. Finally, modern applications like Roomba, AlphaGo, and ethical considerations from Bostrom's 2014 and European Commission guidelines. Need to ensure the flow is logical and each section builds on the previous. Also, check that all references are correctly cited with authors, year, and publication. Avoid introducing fictional papers. Make sure the conclusion ties it all together, highlighting the evolution and current state. The user wants references, so maybe include in-text citations with (Author, Year) and a reference list at the end. Let me structure each section with a date range, key concepts, notable systems, and citations. Need to mention that agents are entities that act autonomously to achieve goals, and how the concept evolved from symbolic AI to machine learning-based approaches. Also, touch on the transition from single agents to multi-agent systems and collaboration. The user might expect a discussion on the impact of machine learning and reinforcement learning in modern agents, like DeepMind's work. Make sure to explain each type of agent architecture clearly. Check if all the points in the outline are covered and expand them into a coherent essay. Avoid technical jargon where possible to keep it accessible. Also, ensure that the essay is comprehensive but concise, covering all the key milestones in the development of AI agents over time. Let me start drafting the first section on theoretical foundations, then move through each historical phase, and conclude with future directions. Double-check all sources and ensure accuracy. Maybe list the references in APA format at the end as in the example. That should cover it.\n",
      "----------Editor Output----------\n",
      "Sure, I'd be happy to help you refine your essay outline into a well-structured, coherent narrative with accurate references and logical flow. Here's a comprehensive and academically rigorous essay on the evolution of artificial intelligence agents across computational history:\n",
      "\n",
      "---\n",
      "\n",
      "# The Evolution of Artificial Intelligence Agents: From Theoretical Foundations to Autonomous Systems\n",
      "\n",
      "## Introduction\n",
      "The concept of an \"agent\" in artificial intelligence can be traced back to Alan Turing's 1950 work on computability and his seminal 1950 paper \"Computing Machinery and Intelligence\" that introduced the Turing Test (Turing, 1950). However, the formal definition of rational agents emerged in the 1990s with Stuart Russell and Peter Norvig's influential *Artificial Intelligence: A Modern Approach* (1995), which established the foundational framework still used today. As AI research progressed, the definition of agents expanded from simple rule-following programs to sophisticated adaptive systems capable of perception, learning, and autonomous decision-making.\n",
      "\n",
      "## Theoretical Foundations\n",
      "The concept of agents as goal-oriented entities was first formally articulated in 1991 with the publication of \"Rationality and the Logic of Decision\" by Fagin, Halpern, Moses, and Vardi, who developed formal models for rational decision-making (Fagin et al., 1995). Around the same time, the \"Architecture for Intention-Based Rational Agents\" paper by Pollack (1990) introduced the BDI (Belief-Desire-Intention) model, which remains widely used in cognitive architectures (Wooldridge, 2009). These theoretical underpinnings helped differentiate AI agents from traditional computational models by focusing on intentionality, goal-directed behavior, and the ability to represent world knowledge.\n",
      "\n",
      "## Early AI Agents and Symbolic Programming\n",
      "In the 1950s-1970s, early AI agents existed primarily as rule-based programs within expert systems frameworks. Marvin Minsky's 1956 Logic Theorist program is often considered the first AI system to demonstrate autonomous problem-solving capabilities (Minsky, 1956). These systems relied on hand-crafted knowledge bases and logic programming, as seen in Newell and Simon's General Problem Solver (1972). While rudimentary, these systems embodied the core agent principle of acting in an environment to achieve goals - albeit with limited perceptual and adaptive capabilities.\n",
      "\n",
      "## Reactive and Utility-Based Agents\n",
      "The limitations of purely symbolic AI led to significant developments in the 1980s and 1990s. Brooks' 1986 \"A Robotic Architecture Based on Extending Reactivity\" introduced the concept of reactive agents capable of real-time perceptual processing without complex internal representations (Brooks, 1986). Concurrently, work by Nilsson and others established utility-based agent models that integrated probabilistic decision theory (Nilsson, 1986). These frameworks formed the basis for more sophisticated architectures, combining reactiveness with goal-oriented planning.\n",
      "\n",
      "## Learning Agents and the Rise of Machine Learning\n",
      "The 1995 publication of Russell and Norvig's *Artificial Intelligence: A Modern Approach* (2003, 3rd ed.) marked a paradigm shift toward intelligent agents that could learn from experience. This aligns with the reinforcement learning frameworks developed by Sutton and Barto (1998), who demonstrated how agents could optimize behavior through trial and error. The 2005 paper \"Learning to Predict by the Methods of Temporal Differences\" extended these principles to complex environments, while AlphaGo (Silver et al., 2016) exemplified this evolution in practice, showcasing agents that could master tasks through self-learning.\n",
      "\n",
      "## Multi-Agent Systems and Game Theory\n",
      "The 1990s and 2000s saw exponential growth in multi-agent research, driven by applications in economics, game theory, and distributed systems. The landmark \"Intelligent Software Agents and Their Applications\" paper by Kautz and Selman (1996) formalized the study of agent interactions. Subsequent work by Stone, Kraus, and others (2005) developed coordination models for competitive and cooperative settings, leading to breakthroughs in negotiation systems and distributed problem-solving. The 2010 DARPA Robotics Challenge further highlighted the practical potential of coordinated multi-agent systems in real-world environments.\n",
      "\n",
      "## Modern Autonomous Agents\n",
      "Contemporary AI agents reflect the integration of multiple paradigms. DeepMind's Roomba (1999) marked an early consumer application of autonomous agents, while Amazon's Alexa (2014) demonstrated embodied conversational agents at scale. The emergence of self-driving cars, exemplified by Waymo's systems (2004-present), and financial trading algorithms represents the application of sophisticated reinforcement learning frameworks. Recent work by Russell (2019) expands the concept to include robustness, transparency, and value alignment, reflecting growing ethical considerations in agent design.\n",
      "\n",
      "## Ethical and Philosophical Considerations\n",
      "The rise of advanced AI agents has triggered significant ethical debates. Bostrom's *Superintelligence* (2014) raised critical concerns about long-term risks, while Levesque's 2001 \"Is a Turing Test a Good Idea?\" questioned existing evaluation criteria for agency. The European Commission's 2019 Ethics Guidelines for Trustworthy AI and the IEEE's *Ethically Aligned Design* framework represent key institutional responses. Contemporary researchers increasingly focus on developing value-aligned agents that reflect democratic values while maintaining technical performance.\n",
      "\n",
      "## The Future of AI Agents\n",
      "Current research is focused on developing agents with greater common sense reasoning, social intelligence, and physical embodiment. Advances in large language models like GPT-3 have introduced new agent capabilities, though significant challenges remain in embodied cognition and long-term value alignment. The integration of AI agents into healthcare monitoring, smart infrastructure, and planetary defense systems suggests a trajectory toward increasingly complex and socially integrated autonomous systems.\n",
      "\n",
      "---\n",
      "\n",
      "# References\n",
      "- Bostrom, N. (2014). *Superintelligence: Paths, Dangers, Strategies*. Oxford University Press.\n",
      "- Brooks, R. A. (1986). A Robotic Architecture Based on Extending Reactivity. MIT AI Lab Memo.\n",
      "- European Commission. (2019). Ethics Guidelines for Trustworthy AI. \n",
      "- Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). *Reasoning About Knowledge*. MIT Press.\n",
      "- Kautz, H., & Selman, B. (1996). Intelligent Software Agents and Their Applications. *Communications of the ACM*, 27-30.\n",
      "- Levesque, H. J. (2001). Is a Turing Test a Good Idea? In *Proceedings of the 5th and 6th Symposium on Artificial Intelligence and Mathematics*.\n",
      "- Minsky, M. L. (1956). A Logical View of the Logical Theorist. *Proceedings of the 2nd International Congress for Logic, Methodology, and Philosophy of Science*.\n",
      "- Nilsson, N. J. (1986). *Probabilistic Logic*. Elsevier.\n",
      "- Pollack, M. (1990). The Use of Plans in a Rational Agent Architecture. *Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning*.\n",
      "- Russell, S., & Norvig, P. (2022). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.\n",
      "- Silver, D., et al. (2016). Mastering the Game of Go with Deep Neural Networks and Tree Search. *Nature*, 529, 484-489.\n",
      "- Stone, P., & Kraus, S. (2005). Multiagent Systems in the Real World. *Communications of the ACM*, 48(11), 105-108.\n",
      "- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.\n",
      "- Turing, A. M. (1950). Computing Machinery and Intelligence. *Mind*, 59(236), 433-460.\n",
      "- Wooldridge, M. (2009). *An Introduction to MultiAgent Systems* (2nd ed.). Wiley.\n",
      "\n",
      "If you would like to adjust the depth of coverage for any particular time period or concept, I can certainly make revisions to better match your specific needs. Would you like me to incorporate any particular applications or historical details not included in this version?\n"
     ]
    }
   ],
   "source": [
    "msg = input(\"Hi! I am AI Researcher. Give me any topic and I will write a well researched essay about it. \")\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "with trace(\"Workflow\"):\n",
    "    print(\"----------Planner Output----------\")\n",
    "    planner_result = await Runner.run(planner_agent,inputs)\n",
    "    print(planner_result.final_output.body)\n",
    "    planner_output: Planner = planner_result.final_output\n",
    "    print(\"----------Writer Output----------\")\n",
    "    writer_result = await Runner.run(writer_agent,planner_output.body)\n",
    "    print(writer_result.final_output.body)\n",
    "    writer_output: Writer = writer_result.final_output\n",
    "    print(\"----------Editor Output----------\")\n",
    "    editor_result = await Runner.run(editor_agent,writer_output.body)\n",
    "    print(editor_result.final_output.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efe065-d4e6-41a6-bb4b-60ce7734f102",
   "metadata": {},
   "source": [
    "# Microservices\n",
    "\n",
    "There are several meaningful similarities between LLM-based AI agents and microservices:\n",
    "\n",
    "## Similarities\n",
    "#### Specialized functionality: \n",
    "Both are designed to handle specific tasks or domains. Microservices focus on particular business capabilities, while AI agents can be specialized for specific types of interactions or knowledge domains.\n",
    "### Independent operation: \n",
    "Both can operate autonomously within their defined scope. Once configured, they can process requests without requiring constant supervision.\n",
    "### Communication patterns: \n",
    "Both typically communicate via messages/APIs. Microservices use REST/gRPC/messaging protocols, while AI agents receive prompts and return responses through APIs.\n",
    "### Composability: \n",
    "Both can be combined to build larger systems. Microservices can be orchestrated to create complex applications; similarly, multiple AI agents can work together in a workflow.\n",
    "### Statelessness vs. statefulness: \n",
    "Basic implementations of both can be stateless, but more sophisticated versions maintain state. The Agent class you showed maintains conversation history, similar to how some microservices maintain session state.\n",
    "### Scaling considerations: \n",
    "Both face similar operational challenges around scaling, monitoring, and versioning.\n",
    "\n",
    "## Key differences:\n",
    "\n",
    "### Implementation: \n",
    "Microservices are traditional code with deterministic logic, while LLM agents use probabilistic models. MCP Servers which expose tools to be used by Agents could be totally traditional code with deterministic logic.\n",
    "### Predictability: \n",
    "Microservices have more predictable outputs for given inputs, while LLM responses can vary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9ab57-7246-4c17-a9c1-2ccc9a7cc487",
   "metadata": {},
   "source": [
    "# AFTERWORD\n",
    "Agents are an extremely powerful construct in the field of Generative AI:\n",
    "1. You can achieve complex tasks designing appropriate agents and tools and driving interaction between the different agents.\n",
    "1. There are known ways by which we can improve accuracy of the output. Much like human beings help check one another's work, agents can do the same.\n",
    "1. External data retrieval and queries are carried out through the tools.\n",
    "1. If agent processing needs to be vetted, make sure humans are used (human-in-the-loop) to are used to vet the agent output before it moves to the next step. Really, this is no different to how we operate in our real life with human beings - we have review and approval processes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78716910-84ca-42b6-9f2b-faa39f4df1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
