{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b074a7d-facf-440d-92ce-d9a22caedf23",
   "metadata": {},
   "source": [
    "## This notebook uses llama-stack-client to do handle the ingesting of docs and querying them. A simple ootb RAG use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b49bb66-4009-4990-ae0f-ec3da7e18c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.agents.client_tool import client_tool\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from rich.pretty import pprint\n",
    "import rich\n",
    "import json\n",
    "import uuid\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "#from llama_stack.distribution.library_client import LlamaStackAsLibraryClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "#BRAVE_SEARCH_API_KEY = os.environ[\"BRAVE_SEARCH_API_KEY\"]\n",
    "HOST=os.environ[\"HOST\"]\n",
    "PORT=os.environ[\"LLAMA_STACK_PORT\"]\n",
    "MODEL_NAME=os.environ[\"INFERENCE_MODEL\"]\n",
    "#TAVILY_SEARCH_API_KEY=os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f45054a-4ac9-4d1b-81ce-e28ea7c04887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool(description='Execute code', identifier='code_interpreter', parameters=[Parameter(description='The code to execute', name='code', parameter_type='string', required=True, default=None)], provider_id='code-interpreter', provider_resource_id='code_interpreter', tool_host='distribution', toolgroup_id='builtin::code_interpreter', type='tool', metadata=None)\n",
      "-----\n",
      "Tool(description='Insert documents into memory', identifier='insert_into_memory', parameters=[], provider_id='rag-runtime', provider_resource_id='insert_into_memory', tool_host='distribution', toolgroup_id='builtin::rag', type='tool', metadata=None)\n",
      "-----\n",
      "Tool(description='Search for information in a database.', identifier='knowledge_search', parameters=[Parameter(description='The query to search for. Can be a natural language sentence or keywords.', name='query', parameter_type='string', required=True, default=None)], provider_id='rag-runtime', provider_resource_id='knowledge_search', tool_host='distribution', toolgroup_id='builtin::rag', type='tool', metadata=None)\n",
      "-----\n",
      "Tool(description='Search the web for information', identifier='web_search', parameters=[Parameter(description='The query to search for', name='query', parameter_type='string', required=True, default=None)], provider_id='tavily-search', provider_resource_id='web_search', tool_host='distribution', toolgroup_id='builtin::websearch', type='tool', metadata=None)\n",
      "-----\n",
      "Tool(description='Query WolframAlpha for computational knowledge', identifier='wolfram_alpha', parameters=[Parameter(description='The query to compute', name='query', parameter_type='string', required=True, default=None)], provider_id='wolfram-alpha', provider_resource_id='wolfram_alpha', tool_host='distribution', toolgroup_id='builtin::wolfram_alpha', type='tool', metadata=None)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "client = LlamaStackClient(base_url=f\"http://{HOST}:{PORT}\")\n",
    "for tool in client.tools.list() :\n",
    "    print(tool)\n",
    "    print('-----')\n",
    "#for provider in client.providers.list() :\n",
    "#    print(provider)\n",
    "#    print('-----')\n",
    "#vector_providers = [\n",
    "#    provider for provider in client.providers.list() if provider.api == \"vector_io\"\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f83127a-6e6a-42d3-9e43-aa941f45bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.types import Document\n",
    "urls = [\n",
    "    \"memory_optimizations.rst\",\n",
    "    \"chat.rst\",\n",
    "    \"llama3.rst\",\n",
    "    \"datasets.rst\",\n",
    "    \"qat_finetune.rst\",\n",
    "    \"lora_finetune.rst\",\n",
    "]\n",
    "documents = [\n",
    "    Document(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=f\"https://raw.githubusercontent.com/pytorch/torchtune/main/docs/source/tutorials/{url}\",\n",
    "        mime_type=\"text/plain\",\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, url in enumerate(urls)\n",
    "]\n",
    "\n",
    "#vector_providers = [\n",
    "#    provider for provider in client.providers.list() if provider.api == \"vector_io\"\n",
    "#]\n",
    "#selected_vector_provider = vector_providers[0]\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",\n",
    "    embedding_dimension=384,\n",
    "    #provider_id=selected_vector_provider.provider_id,\n",
    "    provider_id=\"sqlite-vec\",\n",
    ")\n",
    "\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049313ad-8898-46e2-ac67-cb2b7fd3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's come up with a couple of examples to test the agent\n",
    "examples = [\n",
    "    {\n",
    "        \"input_query\": \"What precision formats does torchtune support?\",\n",
    "        \"expected_answer\": \"Torchtune supports two data types for precision: fp32 (full-precision) which uses 4 bytes per model and optimizer parameter, and bfloat16 (half-precision) which uses 2 bytes per model and optimizer parameter.\"\n",
    "    },\n",
    "    {\n",
    "        \"input_query\": \"What does DoRA stand for in torchtune?\",\n",
    "        \"expected_answer\": \"Weight-Decomposed Low-Rank Adaptation\"\n",
    "    },\n",
    "    {\n",
    "        \"input_query\": \"How does the CPUOffloadOptimizer reduce GPU memory usage?\",\n",
    "        \"expected_answer\": \"The CPUOffloadOptimizer reduces GPU memory usage by keeping optimizer states on CPU and performing optimizer steps on CPU. It can also optionally offload gradients to CPU by using offload_gradients=True\"\n",
    "    },\n",
    "    {\n",
    "        \"input_query\": \"How do I ensure only LoRA parameters are trainable when fine-tuning?\",\n",
    "        \"expected_answer\": \"You can set only LoRA parameters to trainable using torchtune's utility functions: first fetch all LoRA parameters with lora_params = get_adapter_params(lora_model), then set them as trainable with set_trainable_params(lora_model, lora_params). The LoRA recipe handles this automatically.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ca81c2-1fa4-4e12-b6bc-c39e328c3f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span> What precision formats does torchtune support?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mQuestion:\u001b[0m What precision formats does torchtune support?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Agent Answer:</span> The provided text is a documentation for using Meta Llama3 with torchtune and the broader ecosystem. \n",
       "It covers various aspects of fine-tuning and quantizing a model, including:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Fine-tuning**: The process of training a model on a specific task or dataset to optimize its performance.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Quantization-aware training <span style=\"font-weight: bold\">(</span>QAT<span style=\"font-weight: bold\">)</span>**: A technique that allows for efficient training of models with quantized \n",
       "weights and activations.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Int8 dynamic activation-int4 weight configuration**: A specific QAT configuration that uses int8 activations \n",
       "and int4 weights.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Post-training quantization <span style=\"font-weight: bold\">(</span>PTQ<span style=\"font-weight: bold\">)</span>**: The process of converting a model from a fake-quantized model to an actual\n",
       "quantized model after fine-tuning.\n",
       "\n",
       "The documentation provides examples of how to:\n",
       "\n",
       "* Fine-tune a model using torchtune\n",
       "* Convert a fake-quantized model to an actual quantized model using PTQ\n",
       "* Use the `torch.compile` function for speedups\n",
       "\n",
       "It also mentions that torchao provides a table listing performance and accuracy results for certain models, \n",
       "including Llama2 and Llama3.\n",
       "\n",
       "Overall, the documentation aims to provide a comprehensive guide for users who want to fine-tune and quantize their\n",
       "Meta Llama3 models using torchtune and the broader ecosystem.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mAgent Answer:\u001b[0m The provided text is a documentation for using Meta Llama3 with torchtune and the broader ecosystem. \n",
       "It covers various aspects of fine-tuning and quantizing a model, including:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Fine-tuning**: The process of training a model on a specific task or dataset to optimize its performance.\n",
       "\u001b[1;36m2\u001b[0m. **Quantization-aware training \u001b[1m(\u001b[0mQAT\u001b[1m)\u001b[0m**: A technique that allows for efficient training of models with quantized \n",
       "weights and activations.\n",
       "\u001b[1;36m3\u001b[0m. **Int8 dynamic activation-int4 weight configuration**: A specific QAT configuration that uses int8 activations \n",
       "and int4 weights.\n",
       "\u001b[1;36m4\u001b[0m. **Post-training quantization \u001b[1m(\u001b[0mPTQ\u001b[1m)\u001b[0m**: The process of converting a model from a fake-quantized model to an actual\n",
       "quantized model after fine-tuning.\n",
       "\n",
       "The documentation provides examples of how to:\n",
       "\n",
       "* Fine-tune a model using torchtune\n",
       "* Convert a fake-quantized model to an actual quantized model using PTQ\n",
       "* Use the `torch.compile` function for speedups\n",
       "\n",
       "It also mentions that torchao provides a table listing performance and accuracy results for certain models, \n",
       "including Llama2 and Llama3.\n",
       "\n",
       "Overall, the documentation aims to provide a comprehensive guide for users who want to fine-tune and quantize their\n",
       "Meta Llama3 models using torchtune and the broader ecosystem.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span> What does DoRA stand for in torchtune?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mQuestion:\u001b[0m What does DoRA stand for in torchtune?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Agent Answer:</span> Here is the code that corresponds to the provided specification:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from torch import nn\n",
       "from torch.nn import Linear, RotaryPositionalEmbeddings\n",
       "from torch.nn.functional import dropout\n",
       "from torch.nn.utils.rnn import pack_padded_sequence\n",
       "\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoRALinear</span><span style=\"font-weight: bold\">(</span>nn.Module<span style=\"font-weight: bold\">)</span>:\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">(</span>self, in_features, out_features, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>:\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">(</span>LoRALinear, self<span style=\"font-weight: bold\">)</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.__init__</span><span style=\"font-weight: bold\">()</span>\n",
       "        self.q_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">out_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #800080; text-decoration-color: #800080\">bias</span><span style=\"font-weight: bold\">)</span>\n",
       "        self.k_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">out_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #800080; text-decoration-color: #800080\">bias</span><span style=\"font-weight: bold\">)</span>\n",
       "        self.v_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">out_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #800080; text-decoration-color: #800080\">bias</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward</span><span style=\"font-weight: bold\">(</span>self, x<span style=\"font-weight: bold\">)</span>:\n",
       "        q = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.q_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        k = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.k_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        v = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.v_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        return q, k, v\n",
       "\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiHeadAttention</span><span style=\"font-weight: bold\">(</span>nn.Module<span style=\"font-weight: bold\">)</span>:\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">(</span>self, in_features, num_heads, <span style=\"color: #808000; text-decoration-color: #808000\">dropout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">)</span>:\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">(</span>MultiHeadAttention, self<span style=\"font-weight: bold\">)</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.__init__</span><span style=\"font-weight: bold\">()</span>\n",
       "        self.q_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span> * num_heads, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        self.k_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span> * num_heads, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        self.v_proj = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">in_features</span> * num_heads, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        self.dropout = dropout\n",
       "\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward</span><span style=\"font-weight: bold\">(</span>self, x<span style=\"font-weight: bold\">)</span>:\n",
       "        q = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.q_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        k = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.k_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        v = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.v_proj</span><span style=\"font-weight: bold\">(</span>x<span style=\"font-weight: bold\">)</span>\n",
       "        # Apply LoRA\n",
       "        q = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoRALinear</span><span style=\"font-weight: bold\">(</span>q, <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">q</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">q</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">])(</span>q<span style=\"font-weight: bold\">)</span>\n",
       "        k = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoRALinear</span><span style=\"font-weight: bold\">(</span>k, <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">k</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">k</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">])(</span>k<span style=\"font-weight: bold\">)</span>\n",
       "        v = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoRALinear</span><span style=\"font-weight: bold\">(</span>v, <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">v</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #800080; text-decoration-color: #800080\">v</span>.shape<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"font-weight: bold\">])(</span>v<span style=\"font-weight: bold\">)</span>\n",
       "        # Apply dropout\n",
       "        q = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.dropout</span><span style=\"font-weight: bold\">(</span>q<span style=\"font-weight: bold\">)</span>\n",
       "        k = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.dropout</span><span style=\"font-weight: bold\">(</span>k<span style=\"font-weight: bold\">)</span>\n",
       "        v = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.dropout</span><span style=\"font-weight: bold\">(</span>v<span style=\"font-weight: bold\">)</span>\n",
       "        return q, k, v\n",
       "\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoraLLama2</span><span style=\"font-weight: bold\">(</span>nn.Module<span style=\"font-weight: bold\">)</span>:\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">(</span>self, <span style=\"color: #808000; text-decoration-color: #808000\">lora_attn_modules</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">apply_lora_to_mlp</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">apply_lora_to_output</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>:\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">(</span>LoraLLama2, self<span style=\"font-weight: bold\">)</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.__init__</span><span style=\"font-weight: bold\">()</span>\n",
       "        if lora_attn_modules is <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>:\n",
       "            lora_attn_modules = <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"q_proj\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"k_proj\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"v_proj\"</span><span style=\"font-weight: bold\">]</span>\n",
       "        else:\n",
       "            lora_attn_modules = lora_attn_modules\n",
       "        self.layers = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">nn.ModuleList</span><span style=\"font-weight: bold\">([</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiHeadAttention</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">num_heads</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span> for _ in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">range</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">)])</span>\n",
       "        for i, module in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">enumerate</span><span style=\"font-weight: bold\">(</span>self.layers<span style=\"font-weight: bold\">)</span>:\n",
       "            if apply_lora_to_mlp and i &lt; <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>lora_attn_modules<span style=\"font-weight: bold\">)</span>:\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">setattr</span><span style=\"font-weight: bold\">(</span>self, f\"lora_<span style=\"font-weight: bold\">{</span>lora_attn_modules<span style=\"font-weight: bold; font-style: italic\">}</span><span style=\"font-style: italic\">\", </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">LoRALinear</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">in_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-style: italic\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">out_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-weight: bold; font-style: italic\">))</span>\n",
       "<span style=\"font-style: italic\">            if apply_lora_to_output:</span>\n",
       "<span style=\"font-style: italic\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">setattr</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self, f\"output_</span><span style=\"font-weight: bold; font-style: italic\">{</span><span style=\"font-style: italic\">i</span><span style=\"font-weight: bold; font-style: italic\">}</span><span style=\"font-style: italic\">\", </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">Linear</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">in_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-style: italic\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">out_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-weight: bold; font-style: italic\">))</span>\n",
       "\n",
       "<span style=\"font-style: italic\">    def </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">forward</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self, x</span><span style=\"font-weight: bold; font-style: italic\">)</span><span style=\"font-style: italic\">:</span>\n",
       "<span style=\"font-style: italic\">        for i, layer in </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">enumerate</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self.layers</span><span style=\"font-weight: bold; font-style: italic\">)</span><span style=\"font-style: italic\">:</span>\n",
       "<span style=\"font-style: italic\">            q, k, v = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">layer</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">x</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            # Apply LoRA</span>\n",
       "<span style=\"font-style: italic\">            q = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">getattr</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self, f'lora_q_proj_</span><span style=\"font-weight: bold; font-style: italic\">{</span><span style=\"font-style: italic\">i</span><span style=\"font-weight: bold; font-style: italic\">}</span><span style=\"font-style: italic\">'</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            k = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">getattr</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self, f'lora_k_proj_</span><span style=\"font-weight: bold; font-style: italic\">{</span><span style=\"font-style: italic\">i</span><span style=\"font-weight: bold; font-style: italic\">}</span><span style=\"font-style: italic\">'</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            v = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">getattr</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">self, f'lora_v_proj_</span><span style=\"font-weight: bold; font-style: italic\">{</span><span style=\"font-style: italic\">i</span><span style=\"font-weight: bold; font-style: italic\">}</span><span style=\"font-style: italic\">'</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            q = q + </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">dropout</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">q</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            k = k + </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">dropout</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">k</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            v = v + </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">dropout</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">v</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            # Apply output layer</span>\n",
       "<span style=\"font-style: italic\">            if i == </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">11</span><span style=\"font-style: italic\">:</span>\n",
       "<span style=\"font-style: italic\">                x = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">Linear</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">in_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">q</span><span style=\"font-style: italic\">.shape</span><span style=\"font-weight: bold; font-style: italic\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">-1</span><span style=\"font-weight: bold; font-style: italic\">]</span><span style=\"font-style: italic\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">out_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-weight: bold; font-style: italic\">)(</span><span style=\"font-style: italic\">q</span><span style=\"font-weight: bold; font-style: italic\">)</span><span style=\"font-style: italic\"> + </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">Linear</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">in_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">k</span><span style=\"font-style: italic\">.shape</span><span style=\"font-weight: bold; font-style: italic\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">-1</span><span style=\"font-weight: bold; font-style: italic\">]</span><span style=\"font-style: italic\">, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">out_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-weight: bold; font-style: italic\">)(</span><span style=\"font-style: italic\">k</span><span style=\"font-weight: bold; font-style: italic\">)</span><span style=\"font-style: italic\"> + </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">Linear</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">in_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">v</span><span style=\"font-style: italic\">.shape</span><span style=\"font-weight: bold; font-style: italic\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">-1</span><span style=\"font-weight: bold; font-style: italic\">]</span><span style=\"font-style: italic\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">out_features</span><span style=\"font-style: italic\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">4096</span><span style=\"font-weight: bold; font-style: italic\">)(</span><span style=\"font-style: italic\">v</span><span style=\"font-weight: bold; font-style: italic\">)</span>\n",
       "<span style=\"font-style: italic\">            else:</span>\n",
       "<span style=\"font-style: italic\">                x = q</span>\n",
       "<span style=\"font-style: italic\">        return x</span>\n",
       "\n",
       "<span style=\"font-style: italic\"># Create a Llama2 model without LoRA</span>\n",
       "<span style=\"font-style: italic\">base_model = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">Llama2</span><span style=\"font-weight: bold; font-style: italic\">()</span>\n",
       "\n",
       "<span style=\"font-style: italic\"># Create a Llama2 model with LoRA applied to some layers</span>\n",
       "<span style=\"font-style: italic\">lora_model = </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold; font-style: italic\">LoraLLama2</span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">lora_attn_modules</span><span style=\"font-style: italic\">=</span><span style=\"font-weight: bold; font-style: italic\">[</span><span style=\"color: #008000; text-decoration-color: #008000; font-style: italic\">\"q_proj\"</span><span style=\"font-style: italic\">, </span><span style=\"color: #008000; text-decoration-color: #008000; font-style: italic\">\"v_proj\"</span><span style=\"font-weight: bold; font-style: italic\">])</span>\n",
       "<span style=\"font-style: italic\">```</span>\n",
       "\n",
       "<span style=\"font-style: italic\">This code defines the `LoRALinear` class, which represents a linear layer with LoRA. It also defines the </span>\n",
       "<span style=\"font-style: italic\">`MultiHeadAttention` class, which is a multi-head attention mechanism that applies LoRA to its input. The </span>\n",
       "<span style=\"font-style: italic\">`LoraLLama2` class is a Llama2 model that can be configured to apply LoRA to some of its layers.</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The code then creates two models: one without LoRA and one with LoRA applied to the query and value projections in </span>\n",
       "<span style=\"font-style: italic\">each self-attention layer.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mAgent Answer:\u001b[0m Here is the code that corresponds to the provided specification:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from torch import nn\n",
       "from torch.nn import Linear, RotaryPositionalEmbeddings\n",
       "from torch.nn.functional import dropout\n",
       "from torch.nn.utils.rnn import pack_padded_sequence\n",
       "\n",
       "class \u001b[1;35mLoRALinear\u001b[0m\u001b[1m(\u001b[0mnn.Module\u001b[1m)\u001b[0m:\n",
       "    def \u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0mself, in_features, out_features, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m:\n",
       "        \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0mLoRALinear, self\u001b[1m)\u001b[0m\u001b[1;35m.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.q_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mout_features\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[35mbias\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.k_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mout_features\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[35mbias\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.v_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mout_features\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[35mbias\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "    def \u001b[1;35mforward\u001b[0m\u001b[1m(\u001b[0mself, x\u001b[1m)\u001b[0m:\n",
       "        q = \u001b[1;35mself.q_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        k = \u001b[1;35mself.k_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        v = \u001b[1;35mself.v_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        return q, k, v\n",
       "\n",
       "class \u001b[1;35mMultiHeadAttention\u001b[0m\u001b[1m(\u001b[0mnn.Module\u001b[1m)\u001b[0m:\n",
       "    def \u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0mself, in_features, num_heads, \u001b[33mdropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m:\n",
       "        \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0mMultiHeadAttention, self\u001b[1m)\u001b[0m\u001b[1;35m.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.q_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35min_features\u001b[0m * num_heads, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.k_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35min_features\u001b[0m * num_heads, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.v_proj = \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[35min_features\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35min_features\u001b[0m * num_heads, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        self.dropout = dropout\n",
       "\n",
       "    def \u001b[1;35mforward\u001b[0m\u001b[1m(\u001b[0mself, x\u001b[1m)\u001b[0m:\n",
       "        q = \u001b[1;35mself.q_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        k = \u001b[1;35mself.k_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        v = \u001b[1;35mself.v_proj\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m\n",
       "        # Apply LoRA\n",
       "        q = \u001b[1;35mLoRALinear\u001b[0m\u001b[1m(\u001b[0mq, \u001b[33min_features\u001b[0m=\u001b[35mq\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mq\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m(\u001b[0mq\u001b[1m)\u001b[0m\n",
       "        k = \u001b[1;35mLoRALinear\u001b[0m\u001b[1m(\u001b[0mk, \u001b[33min_features\u001b[0m=\u001b[35mk\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mk\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m(\u001b[0mk\u001b[1m)\u001b[0m\n",
       "        v = \u001b[1;35mLoRALinear\u001b[0m\u001b[1m(\u001b[0mv, \u001b[33min_features\u001b[0m=\u001b[35mv\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[35mv\u001b[0m.shape\u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m(\u001b[0mv\u001b[1m)\u001b[0m\n",
       "        # Apply dropout\n",
       "        q = \u001b[1;35mself.dropout\u001b[0m\u001b[1m(\u001b[0mq\u001b[1m)\u001b[0m\n",
       "        k = \u001b[1;35mself.dropout\u001b[0m\u001b[1m(\u001b[0mk\u001b[1m)\u001b[0m\n",
       "        v = \u001b[1;35mself.dropout\u001b[0m\u001b[1m(\u001b[0mv\u001b[1m)\u001b[0m\n",
       "        return q, k, v\n",
       "\n",
       "class \u001b[1;35mLoraLLama2\u001b[0m\u001b[1m(\u001b[0mnn.Module\u001b[1m)\u001b[0m:\n",
       "    def \u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0mself, \u001b[33mlora_attn_modules\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mapply_lora_to_mlp\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mapply_lora_to_output\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m:\n",
       "        \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0mLoraLLama2, self\u001b[1m)\u001b[0m\u001b[1;35m.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        if lora_attn_modules is \u001b[3;35mNone\u001b[0m:\n",
       "            lora_attn_modules = \u001b[1m[\u001b[0m\u001b[32m\"q_proj\"\u001b[0m, \u001b[32m\"k_proj\"\u001b[0m, \u001b[32m\"v_proj\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "        else:\n",
       "            lora_attn_modules = lora_attn_modules\n",
       "        self.layers = \u001b[1;35mnn.ModuleList\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;35mMultiHeadAttention\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mnum_heads\u001b[0m=\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m for _ in \u001b[1;35mrange\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "        for i, module in \u001b[1;35menumerate\u001b[0m\u001b[1m(\u001b[0mself.layers\u001b[1m)\u001b[0m:\n",
       "            if apply_lora_to_mlp and i < \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mlora_attn_modules\u001b[1m)\u001b[0m:\n",
       "                \u001b[1;35msetattr\u001b[0m\u001b[1m(\u001b[0mself, f\"lora_\u001b[1m{\u001b[0mlora_attn_modules\u001b[1;3m}\u001b[0m\u001b[3m\", \u001b[0m\u001b[1;3;35mLoRALinear\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33min_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[3m, \u001b[0m\u001b[3;33mout_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[1;3m)\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            if apply_lora_to_output:\u001b[0m\n",
       "\u001b[3m                \u001b[0m\u001b[1;3;35msetattr\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself, f\"output_\u001b[0m\u001b[1;3m{\u001b[0m\u001b[3mi\u001b[0m\u001b[1;3m}\u001b[0m\u001b[3m\", \u001b[0m\u001b[1;3;35mLinear\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33min_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[3m, \u001b[0m\u001b[3;33mout_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[1;3m)\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\n",
       "\u001b[3m    def \u001b[0m\u001b[1;3;35mforward\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself, x\u001b[0m\u001b[1;3m)\u001b[0m\u001b[3m:\u001b[0m\n",
       "\u001b[3m        for i, layer in \u001b[0m\u001b[1;3;35menumerate\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself.layers\u001b[0m\u001b[1;3m)\u001b[0m\u001b[3m:\u001b[0m\n",
       "\u001b[3m            q, k, v = \u001b[0m\u001b[1;3;35mlayer\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mx\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            # Apply LoRA\u001b[0m\n",
       "\u001b[3m            q = \u001b[0m\u001b[1;3;35mgetattr\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself, f'lora_q_proj_\u001b[0m\u001b[1;3m{\u001b[0m\u001b[3mi\u001b[0m\u001b[1;3m}\u001b[0m\u001b[3m'\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            k = \u001b[0m\u001b[1;3;35mgetattr\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself, f'lora_k_proj_\u001b[0m\u001b[1;3m{\u001b[0m\u001b[3mi\u001b[0m\u001b[1;3m}\u001b[0m\u001b[3m'\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            v = \u001b[0m\u001b[1;3;35mgetattr\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mself, f'lora_v_proj_\u001b[0m\u001b[1;3m{\u001b[0m\u001b[3mi\u001b[0m\u001b[1;3m}\u001b[0m\u001b[3m'\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            q = q + \u001b[0m\u001b[1;3;35mdropout\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mq\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            k = k + \u001b[0m\u001b[1;3;35mdropout\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mk\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            v = v + \u001b[0m\u001b[1;3;35mdropout\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mv\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            # Apply output layer\u001b[0m\n",
       "\u001b[3m            if i == \u001b[0m\u001b[1;3;36m11\u001b[0m\u001b[3m:\u001b[0m\n",
       "\u001b[3m                x = \u001b[0m\u001b[1;3;35mLinear\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33min_features\u001b[0m\u001b[3m=\u001b[0m\u001b[3;35mq\u001b[0m\u001b[3m.shape\u001b[0m\u001b[1;3m[\u001b[0m\u001b[1;3;36m-1\u001b[0m\u001b[1;3m]\u001b[0m\u001b[3m, \u001b[0m\u001b[3;33mout_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[1;3m)\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mq\u001b[0m\u001b[1;3m)\u001b[0m\u001b[3m + \u001b[0m\u001b[1;3;35mLinear\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33min_features\u001b[0m\u001b[3m=\u001b[0m\u001b[3;35mk\u001b[0m\u001b[3m.shape\u001b[0m\u001b[1;3m[\u001b[0m\u001b[1;3;36m-1\u001b[0m\u001b[1;3m]\u001b[0m\u001b[3m, \u001b[0m\n",
       "\u001b[3;33mout_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[1;3m)\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mk\u001b[0m\u001b[1;3m)\u001b[0m\u001b[3m + \u001b[0m\u001b[1;3;35mLinear\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33min_features\u001b[0m\u001b[3m=\u001b[0m\u001b[3;35mv\u001b[0m\u001b[3m.shape\u001b[0m\u001b[1;3m[\u001b[0m\u001b[1;3;36m-1\u001b[0m\u001b[1;3m]\u001b[0m\u001b[3m, \u001b[0m\u001b[3;33mout_features\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3;36m4096\u001b[0m\u001b[1;3m)\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mv\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m            else:\u001b[0m\n",
       "\u001b[3m                x = q\u001b[0m\n",
       "\u001b[3m        return x\u001b[0m\n",
       "\n",
       "\u001b[3m# Create a Llama2 model without LoRA\u001b[0m\n",
       "\u001b[3mbase_model = \u001b[0m\u001b[1;3;35mLlama2\u001b[0m\u001b[1;3m(\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\n",
       "\u001b[3m# Create a Llama2 model with LoRA applied to some layers\u001b[0m\n",
       "\u001b[3mlora_model = \u001b[0m\u001b[1;3;35mLoraLLama2\u001b[0m\u001b[1;3m(\u001b[0m\u001b[3;33mlora_attn_modules\u001b[0m\u001b[3m=\u001b[0m\u001b[1;3m[\u001b[0m\u001b[3;32m\"q_proj\"\u001b[0m\u001b[3m, \u001b[0m\u001b[3;32m\"v_proj\"\u001b[0m\u001b[1;3m]\u001b[0m\u001b[1;3m)\u001b[0m\n",
       "\u001b[3m```\u001b[0m\n",
       "\n",
       "\u001b[3mThis code defines the `LoRALinear` class, which represents a linear layer with LoRA. It also defines the \u001b[0m\n",
       "\u001b[3m`MultiHeadAttention` class, which is a multi-head attention mechanism that applies LoRA to its input. The \u001b[0m\n",
       "\u001b[3m`LoraLLama2` class is a Llama2 model that can be configured to apply LoRA to some of its layers.\u001b[0m\n",
       "\n",
       "\u001b[3mThe code then creates two models: one without LoRA and one with LoRA applied to the query and value projections in \u001b[0m\n",
       "\u001b[3meach self-attention layer.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span> How does the CPUOffloadOptimizer reduce GPU memory usage?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mQuestion:\u001b[0m How does the CPUOffloadOptimizer reduce GPU memory usage?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Agent Answer:</span> <span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mAgent Answer:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Question:</span> How do I ensure only LoRA parameters are trainable when fine-tuning?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mQuestion:\u001b[0m How do I ensure only LoRA parameters are trainable when fine-tuning?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Agent Answer:</span> Here is the code that corresponds to the provided specification:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from torch import nn\n",
       "from torch.optim import AdamW\n",
       "from torch.utils.data import Dataset, DataLoader\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
       "from peft import PeftModel, PeftConfig\n",
       "from peft.peft_utils import get_adapter_params, set_trainable_params\n",
       "\n",
       "# Load the pre-trained model and tokenizer\n",
       "model_name = <span style=\"color: #008000; text-decoration-color: #008000\">\"facebook/llamalarge-lm\"</span>\n",
       "tokenizer = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AutoTokenizer.from_pretrained</span><span style=\"font-weight: bold\">(</span>model_name<span style=\"font-weight: bold\">)</span>\n",
       "model = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AutoModelForCausalLM.from_pretrained</span><span style=\"font-weight: bold\">(</span>model_name<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Set up the dataset and data loader\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MyDataset</span><span style=\"font-weight: bold\">(</span>Dataset<span style=\"font-weight: bold\">)</span>:\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">(</span>self, texts, tokenizer<span style=\"font-weight: bold\">)</span>:\n",
       "        self.texts = texts\n",
       "        self.tokenizer = tokenizer\n",
       "\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__len__</span><span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>:\n",
       "        return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>self.texts<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__getitem__</span><span style=\"font-weight: bold\">(</span>self, idx<span style=\"font-weight: bold\">)</span>:\n",
       "        text = self.texts\n",
       "        inputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.tokenizer</span><span style=\"font-weight: bold\">(</span>text, <span style=\"color: #808000; text-decoration-color: #808000\">return_tensors</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"pt\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_length</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #808000; text-decoration-color: #808000\">truncation</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "        return inputs\n",
       "\n",
       "dataset = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MyDataset</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">\"text1\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"text2\"</span><span style=\"font-weight: bold\">]</span>, tokenizer<span style=\"font-weight: bold\">)</span>\n",
       "data_loader = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DataLoader</span><span style=\"font-weight: bold\">(</span>dataset, <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Set up the optimizer and scheduler\n",
       "optimizer = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AdamW</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model.parameters</span><span style=\"font-weight: bold\">()</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-5</span><span style=\"font-weight: bold\">)</span>\n",
       "scheduler = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.optim.lr_scheduler.StepLR</span><span style=\"font-weight: bold\">(</span>optimizer, <span style=\"color: #808000; text-decoration-color: #808000\">step_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Fine-tune the model with LoRA\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fine_tune_lora</span><span style=\"font-weight: bold\">(</span>model, data_loader, optimizer, scheduler<span style=\"font-weight: bold\">)</span>:\n",
       "    for epoch in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">range</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:\n",
       "        for batch in data_loader:\n",
       "            inputs = batch<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"input_ids\"</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.to</span><span style=\"font-weight: bold\">(</span>device<span style=\"font-weight: bold\">)</span>\n",
       "            labels = batch<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"labels\"</span><span style=\"font-weight: bold\">]</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.to</span><span style=\"font-weight: bold\">(</span>device<span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">optimizer.zero_grad</span><span style=\"font-weight: bold\">()</span>\n",
       "            outputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model</span><span style=\"font-weight: bold\">(</span>inputs, <span style=\"color: #808000; text-decoration-color: #808000\">labels</span>=<span style=\"color: #800080; text-decoration-color: #800080\">labels</span><span style=\"font-weight: bold\">)</span>\n",
       "            loss = outputs.loss\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">loss.backward</span><span style=\"font-weight: bold\">()</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">optimizer.step</span><span style=\"font-weight: bold\">()</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">scheduler.step</span><span style=\"font-weight: bold\">()</span>\n",
       "\n",
       "# Load the pre-trained weights and set only LoRA parameters to trainable\n",
       "device = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"cuda\"</span> if <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.cuda.is_available</span><span style=\"font-weight: bold\">()</span> else <span style=\"color: #008000; text-decoration-color: #008000\">\"cpu\"</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model.to</span><span style=\"font-weight: bold\">(</span>device<span style=\"font-weight: bold\">)</span>\n",
       "lora_model = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PeftModel</span><span style=\"font-weight: bold\">(</span>model, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #800080; text-decoration-color: #800080\">device</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "base_model_state_dict = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model.state_dict</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">lora_model.load_state_dict</span><span style=\"font-weight: bold\">(</span>base_model_state_dict, <span style=\"color: #808000; text-decoration-color: #808000\">strict</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Set only LoRA parameters to trainable\n",
       "lora_params = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_adapter_params</span><span style=\"font-weight: bold\">(</span>lora_model<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">set_trainable_params</span><span style=\"font-weight: bold\">(</span>lora_model, lora_params<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Print the total number of parameters and trainable parameters\n",
       "total_params = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">sum</span><span style=\"font-weight: bold\">()</span>\n",
       "trainable_params = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">sum</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span>f\"<span style=\"font-weight: bold\">{</span>total_params<span style=\"font-weight: bold\">}</span> total params, <span style=\"font-weight: bold\">{</span>trainable_params<span style=\"font-weight: bold\">}</span> trainable params, <span style=\"font-weight: bold\">{(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span> * trainable_params <span style=\"color: #800080; text-decoration-color: #800080\">/</span> \n",
       "total_params<span style=\"font-weight: bold\">)</span>:.2f<span style=\"font-weight: bold\">}</span>% of all params are trainable.\"<span style=\"font-weight: bold\">)</span>\n",
       "```\n",
       "\n",
       "Note that this code assumes you have the `peft` library installed and have replaced the `model_name`, `tokenizer`, \n",
       "and `dataset` variables with your own values. Additionally, you may need to modify the `fine_tune_lora` function to\n",
       "suit your specific use case.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mAgent Answer:\u001b[0m Here is the code that corresponds to the provided specification:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from torch import nn\n",
       "from torch.optim import AdamW\n",
       "from torch.utils.data import Dataset, DataLoader\n",
       "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
       "from peft import PeftModel, PeftConfig\n",
       "from peft.peft_utils import get_adapter_params, set_trainable_params\n",
       "\n",
       "# Load the pre-trained model and tokenizer\n",
       "model_name = \u001b[32m\"facebook/llamalarge-lm\"\u001b[0m\n",
       "tokenizer = \u001b[1;35mAutoTokenizer.from_pretrained\u001b[0m\u001b[1m(\u001b[0mmodel_name\u001b[1m)\u001b[0m\n",
       "model = \u001b[1;35mAutoModelForCausalLM.from_pretrained\u001b[0m\u001b[1m(\u001b[0mmodel_name\u001b[1m)\u001b[0m\n",
       "\n",
       "# Set up the dataset and data loader\n",
       "class \u001b[1;35mMyDataset\u001b[0m\u001b[1m(\u001b[0mDataset\u001b[1m)\u001b[0m:\n",
       "    def \u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0mself, texts, tokenizer\u001b[1m)\u001b[0m:\n",
       "        self.texts = texts\n",
       "        self.tokenizer = tokenizer\n",
       "\n",
       "    def \u001b[1;35m__len__\u001b[0m\u001b[1m(\u001b[0mself\u001b[1m)\u001b[0m:\n",
       "        return \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mself.texts\u001b[1m)\u001b[0m\n",
       "\n",
       "    def \u001b[1;35m__getitem__\u001b[0m\u001b[1m(\u001b[0mself, idx\u001b[1m)\u001b[0m:\n",
       "        text = self.texts\n",
       "        inputs = \u001b[1;35mself.tokenizer\u001b[0m\u001b[1m(\u001b[0mtext, \u001b[33mreturn_tensors\u001b[0m=\u001b[32m\"pt\"\u001b[0m, \u001b[33mmax_length\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mtruncation\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        return inputs\n",
       "\n",
       "dataset = \u001b[1;35mMyDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m\"text1\"\u001b[0m, \u001b[32m\"text2\"\u001b[0m\u001b[1m]\u001b[0m, tokenizer\u001b[1m)\u001b[0m\n",
       "data_loader = \u001b[1;35mDataLoader\u001b[0m\u001b[1m(\u001b[0mdataset, \u001b[33mbatch_size\u001b[0m=\u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "# Set up the optimizer and scheduler\n",
       "optimizer = \u001b[1;35mAdamW\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mmodel.parameters\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mlr\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-5\u001b[0m\u001b[1m)\u001b[0m\n",
       "scheduler = \u001b[1;35mtorch.optim.lr_scheduler.StepLR\u001b[0m\u001b[1m(\u001b[0moptimizer, \u001b[33mstep_size\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "# Fine-tune the model with LoRA\n",
       "def \u001b[1;35mfine_tune_lora\u001b[0m\u001b[1m(\u001b[0mmodel, data_loader, optimizer, scheduler\u001b[1m)\u001b[0m:\n",
       "    for epoch in \u001b[1;35mrange\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m:\n",
       "        for batch in data_loader:\n",
       "            inputs = batch\u001b[1m[\u001b[0m\u001b[32m\"input_ids\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1;35m.to\u001b[0m\u001b[1m(\u001b[0mdevice\u001b[1m)\u001b[0m\n",
       "            labels = batch\u001b[1m[\u001b[0m\u001b[32m\"labels\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1;35m.to\u001b[0m\u001b[1m(\u001b[0mdevice\u001b[1m)\u001b[0m\n",
       "            \u001b[1;35moptimizer.zero_grad\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "            outputs = \u001b[1;35mmodel\u001b[0m\u001b[1m(\u001b[0minputs, \u001b[33mlabels\u001b[0m=\u001b[35mlabels\u001b[0m\u001b[1m)\u001b[0m\n",
       "            loss = outputs.loss\n",
       "            \u001b[1;35mloss.backward\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1;35moptimizer.step\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "            \u001b[1;35mscheduler.step\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "# Load the pre-trained weights and set only LoRA parameters to trainable\n",
       "device = \u001b[1;35mtorch.device\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"cuda\"\u001b[0m if \u001b[1;35mtorch.cuda.is_available\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m else \u001b[32m\"cpu\"\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mmodel.to\u001b[0m\u001b[1m(\u001b[0mdevice\u001b[1m)\u001b[0m\n",
       "lora_model = \u001b[1;35mPeftModel\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mdevice\u001b[0m=\u001b[35mdevice\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "base_model_state_dict = \u001b[1;35mmodel.state_dict\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mlora_model.load_state_dict\u001b[0m\u001b[1m(\u001b[0mbase_model_state_dict, \u001b[33mstrict\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "# Set only LoRA parameters to trainable\n",
       "lora_params = \u001b[1;35mget_adapter_params\u001b[0m\u001b[1m(\u001b[0mlora_model\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mset_trainable_params\u001b[0m\u001b[1m(\u001b[0mlora_model, lora_params\u001b[1m)\u001b[0m\n",
       "\n",
       "# Print the total number of parameters and trainable parameters\n",
       "total_params = \u001b[1;35msum\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "trainable_params = \u001b[1;35msum\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0mf\"\u001b[1m{\u001b[0mtotal_params\u001b[1m}\u001b[0m total params, \u001b[1m{\u001b[0mtrainable_params\u001b[1m}\u001b[0m trainable params, \u001b[1m{\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m100.0\u001b[0m * trainable_params \u001b[35m/\u001b[0m \n",
       "total_params\u001b[1m)\u001b[0m:.2f\u001b[1m}\u001b[0m% of all params are trainable.\"\u001b[1m)\u001b[0m\n",
       "```\n",
       "\n",
       "Note that this code assumes you have the `peft` library installed and have replaced the `model_name`, `tokenizer`, \n",
       "and `dataset` variables with your own values. Additionally, you may need to modify the `fine_tune_lora` function to\n",
       "suit your specific use case.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rag_agent = Agent(\n",
    "    client,\n",
    "    model=MODEL_NAME,\n",
    "    instructions=\"You are a helpful assistant that can answer questions about the Torchtune project. You should always use the RAG tool to answer questions.\",\n",
    "    tools=[{\n",
    "        \"name\": \"builtin::rag\",\n",
    "        \"args\": {\"vector_db_ids\": [vector_db_id]},\n",
    "    }],\n",
    ")\n",
    "\n",
    "for example in examples:\n",
    "    rag_session_id = rag_agent.create_session(session_name=f\"rag_session_{uuid.uuid4()}\")\n",
    "    response = rag_agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": example[\"input_query\"]\n",
    "            }\n",
    "        ],\n",
    "        session_id=rag_session_id,\n",
    "        stream=False\n",
    "    )\n",
    "    rich.print(f\"[bold cyan]Question:[/bold cyan] {example['input_query']}\")\n",
    "    rich.print(f\"[bold yellow]Agent Answer:[/bold yellow] {response.output_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa69a76-1ceb-4535-8657-19485ced92e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".summit",
   "language": "python",
   "name": ".summit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
