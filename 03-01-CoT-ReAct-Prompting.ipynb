{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# getting started\n",
    "\n",
    "In this lab we will compare Chain of Though (Cot) and ReAct (Reason Act) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55909c-3009-4319-9cb6-cbfdce425961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201a5506-5b38-4fcb-a0c6-45e67a8ed5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete, Client initialized\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# import re\n",
    "# # import httpx\n",
    "# import os\n",
    "# # import rich\n",
    "# import json\n",
    "# from openai import OpenAI\n",
    "\n",
    "# api_key = \"placeholder\" \n",
    "# # model = \"llama3.2:3b-instruct-fp16\"\n",
    "# model = \"qwen3:32b\"\n",
    "# model = \"phi4\"\n",
    "\n",
    "\n",
    "# base_url = \"http://localhost:11434/v1/\"\n",
    "\n",
    "# client = OpenAI(\n",
    "#     base_url=base_url,\n",
    "#     api_key=api_key,\n",
    "# )\n",
    "\n",
    "\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = \"placeholder\"  \n",
    "model = \"mistral-small:latest\" # Other oprions here include \"qwen3:32b\"\n",
    "base_url = \"http://localhost:11434/v1/\" #openai/v1/\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "print(\"Imports complete, Client initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127c382-7143-41da-8723-898f392e5db1",
   "metadata": {},
   "source": [
    "# Chain of Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7476f-a86b-4f20-ae24-cf070b2493ec",
   "metadata": {},
   "source": [
    "A Chain of Thought (CoT) prompt is a prompting technique used with large language models (LLMs) where you explicitly guide the model to reason step-by-step before arriving at the final answer.\n",
    "\n",
    "Instead of asking the model to directly give you an answer, a CoT prompt encourages it to \"think aloud\"—breaking down the problem, analyzing it in stages, and only then giving a conclusion. This helps improve accuracy, especially for complex reasoning, math, logic, or multi-hop questions.\n",
    "\n",
    "Can be combined with few-shot prompting (i.e., giving multiple CoT examples before the actual question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112d49f4-f8d6-444b-8ecf-651efc85bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static example to demonstrate format (few-shot learning)\n",
    "prompt = \"\"\"\n",
    "You are a thoughtful and logical assistant. For every question, you will:\n",
    "- Think step-by-step under a “Thought” section.\n",
    "- Then write the final result under “Answer”.\n",
    "- Always follow the structure shown below.\n",
    "\n",
    "Use this format:\n",
    "Question: <the question>\n",
    "Thought: <your detailed reasoning>\n",
    "Answer: <final answer>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Question: If a train leaves at 2 PM and takes 3 hours to reach its destination, what time does it arrive?\n",
    "Thought: The train departs at 2 PM. If it travels for 3 hours, it will arrive at 2 + 3 = 5 PM.\n",
    "Answer: 5 PM\n",
    "\n",
    "Question: What is the capital of the country whose official language is French and borders Germany?\n",
    "Thought: France is a country that borders Germany and has French as its official language. The capital of France is Paris.\n",
    "Answer: Paris\n",
    "\n",
    "Question: What is the sum of the first three even numbers?\n",
    "Thought: The first three even numbers are 2, 4, and 6. Their sum is 2 + 4 + 6 = 12.\n",
    "Answer: 12\n",
    "\n",
    "Now answer the next question using the same format:\n",
    "\"\"\"\n",
    "\n",
    "#question = \"what is elevation range for the area that the eastern sector of colorado orogeny extends into?\"\n",
    "question = \"If Tom has 5 cookies and eats 2, how many does he have left?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e07f566-492c-4b77-9e0e-5a10eac67a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Thought:** Tom starts with 5 cookies. If he eats 2, then he will have 5 - 2 = 3 cookies remaining.\n",
      "\n",
      "**Answer**: 3 cookies\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93353aa-5f03-46ba-bbaf-20a24e963403",
   "metadata": {},
   "source": [
    "# ReAct Style\n",
    "1. Encourages explicit reasoning, not just end answers\n",
    "1. Allows the model to interleave thoughts and actions\n",
    "1. Great for use with tools or plugins (e.g., search, code exec, database)\n",
    "1. Makes model behavior transparent and verifiable\n",
    "\n",
    "## Template\n",
    "\n",
    "1. Question: [user question]\n",
    "1. Thought: [model's internal reasoning]\n",
    "1. Action: [some action like Search(), Calculator(), API call]\n",
    "1. Observation: [result of the action]\n",
    "\n",
    "...repeat Thought → Action → Observation...\n",
    "\n",
    "Answer: [final response to the question]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79fa18-b317-4614-b282-83134b135359",
   "metadata": {},
   "source": [
    "TODO: Explain/introduce \"few shot prompting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f08e9f4-90e1-4b76-acbb-bd7d20fcc411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static example to demonstrate format (few-shot learning)\n",
    "\n",
    "few_shot_example = (\n",
    "    \"Question: What is the capital of the country that borders Germany and has Vienna as its capital?\\n\"\n",
    "    \"Thought: I need to find which country has Vienna as its capital.\\n\"\n",
    "    \"Action:  Lookup('country with capital Vienna')\\n\"\n",
    "    \"Observation: Austria\\n\"\n",
    "    \"Thought: Now check if Austria borders Germany.\\n\"\n",
    "    \"Action:  Lookup('Does Austria border Germany?')\\n\"\n",
    "    \"Observation: Yes\\n\"    \n",
    "    \"Answer: The capital of Austria, which borders Germany, is Vienna.\"\n",
    "    )\n",
    "\n",
    "question = \"what is elevation range for the area that the eastern sector of colorado orogeny extends into?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d9bad-abda-43fc-a60b-1e9102095c0a",
   "metadata": {},
   "source": [
    "Note - \n",
    "- In the last example for CoT, the system prompt got the examples.\n",
    "- In this example, we keep pass the example data with each questions.\n",
    "It is just 2 different styles to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee5e962-da45-489e-97ad-2aace3c4809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to find out about the eastern sector of the Colorado Orogeny and its elevation range.\n",
      "Action: Lookup('eastern sector of the Colorado Orogeny')\n",
      "Observation:\n",
      "\n",
      "The Eastern Slope of Colorado's Rocky Mountain system begins east of the Great Continental Divide (Rockies). It extends east and slopes down gradually to the high plains eastward. The eastern section runs from south to north through a series of low to high mountain ranges and is part of the Rocky Mountains, although it is not the highest in elevation as compared to the Western Slope.\n",
      "\n",
      "**Elevation Range**: (5,000 - 14,000 feet) or (**~1535 meters**).\n",
      "\n",
      "Answer: The elevation range for the area that the eastern sector of the Colorado Orogeny extends into is approximately 5,000 to 14,000 feet.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"{few_shot_example}\n",
    "\n",
    "Question: {question}\n",
    "Thought:\"\"\"\n",
    "\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Answer questions using a ReAct format: Thought → Action → Observation → Answer.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e86f2-6d0b-4d01-9a61-c0cbe078eb20",
   "metadata": {},
   "source": [
    "# Chain of Thought (CoT) vs ReAct (Reasoning + Acting)\n",
    "\n",
    "## Chain of Thought (CoT)\n",
    "What it is:\n",
    "Just reasoning — step-by-step thoughts leading to an answer.\n",
    "\n",
    "\n",
    "|Strengths|Limitations|\n",
    "|---|---|\n",
    "|Good for pure reasoning tasks (math, logic, factual multi-step questions).|Doesn’t interact with external tools or sources.|\n",
    "|Easy to implement.|Limited when answers need fresh data, search, or database queries.|\n",
    "|Transparent: you can see the reasoning path.||\n",
    "\n",
    "\n",
    "## ReAct (Reasoning + Acting)\n",
    "What it is:\n",
    "A prompt style that combines reasoning (like CoT) with actions, such as calling tools, web searches, or internal functions. Often used with agents.\n",
    "\n",
    "\n",
    "|Strengths|Limitations|\n",
    "|---|---|\n",
    "|Perfect for agent workflows, e.g., answering based on tool output, RAG systems, browsing, calling APIs.|More complex to implement (you need tool handlers or agents).|\n",
    "|Enables decision-making with dynamic data.|Harder to debug if the chain gets too long or recursive.|\n",
    "|You can plug in your own tools, like databases, vector search, etc.||\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
