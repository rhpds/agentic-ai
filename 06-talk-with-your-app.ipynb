{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# Talk to your App\n",
    "\n",
    "In majority of the examples, LLM Usage is shown as a chat-bot or personal assistant. \n",
    "\n",
    "A more powerful usage of Agentic-AI are when they interact with the system in the background and enrich it or take autonomous actions. This is conceptually similar to streaming analytics - with analytics being processed by Agents powered by LLMs.\n",
    "\n",
    "You will see that for chat-bot type usage - if the AI infrastructure is down, things still work.\n",
    "However for the Agents in backend - if the AI system is down, then the system will suffer some down time.\n",
    "\n",
    "_Each module is typically dependent on the prior modules having been completed successfully_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a049faf1-8a5c-4b36-a85c-7f7627635c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model setup - OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: dummy_key. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from agents import Agent, ModelSettings, function_tool,Runner,AsyncOpenAI,OpenAIChatCompletionsModel\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from rich.pretty import pprint\n",
    "\n",
    "\n",
    "# llm=\"mistral-small:latest\"\n",
    "\n",
    "# llm = \"qwen3:32b\"\n",
    "\n",
    "model = \"llama3.2:3b-instruct-fp16\" \n",
    "base_url = \"http://localhost:11434/v1/\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dummy_key\" \n",
    "model = OpenAIChatCompletionsModel( \n",
    "    model=model,\n",
    "    openai_client=AsyncOpenAI(base_url=base_url)\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Model setup - OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af63f69-2d06-40f9-9fa5-cc490cf11768",
   "metadata": {},
   "source": [
    "## Automated Error Handling\n",
    "\n",
    "1.The process is started when an ansible job log completion data comes in. (as of now, we simulate this as a user input)\n",
    "1. It examimes if there is any error. If no error, it ends\n",
    "1. If there is an error:\n",
    "    - Agent analyzes and recommends\n",
    "    - Agent opens a jira ticket\n",
    "    - Agent sends a slack message\n",
    "\n",
    "![Workflow](resources/images/agent_log_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f956699-6763-4872-a4c5-8fe453c8165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Advisor:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Slacker:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class JIRAer:\n",
    "    body: str\n",
    "\n",
    "\n",
    "advisor_agent = Agent(\n",
    "    name=\"advisor_agent\",\n",
    "    instructions=\"You can look at the contents of an ansible log and spot the error. You will describe what the error is in a few crisp sentences so that a human can take corrective actions.\",\n",
    "    model = model,\n",
    "    output_type=Advisor,\n",
    ")\n",
    "\n",
    "slack_agent = Agent(\n",
    "    name=\"slack_agent\",\n",
    "    instructions=\"If there is an error captured in the input, you will always state - I have slacked the message. Also add the contents that in the provided input. Give a made up slack link. If there is no error, then just say - All is well, there is nothing to be done.\",\n",
    "    model = model,\n",
    "    output_type=Slacker,\n",
    ")\n",
    "\n",
    "jira_agent = Agent(\n",
    "    name=\"jira_agent\",\n",
    "    instructions=\"If there is an error captured in the input, you will always state - I have opened a JIRA ticket. Also add the contents that in the provided input. Give a made up JIRA Handle. If there is no error, then just say - All is well, there is nothing to be done.\",\n",
    "    model = model,\n",
    "    output_type=JIRAer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07d1120-a9f5-4727-aaff-e2865f2a85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Advisor Output----------\n",
      "ssh_exchange_ident_err\n",
      "Error message: \n",
      "The authentication method `password` requires a username and a secret key or other non-password authentication method. In order to use 'ansible' to manage remote hosts you must add the user's keys, or make sure your password is not expired (it should be set in 'expire date' before running 'ssh -p ...')\n",
      "\n",
      "Error on host: {'AnsibleHost': {'name': \"localhost\"}}\n",
      "----------JIRA Output----------\n",
      "<html><body>Internal Server Error</body></html>\n",
      "----------Slack Output----------\n",
      "<html><body>Sorry <a href=\"https://slack.com/share/BU3X0R9FV\">the link to slack</a></body></html>\n"
     ]
    }
   ],
   "source": [
    "#msg = \"all tasks successfully finished\"\n",
    "msg = \"could not connect to the host as the password as expired. \"\n",
    "inputs = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "#with trace(\"Router\"):\n",
    "#    story_outline_result = await Runner.run(advisor_agent,inputs)\n",
    "#    #uncomment this to see the details\n",
    "#    pprint(story_outline_result)\n",
    "#    print(\"--------------------------\")\n",
    "#    print(story_outline_result.final_output)\n",
    "\n",
    "with trace(\"Workflow\"):\n",
    "    print(\"----------Advisor Output----------\")\n",
    "    advisor_result = await Runner.run(advisor_agent,inputs)\n",
    "    print(advisor_result.final_output.body)\n",
    "    advisor_output: Advisor = advisor_result.final_output\n",
    "    \n",
    "    print(\"----------JIRA Output----------\")\n",
    "    jira_result = await Runner.run(jira_agent,advisor_output.body)\n",
    "    print(jira_result.final_output.body)\n",
    "    \n",
    "    print(\"----------Slack Output----------\")\n",
    "    slack_result = await Runner.run(slack_agent,advisor_output.body)\n",
    "    print(slack_result.final_output.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9ab57-7246-4c17-a9c1-2ccc9a7cc487",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop\n",
    "But LLMs hallucinate!\n",
    "\n",
    "Yes, LLMs, just like traditional AI and human beings may not always give the right answer. To handle those kind of possible mistakes, we have processes in place.\n",
    "\n",
    "In the above example, we are seamlessly blending human-in-the-loop when we open a JIRA ticket or Slack a message. Even if the contents of these are not entirely accurate, we do not lose much because a person can check and correct if needed. \n",
    "\n",
    "In distributed systems, there are lots of similar examples - which has been around us for a long time - to take care of possible errors: for example those which arise out of CAP Theorem related inconsistencies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc062f-d913-4042-b4a3-2f0d6d075d55",
   "metadata": {},
   "source": [
    "## Extend the Debugging Agent capabilities to make it robust\n",
    "We shared in 05-agents.ipynb a debugger agent. Let us make it more robust. What happens if the answer given by the debugger has obvious gaps or hallucinates. Can we get another agent to review it and fix it? Let us see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c6be0-9da0-4219-92b6-caa5d6744d62",
   "metadata": {},
   "source": [
    "### This is a clone of the last lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780c5079-3470-4334-a74c-ec332bc4c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_dependency(service:str) ->list[str]:\n",
    "    dep_service=[\"ProductCatalogService\",\"CheckoutService\",\"UserProfileService\"] \n",
    "    return dep_service\n",
    "\n",
    "did_agent = Agent(\n",
    "    name=\"DependencyIdentifier Agent\",\n",
    "    instructions=(\n",
    "        \"An incident will be passed on.\\n\"\n",
    "        \"From that, firstly identify the affected service name only.\\n\"\n",
    "        \"Next, identify what are the service dependencies for that service.\\n\"\n",
    "        \"Just return all service names in a comma separated format like a python list[str]. Also include the affected service.\\n\"\n",
    "        \"And nothing else\"\n",
    "    ),\n",
    "    model=model,\n",
    "    tools=[get_dependency],\n",
    ")\n",
    "\n",
    "@function_tool\n",
    "def get_changelog(service:list) ->list[str]:\n",
    "    change_log=[\"ProductCatalogService changed\",\"CheckoutService changed\"]\n",
    "    return change_log\n",
    "\n",
    "change_agent = Agent(\n",
    "    name=\"ChangeLog Agent\",\n",
    "    instructions=(\n",
    "        \"An array of service names will be passed on.\\n\"\n",
    "        \"Identify what has changed with these services and return them.\\n\"\n",
    "        \"Just return all changes in a comma separated format like a python list[str].\\n\"\n",
    "        \"Do not return duplicate changes\"\n",
    "    ),\n",
    "    model= model,\n",
    "    tools=[get_changelog],\n",
    ")\n",
    "\n",
    "@function_tool\n",
    "def get_errorlog(service:list) ->list[str]:\n",
    "    error_log=[\"ProductCatalogService is responding slowly\"]\n",
    "    return error_log\n",
    "\n",
    "error_agent = Agent(\n",
    "    name=\"Error Log Agent\",\n",
    "    instructions=(\n",
    "        \"An array of service names will be passed on. \\n\"\n",
    "        \"Note that all services may not have error messages and it is unlikely that same message appear in logs of all services. \\n\"\n",
    "        \"The error messages will have service names in the messages. \\n\"\n",
    "        \"Identify the error messages in the logs if any and corresponding service name in which the error happens\"\n",
    "    ),\n",
    "    model=model,\n",
    "    tools=[get_errorlog],\n",
    ")\n",
    "\n",
    "debugger_agent = Agent(\n",
    "    name=\"Debugger Agent\",\n",
    "    instructions=(\n",
    "        \"You will be given:\\n\"\n",
    "        \"1. Incident details.\\n\"\n",
    "        \"2. Services that could have been root cause of the problem.\\n\"\n",
    "        \"3. Services that were changed in the time interval.\\n\"\n",
    "        \"4. Services that had errors in the logs.\\n\"\n",
    "        \"Based on the above, loigically think through and conclude the most likely reason for this problem. \\n\"\n",
    "        \"Please lay down your thought process clearly that led you to the conclusion. \"\n",
    "    ),\n",
    "    model= model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afeaab-4a33-4a8a-8eb7-3f7e8caef050",
   "metadata": {},
   "source": [
    "### Now let us add a new agent\n",
    "We add a Verification Agent whose sole job is to audit each diagnosis before you act on it. In practice this agent will:\n",
    "\n",
    "- Read the incident summary, the list of services, and the debugger’s reasoning\n",
    "- Check for mismatches or missing facts (e.g., a service name dropped or an error overlooked)\n",
    "- Flag any inconsistencies or confirm “All clear”\n",
    "\n",
    "By doing so, we get an extra safety net that catches accidental oversights or AI hallucinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5a17b3-def9-4052-8a3c-347504bf644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_agent = Agent(\n",
    "    name=\"Verification Agent\",\n",
    "    instructions=(\n",
    "        \"You’ll be given four parts:\\n\"\n",
    "        \"1) The incident description\\n\"\n",
    "        \"2) A list of services\\n\"\n",
    "        \"3) The debugger agent’s full reasoning and conclusion\\n\\n\"\n",
    "        \"Check for any of these issues:\\n\"\n",
    "        \" • References to services not in the original list\\n\"\n",
    "        \" • Conclusions that contradict the provided errors/changes\\n\"\n",
    "        \" • Missing any service that clearly had errors or changes\\n\\n\"\n",
    "        \"If everything is consistent, reply “Consistent”. Otherwise, list the problems.\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb30817-5cd1-4dda-a44a-af1e9d87f397",
   "metadata": {},
   "source": [
    "### Notice the new section added under orchestrate\n",
    "Invokes the verification agent after debugger agent is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea7428cc-a2b1-47ef-80be-d07ff78512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def orchestrate(input):\n",
    "    # Call the intermediate agents to gather the facts\n",
    "    # These all use tools heavily\n",
    "    dep_result = await Runner.run(did_agent,input)\n",
    "    change_result = await Runner.run(change_agent, dep_result.final_output)\n",
    "    error_result = await Runner.run(error_agent, dep_result.final_output)\n",
    "\n",
    "    services = dep_result.final_output               # e.g. [\"foo\",\"bar\",\"baz\"]\n",
    "    changes  = change_result.final_output             # e.g. [\"foo changed\",\"bar changed\"]\n",
    "    errors   = error_result.final_output              # e.g. [\"foo is responding slowly\"]\n",
    "\n",
    "    # Build a single prompt string:\n",
    "    message = (\n",
    "        \"Incident details: \" + input + \"\\n\"\n",
    "        \"Affected services: \" + services + \"\\n\"\n",
    "        \"Changes detected: \" + changes + \"\\n\"\n",
    "        \"Error logs: \" + errors + \"\\n\"\n",
    "        \"Based on the above, logically think through and conclude the most likely reason for this problem. \"\n",
    "        \"Please lay down your thought process clearly that led you to the conclusion.\"\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    print(\"Input to the Deubgger Agent: \")\n",
    "    print(\"-----------------------------\")\n",
    "    print(message)\n",
    "    print(\"\\n\")\n",
    "    # Invoke it:\n",
    "    debugger_result = await Runner.run(debugger_agent, message)\n",
    "    print(\"=== Debugger Thought Process & Conclusion ===\")\n",
    "    print(debugger_result.final_output)\n",
    "\n",
    "    # New Section:    \n",
    "    verification_prompt = (\n",
    "        \"Incident details: \" + input + \"\\n\"\n",
    "        \"Affected services: \" + services + \"\\n\"\n",
    "        f\"Debugger reasoning:\\n{debugger_result.final_output}\\n\\n\"\n",
    "        \"Please check:\\n\"\n",
    "        \" • Are all referenced services in the original list?\\n\"\n",
    "        \" • Does the conclusion contradict any errors/changes?\\n\"\n",
    "        \"If everything is consistent, reply “Consistent”. \"\n",
    "        \"Otherwise list the issues you see.\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Input to the Verification Agent: \")\n",
    "    print(\"---------------------------------\")\n",
    "    print(verification_prompt)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    verification_result = await Runner.run(verification_agent, verification_prompt)\n",
    "    #pprint(verification_result.final_output)\n",
    "    return verification_result.final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf764e-5645-4ac5-a316-ea79f5afb6ed",
   "metadata": {},
   "source": [
    "### Calling the orchestration function as in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d897a5-098f-4ea4-8757-1bbe66a364df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input to the Deubgger Agent: \n",
      "-----------------------------\n",
      "Incident details: Incident: ShoppingCart response time has increased to 10 sec\n",
      "Affected services: \"Shoplifting and Cart Overflow detected. Investigating Cart optimization and ProductCatelog service dependencies.\"\n",
      "Changes detected: I've analyzed the changes in the cart optimization and product catalog services. Here is a list of changes found:\n",
      "\n",
      "ProductCatalogService changed, CheckoutService changed \n",
      "\n",
      "Please let me know if you'd like more information about these updates.\n",
      "Error logs: It appears that the input provided to the `get_errorlog` tool is not in the correct format.\n",
      "\n",
      "A more accurate response from a log investigation would be:\n",
      "\n",
      "The errors detected are related to \"Cart Overflow\" and \"ProductCatalog\" services. However, without further information or a detailed log output, it's challenging to pinpoint exact error messages.\n",
      "\n",
      "If you'd like to investigate this issue further or request additional logs, please let me know how best to assist you.\n",
      "Based on the above, logically think through and conclude the most likely reason for this problem. Please lay down your thought process clearly that led you to the conclusion.\n",
      "\n",
      "\n",
      "=== Debugger Thought Process & Conclusion ===\n",
      "Here's my thought process:\n",
      "\n",
      "**Initial Thoughts**\n",
      "\n",
      "Upon reading the incident details, I understand that the shopping cart response time has increased to 10 seconds, which is a significant issue from a user experience perspective.\n",
      "\n",
      "The affected services mentioned seem like potential areas of impact, but they don't directly relate to a typical cause for a slow shopping cart. The focus on \"Shoplifting and Cart optimization\" makes me think that there might be some underlying configuration or dependency issues related to the cart service.\n",
      "\n",
      "**Analyzing Changes Detected**\n",
      "\n",
      "I've analyzed the changes in the ProductCatalogService and CheckoutService, as mentioned in the affected services list. These are two separate entities providing different functionalities:\n",
      "\n",
      "1. **ProductCatalogService**: This service likely provides product information such as names, descriptions, and images.\n",
      "2. **CheckoutService**: This service handles the checkout process, including calculating totals, processing payments, and updating cart contents.\n",
      "\n",
      "Given that both of these services have experienced changes in the investigation time frame (product catalog service was changed, and checkout service also had changes), I start to suspect that there might be some dependency issues between the two services.\n",
      "\n",
      "**Analyzing Error Logs**\n",
      "\n",
      "The error logs mention \"Cart Overflow\" and \"ProductCatalog\" services but lack more specific information about actual error messages. While this is a typical issue with such data collection tools, it still implies that the problems experienced are related to these dependencies.\n",
      "\n",
      "Given the impact on user experience (10-second response times) and the fact that both product catalog service and checkout service have been affected by recent changes, I'm starting to lean towards a dependency between these services as the root cause of the issue.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Based on my analysis, **the most likely reason for the shopping cart response time increase is related to a dependency issue between the ProductCatalogService and CheckoutService**, possibly due to incorrect interactions or dependencies between them. These changes in both services have caused potential cart overflow issues that further exacerbate the problem.\n",
      "\n",
      "The lack of explicit error messages from the log investigation suggests that this is not simply a misconfigured setting but perhaps a more complex issue involving service interaction and dependencies, affecting the performance of the checkout process, leading to prolonged response times for cart-related operations.\n",
      "\n",
      "\n",
      "Input to the Verification Agent: \n",
      "---------------------------------\n",
      "Incident details: Incident: ShoppingCart response time has increased to 10 sec\n",
      "Affected services: \"Shoplifting and Cart Overflow detected. Investigating Cart optimization and ProductCatelog service dependencies.\"\n",
      "Debugger reasoning:\n",
      "Here's my thought process:\n",
      "\n",
      "**Initial Thoughts**\n",
      "\n",
      "Upon reading the incident details, I understand that the shopping cart response time has increased to 10 seconds, which is a significant issue from a user experience perspective.\n",
      "\n",
      "The affected services mentioned seem like potential areas of impact, but they don't directly relate to a typical cause for a slow shopping cart. The focus on \"Shoplifting and Cart optimization\" makes me think that there might be some underlying configuration or dependency issues related to the cart service.\n",
      "\n",
      "**Analyzing Changes Detected**\n",
      "\n",
      "I've analyzed the changes in the ProductCatalogService and CheckoutService, as mentioned in the affected services list. These are two separate entities providing different functionalities:\n",
      "\n",
      "1. **ProductCatalogService**: This service likely provides product information such as names, descriptions, and images.\n",
      "2. **CheckoutService**: This service handles the checkout process, including calculating totals, processing payments, and updating cart contents.\n",
      "\n",
      "Given that both of these services have experienced changes in the investigation time frame (product catalog service was changed, and checkout service also had changes), I start to suspect that there might be some dependency issues between the two services.\n",
      "\n",
      "**Analyzing Error Logs**\n",
      "\n",
      "The error logs mention \"Cart Overflow\" and \"ProductCatalog\" services but lack more specific information about actual error messages. While this is a typical issue with such data collection tools, it still implies that the problems experienced are related to these dependencies.\n",
      "\n",
      "Given the impact on user experience (10-second response times) and the fact that both product catalog service and checkout service have been affected by recent changes, I'm starting to lean towards a dependency between these services as the root cause of the issue.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Based on my analysis, **the most likely reason for the shopping cart response time increase is related to a dependency issue between the ProductCatalogService and CheckoutService**, possibly due to incorrect interactions or dependencies between them. These changes in both services have caused potential cart overflow issues that further exacerbate the problem.\n",
      "\n",
      "The lack of explicit error messages from the log investigation suggests that this is not simply a misconfigured setting but perhaps a more complex issue involving service interaction and dependencies, affecting the performance of the checkout process, leading to prolonged response times for cart-related operations.\n",
      "\n",
      "Please check:\n",
      " • Are all referenced services in the original list?\n",
      " • Does the conclusion contradict any errors/changes?\n",
      "If everything is consistent, reply “Consistent”. Otherwise list the issues you see.\n",
      "\n",
      "\n",
      "=============================================\n",
      "=== Verifier Thought Process & Conclusion ===\n",
      "=============================================\n",
      "The reference to \"CheckoutService\" is not in the original list of affected services provided in the incident details. The original list only mentions:\n",
      "\n",
      "1. Shoplifting and Cart Overflow detected.\n",
      "2. Investigating Cart optimization \n",
      "\n",
      "While both services are indeed closely related, only the ProductCatalogService is actually listed as impacted by changes.\n",
      "\n",
      "The conclusion doesn't contradict any errors or changes, but there's a discrepancy with the originally provided list of affected services.\n"
     ]
    }
   ],
   "source": [
    "input = \"Incident: ShoppingCart response time has increased to 10 sec\"\n",
    "diagnosis = await orchestrate(input)\n",
    "print(\"=============================================\")\n",
    "print(\"=== Verifier Thought Process & Conclusion ===\")\n",
    "print(\"=============================================\")\n",
    "print(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663c41-0c58-4cce-b6c3-a40264facbf6",
   "metadata": {},
   "source": [
    "# Going into Production\n",
    "\n",
    "We have seen now how a so called output by AI can be cross checked. This is widely used pattern in Agentic workflows.\n",
    "\n",
    "One other important issue - how does the system Learn ?\n",
    "\n",
    "1. Let us say Agentic application gives a certain resolution to an incident.\n",
    "1. And the engineer verifies it to be correct.\n",
    "1. Or the engineer verifies it not be correct and knows the correct solution.\n",
    "\n",
    "How can we enhance our agentic application with this.\n",
    "\n",
    "## Learning\n",
    "### Integrate Human Feedback\n",
    "- Whenever the Verification Agent flags a problem, route the case to an engineer for review.\n",
    "- Provide a simple thumbs-up/thumbs-down or rating interface. Feed that rating back into your store.\n",
    "- Also think of allowing general text entry field allowing engineer to enter what was done, if it was a thumbs down\n",
    "\n",
    "### Capture and store outcomes\n",
    "- Capture the above data and store it in a database\n",
    "\n",
    "### Feedback the data\n",
    "- Provide this data as an additional context to the debugger agent (or perhaps add another agent) which looks at this data and fine tunes the recommendation.\n",
    "\n",
    "### Continuously refine your agents\n",
    "- Periodically pull the best-rated incident examples (and their human-approved diagnoses) to create few-shot prompts or even fine-tune a custom model.\n",
    "- Update agent instructions based on common failure modes (e.g. “always double-check inventory data”).\n",
    "\n",
    "Some of the other next steps could be -\n",
    "\n",
    "## Build visibility and dashboards\n",
    "- Surface the agents’ findings and verification results in a team dashboard—showing average time to diagnosis, verification pass rates, and automation success rates.\n",
    "- Use that data to spot gaps (e.g. Services that consistently fool the Debugger) and add new special-purpose agents.\n",
    "\n",
    "## Hook into real incident streams\n",
    "- Connect the orchestration function to the monitoring/alerting system (e.g. Prometheus Alertmanager, CloudWatch Alarms, PagerDuty webhooks). Therefore every time an alert fires for “shopping-cart latency,” the agents automatically kick off the dependency→change→error→debug→verify chain.\n",
    "\n",
    "## Future State\n",
    "- Let us imagine a state in future where there may be many agents that can gather data. In the above example it was confined to 3:\n",
    "  - discovering service dependency,\n",
    "  - looking at change log and\n",
    "  - looking at application logs.\n",
    "Let us say there are agents for metrics, anomaly detection, cluster health (for the cluster on which the service is running on etc).\n",
    "- In that case, the incident could go to a `Planner agent` that decides to breakdown the troubleshooting into steps and call agents for each steps.\n",
    "- And then hand over the summary to the Debugger Agent and Verifier agent as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08d242-e381-4802-83de-437f341c68a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
