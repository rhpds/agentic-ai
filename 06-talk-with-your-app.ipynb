{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# Talk to your App\n",
    "\n",
    "In majority of the examples, LLM Usage is shown as a chat-bot or personal assistant. \n",
    "\n",
    "A more powerful usage of Agentic-AI are when they interact with the system in the background and enrich it or take autonomous actions. This is conceptually similar to streaming analytics - with analytics being processed by Agents powered by LLMs.\n",
    "\n",
    "You will see that for chat-bot type usage - if the AI infrastructure is down, things still work.\n",
    "However for the Agents in backend - if the AI system is down, then the system will suffer some down time.\n",
    "\n",
    "_Each module is typically dependent on the prior modules having been completed successfully_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049faf1-8a5c-4b36-a85c-7f7627635c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from agents import Agent, ModelSettings, function_tool,Runner,AsyncOpenAI,OpenAIChatCompletionsModel\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from rich.pretty import pprint\n",
    "\n",
    "\n",
    "# llm=\"mistral-small:latest\"\n",
    "\n",
    "llm = \"qwen3:32b\"\n",
    "base_url = \"http://localhost:11434/v1/\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dummy_key\" \n",
    "model = OpenAIChatCompletionsModel( \n",
    "    model=llm,\n",
    "    openai_client=AsyncOpenAI(base_url=base_url)\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Model setup - OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af63f69-2d06-40f9-9fa5-cc490cf11768",
   "metadata": {},
   "source": [
    "## Automated Error Handling\n",
    "\n",
    "1.The process is started when an ansible job log completion data comes in. (as of now, we simulate this as a user input)\n",
    "1. It examimes if there is any error. If no error, it ends\n",
    "1. If there is an error:\n",
    "    - Agent analyzes and recommends\n",
    "    - Agent opens a jira ticket\n",
    "    - Agent sends a slack message\n",
    "\n",
    "![Workflow](resources/images/agent_log_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f956699-6763-4872-a4c5-8fe453c8165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Advisor:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Slacker:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class JIRAer:\n",
    "    body: str\n",
    "\n",
    "\n",
    "advisor_agent = Agent(\n",
    "    name=\"advisor_agent\",\n",
    "    instructions=\"You can look at the contents of an ansible log and spot the error. You will describe what the error is in a few crisp sentences so that a human can take corrective actions.\",\n",
    "    model = model,\n",
    "    output_type=Advisor,\n",
    ")\n",
    "\n",
    "slack_agent = Agent(\n",
    "    name=\"slack_agent\",\n",
    "    instructions=\"If there is an error captured in the input, you will always state - I have slacked the message. Also add the contents that in the provided input. Give a made up slack link. If there is no error, then just say - All is well, there is nothing to be done.\",\n",
    "    model = model,\n",
    "    output_type=Slacker,\n",
    ")\n",
    "\n",
    "jira_agent = Agent(\n",
    "    name=\"jira_agent\",\n",
    "    instructions=\"If there is an error captured in the input, you will always state - I have opened a JIRA ticket. Also add the contents that in the provided input. Give a made up JIRA Handle. If there is no error, then just say - All is well, there is nothing to be done.\",\n",
    "    model = model,\n",
    "    output_type=JIRAer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d1120-a9f5-4727-aaff-e2865f2a85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#msg = \"all tasks successfully finished\"\n",
    "msg = \"could not connect to the host as the password as expired. \"\n",
    "inputs = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "#with trace(\"Router\"):\n",
    "#    story_outline_result = await Runner.run(advisor_agent,inputs)\n",
    "#    #uncomment this to see the details\n",
    "#    pprint(story_outline_result)\n",
    "#    print(\"--------------------------\")\n",
    "#    print(story_outline_result.final_output)\n",
    "\n",
    "with trace(\"Workflow\"):\n",
    "    print(\"----------Advisor Output----------\")\n",
    "    advisor_result = await Runner.run(advisor_agent,inputs)\n",
    "    print(advisor_result.final_output.body)\n",
    "    advisor_output: Advisor = advisor_result.final_output\n",
    "    \n",
    "    print(\"----------JIRA Output----------\")\n",
    "    jira_result = await Runner.run(jira_agent,advisor_output.body)\n",
    "    print(jira_result.final_output.body)\n",
    "    \n",
    "    print(\"----------Slack Output----------\")\n",
    "    slack_result = await Runner.run(slack_agent,advisor_output.body)\n",
    "    print(slack_result.final_output.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9ab57-7246-4c17-a9c1-2ccc9a7cc487",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop\n",
    "But LLMs hallucinate!\n",
    "\n",
    "Yes, LLMs, just like traditional AI and human beings may not always give the right answer. To handle those kind of possible mistakes, we have processes in place.\n",
    "\n",
    "In the above example, we are seamlessly blending human-in-the-loop when we open a JIRA ticket or Slack a message. Even if the contents of these are not entirely accurate, we do not lose much because a person can check and correct if needed. \n",
    "\n",
    "In distributed systems, there are lots of similar examples - which has been around us for a long time - to take care of possible errors: for example those which arise out of CAP Theorem related inconsistencies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc062f-d913-4042-b4a3-2f0d6d075d55",
   "metadata": {},
   "source": [
    "## Extend the Debugging Agent capabilities to make it robust\n",
    "We shared in 05-agents.ipynb a debugger agent. Let us make it more robust. What happens if the answer given by the debugger has obvious gaps or hallucinates. Can we get another agent to review it and fix it? Let us see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c6be0-9da0-4219-92b6-caa5d6744d62",
   "metadata": {},
   "source": [
    "### This is a clone of the last lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780c5079-3470-4334-a74c-ec332bc4c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_dependency(service:str) ->list[str]:\n",
    "    dep_service=[\"ProductCatalogService\",\"CheckoutService\",\"UserProfileService\"] \n",
    "    return dep_service\n",
    "\n",
    "did_agent = Agent(\n",
    "    name=\"DependencyIdentifier Agent\",\n",
    "    instructions=(\n",
    "        \"An incident will be passed on.\\n\"\n",
    "        \"From that, firstly identify the affected service name only.\\n\"\n",
    "        \"Next, identify what are the service dependencies for that service.\\n\"\n",
    "        \"Just return all service names in a comma separated format like a python list[str]. Also include the affected service.\\n\"\n",
    "        \"And nothing else\"\n",
    "    ),\n",
    "    model= model,\n",
    "    tools=[get_dependency],\n",
    ")\n",
    "\n",
    "@function_tool\n",
    "def get_changelog(service:list) ->list[str]:\n",
    "    change_log=[\"ProductCatalogService changed\",\"CheckoutService changed\"]\n",
    "    return change_log\n",
    "\n",
    "change_agent = Agent(\n",
    "    name=\"ChangeLog Agent\",\n",
    "    instructions=(\n",
    "        \"An array of service names will be passed on.\\n\"\n",
    "        \"Identify what has changed with these services and return them.\\n\"\n",
    "        \"Just return all changes in a comma separated format like a python list[str].\\n\"\n",
    "        \"Do not return duplicate changes\"\n",
    "    ),\n",
    "    model= model,\n",
    "    tools=[get_changelog],\n",
    ")\n",
    "\n",
    "@function_tool\n",
    "def get_errorlog(service:list) ->list[str]:\n",
    "    error_log=[\"ProductCatalogService is responding slowly\"]\n",
    "    return error_log\n",
    "\n",
    "error_agent = Agent(\n",
    "    name=\"Error Log Agent\",\n",
    "    instructions=(\n",
    "        \"An array of service names will be passed on. \\n\"\n",
    "        \"Note that all services may not have error messages and it is unlikely that same message appear in logs of all services. \\n\"\n",
    "        \"The error messages will have service names in the messages. \\n\"\n",
    "        \"Identify the error messages in the logs if any and corresponding service name in which the error happens\"\n",
    "    ),\n",
    "    model= model,\n",
    "    tools=[get_errorlog],\n",
    ")\n",
    "\n",
    "debugger_agent = Agent(\n",
    "    name=\"Debugger Agent\",\n",
    "    instructions=(\n",
    "        \"You will be given:\\n\"\n",
    "        \"1. Incident details.\\n\"\n",
    "        \"2. Services that could have been root cause of the problem.\\n\"\n",
    "        \"3. Services that were changed in the time interval.\\n\"\n",
    "        \"4. Services that had errors in the logs.\\n\"\n",
    "        \"Based on the above, loigically think through and conclude the most likely reason for this problem. \\n\"\n",
    "        \"Please lay down your thought process clearly that led you to the conclusion. \"\n",
    "    ),\n",
    "    model= model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afeaab-4a33-4a8a-8eb7-3f7e8caef050",
   "metadata": {},
   "source": [
    "### Now let us add a new agent\n",
    "We add a Verification Agent whose sole job is to audit each diagnosis before you act on it. In practice this agent will:\n",
    "\n",
    "- Read the incident summary, the list of services, and the debugger’s reasoning\n",
    "- Check for mismatches or missing facts (e.g., a service name dropped or an error overlooked)\n",
    "- Flag any inconsistencies or confirm “All clear”\n",
    "\n",
    "By doing so, we get an extra safety net that catches accidental oversights or AI hallucinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5a17b3-def9-4052-8a3c-347504bf644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_agent = Agent(\n",
    "    name=\"Verification Agent\",\n",
    "    instructions=(\n",
    "        \"You’ll be given four parts:\\n\"\n",
    "        \"1) The incident description\\n\"\n",
    "        \"2) A list of services\\n\"\n",
    "        \"3) The debugger agent’s full reasoning and conclusion\\n\\n\"\n",
    "        \"Check for any of these issues:\\n\"\n",
    "        \" • References to services not in the original list\\n\"\n",
    "        \" • Conclusions that contradict the provided errors/changes\\n\"\n",
    "        \" • Missing any service that clearly had errors or changes\\n\\n\"\n",
    "        \"If everything is consistent, reply “Consistent”. Otherwise, list the problems.\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb30817-5cd1-4dda-a44a-af1e9d87f397",
   "metadata": {},
   "source": [
    "### Notice the new section added under orchestrate\n",
    "Invokes the verification agent after debugger agent is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7428cc-a2b1-47ef-80be-d07ff78512fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def orchestrate(input):\n",
    "    # Call the intermediate agents to gather the facts\n",
    "    # These all use tools heavily\n",
    "    dep_result = await Runner.run(did_agent,input)\n",
    "    change_result = await Runner.run(change_agent, dep_result.final_output)\n",
    "    error_result = await Runner.run(error_agent, dep_result.final_output)\n",
    "\n",
    "    services = dep_result.final_output               # e.g. [\"foo\",\"bar\",\"baz\"]\n",
    "    changes  = change_result.final_output             # e.g. [\"foo changed\",\"bar changed\"]\n",
    "    errors   = error_result.final_output              # e.g. [\"foo is responding slowly\"]\n",
    "\n",
    "    # Build a single prompt string:\n",
    "    message = (\n",
    "        \"Incident details: \" + input + \"\\n\"\n",
    "        \"Affected services: \" + services + \"\\n\"\n",
    "        \"Changes detected: \" + changes + \"\\n\"\n",
    "        \"Error logs: \" + errors + \"\\n\"\n",
    "        \"Based on the above, logically think through and conclude the most likely reason for this problem. \"\n",
    "        \"Please lay down your thought process clearly that led you to the conclusion.\"\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    print(\"Input to the Deubgger Agent: \")\n",
    "    print(\"-----------------------------\")\n",
    "    print(message)\n",
    "    print(\"\\n\")\n",
    "    # Invoke it:\n",
    "    debugger_result = await Runner.run(debugger_agent, message)\n",
    "    print(\"=== Debugger Thought Process & Conclusion ===\")\n",
    "    print(debugger_result.final_output)\n",
    "\n",
    "    # New Section:    \n",
    "    verification_prompt = (\n",
    "        \"Incident details: \" + input + \"\\n\"\n",
    "        \"Affected services: \" + services + \"\\n\"\n",
    "        f\"Debugger reasoning:\\n{debugger_result.final_output}\\n\\n\"\n",
    "        \"Please check:\\n\"\n",
    "        \" • Are all referenced services in the original list?\\n\"\n",
    "        \" • Does the conclusion contradict any errors/changes?\\n\"\n",
    "        \"If everything is consistent, reply “Consistent”. \"\n",
    "        \"Otherwise list the issues you see.\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Input to the Verification Agent: \")\n",
    "    print(\"---------------------------------\")\n",
    "    print(verification_prompt)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    verification_result = await Runner.run(verification_agent, verification_prompt)\n",
    "    #pprint(verification_result.final_output)\n",
    "    return verification_result.final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf764e-5645-4ac5-a316-ea79f5afb6ed",
   "metadata": {},
   "source": [
    "### Calling the orchestration function as in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d897a5-098f-4ea4-8757-1bbe66a364df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input to the Deubgger Agent: \n",
      "-----------------------------\n",
      "Incident details: Incident: ShoppingCart response time has increased to 10 sec\n",
      "Affected services: <think>\n",
      "Okay, let's see. The user reported that the ShoppingCart service's response time has increased to 10 seconds. First, I need to identify the affected service, which is clearly ShoppingCart.\n",
      "\n",
      "Next, I have to figure out the service dependencies for ShoppingCart. The user already called the get_dependency function with the service \"ShoppingCart\" and got the response ['ProductCatalogService', 'CheckoutService', 'UserProfileService']. \n",
      "\n",
      "So, the dependencies are those three services. The task is to return all service names, including the affected one, in a comma-separated list like a Python list of strings. That means I should combine ShoppingCart with its dependencies. Let me make sure there are no other dependencies or nested services, but the response from the tool seems to list them directly. \n",
      "\n",
      "Putting it all together: the affected service is ShoppingCart, and the dependencies are ProductCatalogService, CheckoutService, and UserProfileService. So the final list should include all four. Just need to format them correctly within the list syntax.\n",
      "</think>\n",
      "\n",
      "[\"ShoppingCart\", \"ProductCatalogService\", \"CheckoutService\", \"UserProfileService\"]\n",
      "Changes detected: <think>\n",
      "Okay, let's see. The user asked about the changes in the services related to the ShoppingCart. The initial step was to get the dependencies of the ShoppingCart service, which were ProductCatalogService, CheckoutService, and UserProfileService. Then, the user called the get_changelog function for all these services, including ShoppingCart itself. The response from the tool indicated that ProductCatalogService and CheckoutService have changes. \n",
      "\n",
      "Now, the task is to compile a list of all the changes. The tool's response says \"ProductCatalogService changed\" and \"CheckoutService changed\". So, I need to present these two changes in a comma-separated Python list format. The user specified not to include duplicates, so even if a service was mentioned multiple times, we only list each change once. Since the response only mentions two changes, the final answer should be a list with those two strings.\n",
      "</think>\n",
      "\n",
      "[\"ProductCatalogService changed\", \"CheckoutService changed\"]\n",
      "Error logs: <think>\n",
      "Okay, let's see. The user initially reported that the ShoppingCart service's response time increased to 10 seconds. I checked the dependencies using the get_dependency function and found that ShoppingCart relies on ProductCatalogService, CheckoutService, and UserProfileService. Then, I called get_errorlog on all those services and received an error message: \"ProductCatalogService is responding slowly.\"\n",
      "\n",
      "So, the error is in the ProductCatalogService. But the original issue was about ShoppingCart's response time. Since ProductCatalogService is a dependency of ShoppingCart, its slowness is likely causing the ShoppingCart's increased response time. That makes sense because if a service depends on another that's slow, the dependent service's performance would suffer.\n",
      "\n",
      "I should explain that the root cause is the ProductCatalogService's slow response, which is affecting ShoppingCart. The user might need to look into optimizing or scaling ProductCatalogService to resolve the issue. Also, maybe check if there are other errors in the other services, but the errorlog only mentioned ProductCatalogService. So the answer should highlight that ProductCatalogService is the source of the problem here.\n",
      "</think>\n",
      "\n",
      "The error message \"ProductCatalogService is responding slowly\" was identified in the logs of the **ProductCatalogService**. This likely contributes to the increased response time in the ShoppingCart service, as ProductCatalogService is one of its dependencies. No other errors were reported in the logs for the other services.\n",
      "Based on the above, logically think through and conclude the most likely reason for this problem. Please lay down your thought process clearly that led you to the conclusion.\n",
      "\n",
      "\n",
      "=== Debugger Thought Process & Conclusion ===\n",
      "<think>\n",
      "Okay, let's break this down. The user is asking why the ShoppingCart service has a 10-second response time. I've already identified the affected services and changes, and the error logs point to ProductCatalogService being slow.\n",
      "\n",
      "First, I need to connect the dots. The error log shows ProductCatalogService is responding slowly. That's a dependency of ShoppingCart, right? So if ProductCatalogService is slow, any requests that ShoppingCart makes to it would take longer, increasing the overall response time. But wait, how significant is that impact?\n",
      "\n",
      "The changelog also shows that ProductCatalogService and CheckoutService had recent changes. Maybe the changes in ProductCatalogService caused the slowdown. Could there be a code regression, or perhaps a misconfiguration after deployment? The error log doesn't mention the changes directly, but the slow response is a problem now, so it's possible that the recent update introduced a performance issue. The CheckoutService change might not be directly related unless it's interacting poorly with ProductCatalogService, but there's no evidence for that unless there's more data.\n",
      "\n",
      "Also, the error log only mentions ProductCatalogService. So while CheckoutService had changes, unless those changes caused an issue with how ShoppingCart communicates with them, it's less likely the root cause. The UserProfileService had no changes or errors, so probably not a factor here.\n",
      "\n",
      "Putting it all together: The most likely reason is the recent change to ProductCatalogService which caused it to respond slowly. Since it's a dependency of ShoppingCart, the slow response from ProductCatalogService is directly increasing the time ShoppingCart takes to process requests. The other services either had no changes (UserProfileService) or changes that aren't currently logged with issues (CheckoutService). So the root cause is the ProductCatalogService's performance degradation due to the recent change.\n",
      "</think>\n",
      "\n",
      "The most likely root cause of the ShoppingCart service's increased response time (10 seconds) is **Performance Degradation in ProductCatalogService**, as evidenced by:\n",
      "\n",
      "1. **Dependency Relationship**:  \n",
      "   - ShoppingCart depends on ProductCatalogService (confirmed via `get_dependency`).\n",
      "   - A slowdown in ProductCatalogService would directly impact ShoppingCart's end-to-end response time, as it must wait for ProductCatalogService to fulfill requests.\n",
      "\n",
      "2. **Error Log Evidence**:  \n",
      "   - The error log explicitly states **\"ProductCatalogService is responding slowly\"**. This directly explains the increased latency in the dependent ShoppingCart service.\n",
      "\n",
      "3. **Change Correlation**:  \n",
      "   - Recent changes were made to ProductCatalogService (via `get_changelog`). While the error log does not *explicitly* link the change to the slowdown, the timing of the change and the log entry strongly suggests the change introduced the performance regression (e.g., inefficient code, unexpected traffic, or misconfigured resources).\n",
      "\n",
      "4. **Elimination of Other Factors**:  \n",
      "   - CheckoutService had changes, but no errors or latency issues were reported in its logs (or in services it depends on).  \n",
      "   - UserProfileService had no changes or errors, making it an unlikely contributor.  \n",
      "\n",
      "---\n",
      "\n",
      "**Conclusion**:  \n",
      "The recent change to ProductCatalogService likely caused a performance bottleneck in that service, which cascaded to its dependent service (ShoppingCart). Engineers should prioritize investigating the ProductCatalogService change (e.g., code review, resource utilization, or latency profiling) to resolve the root cause.\n",
      "\n",
      "\n",
      "Input to the Verification Agent: \n",
      "---------------------------------\n",
      "Incident details: Incident: ShoppingCart response time has increased to 10 sec\n",
      "Affected services: <think>\n",
      "Okay, let's see. The user reported that the ShoppingCart service's response time has increased to 10 seconds. First, I need to identify the affected service, which is clearly ShoppingCart.\n",
      "\n",
      "Next, I have to figure out the service dependencies for ShoppingCart. The user already called the get_dependency function with the service \"ShoppingCart\" and got the response ['ProductCatalogService', 'CheckoutService', 'UserProfileService']. \n",
      "\n",
      "So, the dependencies are those three services. The task is to return all service names, including the affected one, in a comma-separated list like a Python list of strings. That means I should combine ShoppingCart with its dependencies. Let me make sure there are no other dependencies or nested services, but the response from the tool seems to list them directly. \n",
      "\n",
      "Putting it all together: the affected service is ShoppingCart, and the dependencies are ProductCatalogService, CheckoutService, and UserProfileService. So the final list should include all four. Just need to format them correctly within the list syntax.\n",
      "</think>\n",
      "\n",
      "[\"ShoppingCart\", \"ProductCatalogService\", \"CheckoutService\", \"UserProfileService\"]\n",
      "Debugger reasoning:\n",
      "<think>\n",
      "Okay, let's break this down. The user is asking why the ShoppingCart service has a 10-second response time. I've already identified the affected services and changes, and the error logs point to ProductCatalogService being slow.\n",
      "\n",
      "First, I need to connect the dots. The error log shows ProductCatalogService is responding slowly. That's a dependency of ShoppingCart, right? So if ProductCatalogService is slow, any requests that ShoppingCart makes to it would take longer, increasing the overall response time. But wait, how significant is that impact?\n",
      "\n",
      "The changelog also shows that ProductCatalogService and CheckoutService had recent changes. Maybe the changes in ProductCatalogService caused the slowdown. Could there be a code regression, or perhaps a misconfiguration after deployment? The error log doesn't mention the changes directly, but the slow response is a problem now, so it's possible that the recent update introduced a performance issue. The CheckoutService change might not be directly related unless it's interacting poorly with ProductCatalogService, but there's no evidence for that unless there's more data.\n",
      "\n",
      "Also, the error log only mentions ProductCatalogService. So while CheckoutService had changes, unless those changes caused an issue with how ShoppingCart communicates with them, it's less likely the root cause. The UserProfileService had no changes or errors, so probably not a factor here.\n",
      "\n",
      "Putting it all together: The most likely reason is the recent change to ProductCatalogService which caused it to respond slowly. Since it's a dependency of ShoppingCart, the slow response from ProductCatalogService is directly increasing the time ShoppingCart takes to process requests. The other services either had no changes (UserProfileService) or changes that aren't currently logged with issues (CheckoutService). So the root cause is the ProductCatalogService's performance degradation due to the recent change.\n",
      "</think>\n",
      "\n",
      "The most likely root cause of the ShoppingCart service's increased response time (10 seconds) is **Performance Degradation in ProductCatalogService**, as evidenced by:\n",
      "\n",
      "1. **Dependency Relationship**:  \n",
      "   - ShoppingCart depends on ProductCatalogService (confirmed via `get_dependency`).\n",
      "   - A slowdown in ProductCatalogService would directly impact ShoppingCart's end-to-end response time, as it must wait for ProductCatalogService to fulfill requests.\n",
      "\n",
      "2. **Error Log Evidence**:  \n",
      "   - The error log explicitly states **\"ProductCatalogService is responding slowly\"**. This directly explains the increased latency in the dependent ShoppingCart service.\n",
      "\n",
      "3. **Change Correlation**:  \n",
      "   - Recent changes were made to ProductCatalogService (via `get_changelog`). While the error log does not *explicitly* link the change to the slowdown, the timing of the change and the log entry strongly suggests the change introduced the performance regression (e.g., inefficient code, unexpected traffic, or misconfigured resources).\n",
      "\n",
      "4. **Elimination of Other Factors**:  \n",
      "   - CheckoutService had changes, but no errors or latency issues were reported in its logs (or in services it depends on).  \n",
      "   - UserProfileService had no changes or errors, making it an unlikely contributor.  \n",
      "\n",
      "---\n",
      "\n",
      "**Conclusion**:  \n",
      "The recent change to ProductCatalogService likely caused a performance bottleneck in that service, which cascaded to its dependent service (ShoppingCart). Engineers should prioritize investigating the ProductCatalogService change (e.g., code review, resource utilization, or latency profiling) to resolve the root cause.\n",
      "\n",
      "Please check:\n",
      " • Are all referenced services in the original list?\n",
      " • Does the conclusion contradict any errors/changes?\n",
      "If everything is consistent, reply “Consistent”. Otherwise list the issues you see.\n",
      "\n",
      "\n",
      "=============================================\n",
      "=== Verifier Thought Process & Conclusion ===\n",
      "=============================================\n",
      "<think>\n",
      "Okay, let's start by looking at the problem here. The user mentioned an incident where the ShoppingCart service's response time increased to 10 seconds. The debugger's reasoning points to ProductCatalogService as the root cause, citing it's responding slowly. Let me verify the services involved.\n",
      "\n",
      "First, the original list of affected services is given as ProductCatalogService, CheckoutService, and UserProfileService when querying dependencies. The debugger's conclusion focuses on ProductCatalogService. The error log for ShoppingCart includes ProductCatalogService being slow, and the changelog shows that ProductCatalogService had a recent change. The reasoning says the change might have caused the slowdown, which is a valid assumption. \n",
      "\n",
      "Now, checking if all referenced services are in the original list. The original list includes ProductCatalogService, CheckoutService, and UserProfileService. The debugger mentions ProductCatalogService and CheckoutService in the reasoning but the issue here is that CheckoutService is not linked to any errors or performance issues. The user's conclusion attributes the problem solely to ProductCatalogService, which is correct based on the error logs. However, the reasoning also mentions that CheckoutService had changes but no errors, which is noted. The conclusion seems consistent with the data provided. \n",
      "\n",
      "Wait, the user's conclusion says the root cause is ProductCatalogService. The original dependencies include CheckoutService and UserProfileService, but the error logs don't mention them. The reasoning correctly eliminates them as possible causes because there's no evidence they caused the issue. The changelog for ProductCatalogService might be the reason for the problem, and the error log supports that. So, the conclusion aligns with the data, and all referenced services are part of the original list. The only potential issue is that the reasoning mentions multiple services (ProductCatalogService and CheckoutService) but the conclusion focuses on one. However, since the error log only points to ProductCatalogService, the conclusion is accurate. \n",
      "\n",
      "I don't see any references to services outside the original list, no contradictions, and all necessary services are addressed. So the reasoning and conclusion are consistent with the provided information.\n",
      "</think>\n",
      "\n",
      "**Answer:** Consistent  \n",
      "\n",
      "**Review Breakdown:**  \n",
      "1. **All referenced services are in the original list**:  \n",
      "   - The debugger references **ProductCatalogService**, **CheckoutService**, and **UserProfileService**, all of which were explicitly called via `get_dependency(\"ShoppingCart\")`. No external services are involved.  \n",
      "\n",
      "2. **Conclusion aligns with provided errors/changes**:  \n",
      "   - The debugger attributes the issue to **ProductCatalogService** based on the error log (`\"ProductCatalogService is responding slowly\"`) and its dependency on ShoppingCart. This is supported by:  \n",
      "     - The error log directly linking ProductCatalogService to the slowdown.  \n",
      "     - The changelog noting ProductCatalogService had a recent change (though not explicitly shown in the logs, this is a reasonable hypothesis for the root cause).  \n",
      "   - **CheckoutService** is correctly dismissed as a root cause in the conclusion, despite having a recent change, since no errors or performance issues were reported for it.  \n",
      "\n",
      "3. **No missing services with errors/changes**:  \n",
      "   - All three services listed in `get_dependency` are properly evaluated.  \n",
      "     - ProductCatalogService is identified as the root cause due to error logs and a recent change.  \n",
      "     - CheckoutService and UserProfileService are ruled out due to lack of evidence (no error logs or performance issues reported for them).  \n",
      "\n",
      "No contradictions, missing services, or extraneous references are present. The reasoning and conclusion are valid given the provided data.\n"
     ]
    }
   ],
   "source": [
    "input = \"Incident: ShoppingCart response time has increased to 10 sec\"\n",
    "diagnosis = await orchestrate(input)\n",
    "print(\"=============================================\")\n",
    "print(\"=== Verifier Thought Process & Conclusion ===\")\n",
    "print(\"=============================================\")\n",
    "print(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663c41-0c58-4cce-b6c3-a40264facbf6",
   "metadata": {},
   "source": [
    "# Going into Production\n",
    "\n",
    "We have seen now how a so called output by AI can be cross checked. This is widely used pattern in Agentic workflows.\n",
    "\n",
    "One other important issue - how does the system Learn ?\n",
    "\n",
    "1. Let us say Agentic application gives a certain resolution to an incident.\n",
    "1. And the engineer verifies it to be correct.\n",
    "1. Or the engineer verifies it not be correct and knows the correct solution.\n",
    "\n",
    "How can we enhance our agentic application with this.\n",
    "\n",
    "## Learning\n",
    "### Integrate Human Feedback\n",
    "- Whenever the Verification Agent flags a problem, route the case to an engineer for review.\n",
    "- Provide a simple thumbs-up/thumbs-down or rating interface. Feed that rating back into your store.\n",
    "- Also think of allowing general text entry field allowing engineer to enter what was done, if it was a thumbs down\n",
    "\n",
    "### Capture and store outcomes\n",
    "- Capture the above data and store it in a database\n",
    "\n",
    "### Feedback the data\n",
    "- Provide this data as an additional context to the debugger agent (or perhaps add another agent) which looks at this data and fine tunes the recommendation.\n",
    "\n",
    "### Continuously refine your agents\n",
    "- Periodically pull the best-rated incident examples (and their human-approved diagnoses) to create few-shot prompts or even fine-tune a custom model.\n",
    "- Update agent instructions based on common failure modes (e.g. “always double-check inventory data”).\n",
    "\n",
    "Some of the other next steps could be -\n",
    "\n",
    "## Build visibility and dashboards\n",
    "- Surface the agents’ findings and verification results in a team dashboard—showing average time to diagnosis, verification pass rates, and automation success rates.\n",
    "- Use that data to spot gaps (e.g. Services that consistently fool the Debugger) and add new special-purpose agents.\n",
    "\n",
    "## Hook into real incident streams\n",
    "- Connect the orchestration function to the monitoring/alerting system (e.g. Prometheus Alertmanager, CloudWatch Alarms, PagerDuty webhooks). Therefore every time an alert fires for “shopping-cart latency,” the agents automatically kick off the dependency→change→error→debug→verify chain.\n",
    "\n",
    "## Future State\n",
    "- Let us imagine a state in future where there may be many agents that can gather data. In the above example it was confined to 3:\n",
    "  - discovering service dependency,\n",
    "  - looking at change log and\n",
    "  - looking at application logs.\n",
    "Let us say there are agents for metrics, anomaly detection, cluster health (for the cluster on which the service is running on etc).\n",
    "- In that case, the incident could go to a `Planner agent` that decides to breakdown the troubleshooting into steps and call agents for each steps.\n",
    "- And then hand over the summary to the Debugger Agent and Verifier agent as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08d242-e381-4802-83de-437f341c68a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
