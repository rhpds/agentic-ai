{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1160b91-0b0c-4b70-87a9-de64f88a5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "Based om Module 2 of the Deep Learning course below (LangGraph)\n",
    "\n",
    "* [A simple Python implementation of the ReAct pattern for LLMs](https://arc.net/l/quote/duflzttq)\n",
    "  * Simon Willison Blog Article\n",
    "* [Deep Learning AI Course, AI Agents with LangGraph](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/1/introduction)\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "* Pythons setup (I created a 3.11 venv)\n",
    "* OpenAI Key (Granite struggled but perhaps not a fair comparions ollama/grantite q4 8b v `gpt-4o`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a049faf1-8a5c-4b36-a85c-7f7627635c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201a5506-5b38-4fcb-a0c6-45e67a8ed5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate for swapping in Granite via ollama\n",
    "# model = \"granite3-dense:8b\"\n",
    "# client = OpenAI(\n",
    "#     base_url='http://localhost:11434/v1',\n",
    "#     api_key='ollama',\n",
    "# ) \n",
    "\n",
    "model = \"gpt-4o\"\n",
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3591d958-9c15-4abd-bfac-15ed92a988cb",
   "metadata": {},
   "source": [
    "# Quick test code - verify LLM conenctivity etc (disable via Raw)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a simple Python example class called User\"}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"{chat_completion.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fff260b-2ee5-4ae9-b66b-4c313d5df9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0,\n",
    "            messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d847b32-cdec-4a6b-94a5-e54e8f625afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11a8eb9c-fe97-4ebe-9c72-566bd0f3a975",
   "metadata": {},
   "source": [
    "# ReAct Agent Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049bda6e-d2b2-4b99-9ab9-5471161a8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run through one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "get_provision_status:\n",
    "e.g. get_provision_status: guid\n",
    "returns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\n",
    "\n",
    "log_error:\n",
    "e.g log_error: status\n",
    "When a guid has a provision_status ERROR call this with the return value of get_provision_status\n",
    "\n",
    "log_status:\n",
    "e.g log_status: status\n",
    "When a guid does not have an ERROR status call this with the return value of get_provision_status\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the staus of cloud deployment with guid <guid>\n",
    "Thought: I should look up the status with get_provision_status \n",
    "Action: get_provision_status: guid \n",
    "PAUSE:\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: Guid status \"SUCCESS: Completed\"\n",
    "\n",
    "You then call any necessary logging tools before outputing the status:\n",
    "\n",
    "Answer: Guid status \"SUCCESS: Completed\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f2cf93-87b3-430e-9a4b-0bec9eb9e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "First of the *fake* functions to test if the LLM/Prompt will ReAct correctly\n",
    "taking different paths on different results\n",
    "'''\n",
    "\n",
    "def get_provision_status(guid):\n",
    "\n",
    "    #// call to MCP Server AAP2 Controller\n",
    "    # // foo = bar()\n",
    "    \n",
    "    status_messages = [\n",
    "        \"INFO: Initializing\",\n",
    "        \"INFO: In progress\",\n",
    "        \"ERROR: Failed\",\n",
    "        \"ERROR: API Timeout\",\n",
    "        \"ERROR: Rate Limited\",\n",
    "        \"WARNING: Minor errors\",\n",
    "        \"SUCCESS: Completed\"\n",
    "    ]\n",
    "        # \"INFO: Finalizing\",\n",
    "    # return random.choice(f\"{guid} status: {status_messages}\")\n",
    "    status = random.choice(status_messages)\n",
    "    return f\"{guid} status: {status}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc6f2d9-80c9-4ad6-9165-d0158c049954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(status):\n",
    "    print(f\"{status} Logged stateus to Slack.\")\n",
    "    print(f\"{status} Opened Jira Ticket with Status.\")\n",
    "    return 0\n",
    "\n",
    "def log_status(status):\n",
    "    print(f\"{status} Logged status to Slack.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d41d31-7186-474d-b405-9a5396221d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_actions = {\n",
    "   \"log_status\": log_status,\n",
    "   \"log_error\": log_error,\n",
    "   \"get_provision_status\": get_provision_status,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47df89b-5030-4e6a-a3bd-d16e72655bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df37b053-6f9e-42ef-aa18-915bd47d6f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: App -> LLM:\n",
      "\n",
      "Role: system\n",
      "Content:\n",
      "\n",
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run through one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "get_provision_status:\n",
      "e.g. get_provision_status: guid\n",
      "returns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\n",
      "\n",
      "log_error:\n",
      "e.g log_error: status\n",
      "When a guid has a provision_status ERROR call this with the return value of get_provision_status\n",
      "\n",
      "log_status:\n",
      "e.g log_status: status\n",
      "When a guid does not have an ERROR status call this with the return value of get_provision_status\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: What is the staus of cloud deployment with guid <guid>\n",
      "Thought: I should look up the status with get_provision_status \n",
      "Action: get_provision_status: guid \n",
      "PAUSE:\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "You then call any necessary logging tools before outputing the status:\n",
      "\n",
      "Answer: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, message in  enumerate(abot.messages):\n",
    "    if message[\"role\"] != \"assistant\":\n",
    "        print(f\"Step {i}: App -> LLM:\\n\")\n",
    "    else:\n",
    "        print(f\"Step {i}: App <- LLM:\\n\")\n",
    "    print(f\"Role: {message['role']}\\nContent:\\n\\n{message['content']}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "966d030e-9050-4b31-b1f5-2585948d9869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run through one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\nget_provision_status:\\ne.g. get_provision_status: guid\\nreturns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\\n\\nlog_error:\\ne.g log_error: status\\nWhen a guid has a provision_status ERROR call this with the return value of get_provision_status\\n\\nlog_status:\\ne.g log_status: status\\nWhen a guid does not have an ERROR status call this with the return value of get_provision_status\\n\\nExample session:\\n\\nQuestion: What is the staus of cloud deployment with guid <guid>\\nThought: I should look up the status with get_provision_status \\nAction: get_provision_status: guid \\nPAUSE:\\n\\nYou will be called again with this:\\n\\nObservation: Guid status \"SUCCESS: Completed\"\\n\\nYou then call any necessary logging tools before outputing the status:\\n\\nAnswer: Guid status \"SUCCESS: Completed\"'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot = Agent(prompt)\n",
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d1a91f-48cf-4440-ba51-77b17316637a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: App -> LLM:\n",
      "\n",
      "Role: system\n",
      "Content:\n",
      "\n",
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run through one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "get_provision_status:\n",
      "e.g. get_provision_status: guid\n",
      "returns the status of a cloud deployment such as a virtual machine when gived a guid (globally unique identifier)\n",
      "\n",
      "log_error:\n",
      "e.g log_error: status\n",
      "When a guid has a provision_status ERROR call this with the return value of get_provision_status\n",
      "\n",
      "log_status:\n",
      "e.g log_status: status\n",
      "When a guid does not have an ERROR status call this with the return value of get_provision_status\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: What is the staus of cloud deployment with guid <guid>\n",
      "Thought: I should look up the status with get_provision_status \n",
      "Action: get_provision_status: guid \n",
      "PAUSE:\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "You then call any necessary logging tools before outputing the status:\n",
      "\n",
      "Answer: Guid status \"SUCCESS: Completed\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, message in  enumerate(abot.messages):\n",
    "    if message[\"role\"] != \"assistant\":\n",
    "        print(f\"Step {i}: App -> LLM:\\n\")\n",
    "    else:\n",
    "        print(f\"Step {i}: App <- LLM:\\n\")\n",
    "    print(f\"Role: {message['role']}\\nContent:\\n\\n{message['content']}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57606abf-1465-4c3d-a8fa-787d64da0826",
   "metadata": {},
   "source": [
    "# So far a bit to much \"Human in the Loop\"\n",
    "\n",
    "Let's automate all this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47413ee-c8e3-4a25-9df4-cd4a8c803796",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_re = re.compile(\"^Action: (\\w+): (.*)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a22524-fb84-4803-a9e3-c9504378d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    print(\"Step 0\")\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a)\n",
    "            for a in result.split('\\n')\n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            print(f\"\\nStep {i}\")\n",
    "            # print(f\"Actions:\\n\\n{actions}\")\n",
    "            action, action_inputs = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(f\"Unknown action: {action}: -- running {action} {action_inputs}\")\n",
    "            observation = known_actions[action](action_inputs)\n",
    "            print(f\"Observation: {observation}\")\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d9646e-eea8-41bb-a2ea-fad299ffebff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Thought: I should look up the status of the deployment with the provided guid using get_provision_status.\n",
      "Action: get_provision_status: 1adr4 \n",
      "PAUSE.\n",
      "\n",
      "Step 1\n",
      "Observation: 1adr4  status: SUCCESS: Completed\n",
      "Action: log_status: SUCCESS: Completed\n",
      "PAUSE.\n",
      "\n",
      "Step 2\n",
      "SUCCESS: Completed Logged status to Slack.\n",
      "Observation: 0\n",
      "Answer: Guid status \"SUCCESS: Completed\"\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "I have a deployments running with guid: 1adr4 what is its status\n",
    "\"\"\"\n",
    "\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb3bd2e-d259-4351-a7a0-4a57c2cbd5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Thought: I will start by checking the provision status for each of the provided guids one by one. I will then log the status accordingly and finally output the results in both a table and JSON format.\n",
      "\n",
      "Action: get_provision_status: 1adr4\n",
      "PAUSE\n",
      "\n",
      "Step 1\n",
      "Observation: 1adr4 status: INFO: Initializing\n",
      "Action: log_status: INFO: Initializing\n",
      "PAUSE\n",
      "\n",
      "Step 2\n",
      "INFO: Initializing Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: aabf5\n",
      "PAUSE\n",
      "\n",
      "Step 3\n",
      "Observation: aabf5 status: INFO: Initializing\n",
      "Action: log_status: INFO: Initializing\n",
      "PAUSE\n",
      "\n",
      "Step 4\n",
      "INFO: Initializing Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: 45663\n",
      "PAUSE\n",
      "\n",
      "Step 5\n",
      "Observation: 45663 status: INFO: Initializing\n",
      "Action: log_status: INFO: Initializing\n",
      "PAUSE\n",
      "\n",
      "Step 6\n",
      "INFO: Initializing Logged status to Slack.\n",
      "Observation: 0\n",
      "Action: get_provision_status: 45ghb\n",
      "PAUSE\n",
      "\n",
      "Step 7\n",
      "Observation: 45ghb status: ERROR: API Timeout\n",
      "Action: log_error: ERROR: API Timeout\n",
      "PAUSE\n",
      "\n",
      "Step 8\n",
      "ERROR: API Timeout Logged stateus to Slack.\n",
      "ERROR: API Timeout Opened Jira Ticket with Status.\n",
      "Observation: 0\n",
      "Answer:\n",
      "\n",
      "| GUID   | Status                  | Logging Service |\n",
      "|--------|-------------------------|-----------------|\n",
      "| 1adr4  | INFO: Initializing      | log_status      |\n",
      "| aabf5  | INFO: Initializing      | log_status      |\n",
      "| 45663  | INFO: Initializing      | log_status      |\n",
      "| 45ghb  | ERROR: API Timeout      | log_error       |\n",
      "\n",
      "JSON:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"guid\": \"1adr4\",\n",
      "        \"status\": \"INFO: Initializing\",\n",
      "        \"logging_service\": \"log_status\"\n",
      "    },\n",
      "    {\n",
      "        \"guid\": \"aabf5\",\n",
      "        \"status\": \"INFO: Initializing\",\n",
      "        \"logging_service\": \"log_status\"\n",
      "    },\n",
      "    {\n",
      "        \"guid\": \"45663\",\n",
      "        \"status\": \"INFO: Initializing\",\n",
      "        \"logging_service\": \"log_status\"\n",
      "    },\n",
      "    {\n",
      "        \"guid\": \"45ghb\",\n",
      "        \"status\": \"ERROR: API Timeout\",\n",
      "        \"logging_service\": \"log_error\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"\"\"\n",
    "I have deployments running with guids: 1adr4, aabf5, 45663, and 45ghb\n",
    "First get each provision status and log to any services that need to know\n",
    "Once finished with all deployments output their guids, status, and logging services:\n",
    "\n",
    "* In a simple table\n",
    "* As JSON \n",
    "\"\"\"\n",
    "\n",
    "query(question, max_turns=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f202e6-e0e8-4e2a-bb4c-e4a655b9bc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
