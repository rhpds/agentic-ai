{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8987006-614e-41b7-9c2f-aa6359e8e231",
   "metadata": {},
   "source": [
    "# Tools, API & Microservices\n",
    "\n",
    "Now that we have seen the power of prompts and a look how they come together in a simple agent, lets explore formally a few other concepts.\n",
    "\n",
    "1. Function calling\n",
    "2. Tool Calling\n",
    "3. Introduction to Agents\n",
    "4. Agents calling tools\n",
    "5. Agentic Patterns\n",
    "6. Agents and Microservices\n",
    "\n",
    "_Each module is typically dependent on the prior modules having been completed successfully_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870cab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents==0.0.13\n",
      "  Downloading openai_agents-0.0.13-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents==0.0.13)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting mcp<2,>=1.6.0 (from openai-agents==0.0.13)\n",
      "  Downloading mcp-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: openai>=1.76.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai-agents==0.0.13) (1.76.2)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai-agents==0.0.13) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai-agents==0.0.13) (2.32.3)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents==0.0.13)\n",
      "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai-agents==0.0.13) (4.13.2)\n",
      "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents==0.0.13)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio>=4.5 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from mcp<2,>=1.6.0->openai-agents==0.0.13) (4.9.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from mcp<2,>=1.6.0->openai-agents==0.0.13) (0.28.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Downloading sse_starlette-2.3.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting starlette>=0.27 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting uvicorn>=0.23.1 (from mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents==0.0.13) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents==0.0.13) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents==0.0.13) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents==0.0.13) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents==0.0.13) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents==0.0.13) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents==0.0.13) (2025.4.26)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.6.0->openai-agents==0.0.13) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from httpx>=0.27->mcp<2,>=1.6.0->openai-agents==0.0.13) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.6.0->openai-agents==0.0.13) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai>=1.76.0->openai-agents==0.0.13) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai>=1.76.0->openai-agents==0.0.13) (0.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from openai>=1.76.0->openai-agents==0.0.13) (4.67.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.6.0->openai-agents==0.0.13)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: click>=7.0 in /Users/tok/Dropbox/PARAL/Resources/virtual-envs/summit-agentic-ai/lib/python3.12/site-packages (from uvicorn>=0.23.1->mcp<2,>=1.6.0->openai-agents==0.0.13) (8.1.8)\n",
      "Downloading openai_agents-0.0.13-py3-none-any.whl (116 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading mcp-1.7.1-py3-none-any.whl (100 kB)\n",
      "Downloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading sse_starlette-2.3.4-py3-none-any.whl (10 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Installing collected packages: uvicorn, types-requests, python-multipart, python-dotenv, httpx-sse, colorama, starlette, griffe, sse-starlette, pydantic-settings, mcp, openai-agents\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [openai-agents]━━\u001b[0m \u001b[32m11/12\u001b[0m [openai-agents]\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 griffe-1.7.3 httpx-sse-0.4.0 mcp-1.7.1 openai-agents-0.0.13 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 sse-starlette-2.3.4 starlette-0.46.2 types-requests-2.32.0.20250328 uvicorn-0.34.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"openai-agents==0.0.13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a049faf1-8a5c-4b36-a85c-7f7627635c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "# from agents import Agent #, ModelSettings, function_tool,Runner\n",
    "\n",
    "from agents import Agent, ModelSettings, function_tool, Runner,AsyncOpenAI,OpenAIChatCompletionsModel\n",
    "from rich.pretty import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201a5506-5b38-4fcb-a0c6-45e67a8ed5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete, Client initialized\n"
     ]
    }
   ],
   "source": [
    "# # Boilerplate for swapping in Granite via ollama\n",
    "# #model = \"granite3-dense:8b\"\n",
    "# #model = \"granite3.1-dense:2b\"\n",
    "# #client = OpenAI(\n",
    "# #     base_url='http://localhost:11434/v1',\n",
    "# #     api_key='ollama',\n",
    "# # ) \n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# model = \"gpt-4o\"\n",
    "# client = OpenAI() \n",
    "\n",
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import rich\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = \"placeholder\"  \n",
    "model = \"mistral-small:latest\" # Other oprions here include \"qwen3:32b\"\n",
    "base_url = \"http://localhost:11434/v1/\" #openai/v1/\"\n",
    "model = \"qwen3:32b\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "print(\"Imports complete, Client initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d258e9a-263a-42f3-8b38-fbba37cc90c6",
   "metadata": {},
   "source": [
    "# Quick test code - verify LLM conenctivity etc (disable via Raw)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a simple Python example class called User\"}],\n",
    "    temperature=0,\n",
    ")\n",
    "print(model)\n",
    "print(f\"{chat_completion.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b2085-0943-4b10-96d5-957ec12befe9",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bd7a3d-b43b-4bc2-91b0-b0a0403ea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60f9c28-8548-4894-beb8-0a768f80d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_rg5pbufy', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)]\n"
     ]
    }
   ],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"latitude\": {\"type\": \"number\"},\n",
    "                \"longitude\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"latitude\", \"longitude\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181c6de",
   "metadata": {},
   "source": [
    "You should see a result similar to, indicating the LLM both identified the need to determine the latitude and longitude and successfully called the tool\n",
    " ```[ChatCompletionMessageToolCall(id='call_rg5pbufy', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b63222-8e7d-47e1-91b6-4435e439b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf33aab-877f-42d9-b1f8-63d59e99874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9\n"
     ]
    }
   ],
   "source": [
    "tool_call = completion.choices[0].message.tool_calls[0]\n",
    "args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f92a80d-10a6-4243-8e67-f07cf6e60237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let me see. The user asked for the weather in Paris today. I called the get_weather function with the coordinates for Paris, which I think are approximately 48.8566° N (latitude) and 2.3522° E (longitude). The function returned a temperature of 11.9°C.\n",
      "\n",
      "Now I need to present this information in a friendly way. The user probably wants to know if they should bring a jacket or not. 11.9°C is a bit cool, so maybe mention that it's chilly. I'll start by stating the current temperature in Paris and then add a suggestion about clothing. Let me check if there's any other info needed, but since the function only provided the temperature, I'll stick to that. Make sure to keep the response clear and concise. Alright, let's put it all together.\n",
      "</think>\n",
      "\n",
      "The current temperature in Paris is 11.9°C. It's a bit chilly, so you might want to wear a light jacket if you're heading out!\n"
     ]
    }
   ],
   "source": [
    "messages.append(completion.choices[0].message)  # append model's function call message\n",
    "messages.append({                               # append result message\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": str(result)\n",
    "})\n",
    "\n",
    "completion_2 = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(completion_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b841d14-dc51-46a4-8bee-cfcecc4b122e",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "Agents are the heart of complex AI applications. They combine inference, memory, safety, and tool usage into coherent workflows. At its core, an agent follows a sophisticated execution loop that enables multi-step reasoning, tool usage, and safety checks.\n",
    "Ref: https://llama-stack.readthedocs.io/en/latest/building_applications/agent_execution_loop.html\n",
    "\n",
    "An Agentic-AI eco system is much larger than the LLM/s which it uses. While LLMs are being used, the agentic structure helps us to automate using those sophisticated prompts that we talked about.  The power of agentic AI is not only in the model, but in the orchestration—how you structure the workflow to get durable, repeatable outcomes without hand-holding.\n",
    "\n",
    "\n",
    "### Goal-Oriented Looping\n",
    "\n",
    "- A raw LLM gives one-shot answers. An agent keeps trying, planning multiple steps, checking for errors, adapting.\n",
    "- Think of it as: “Try → Check → Revise → Retry → Finish” or \"Thought → Action → Observation → Repeat → Answer\"\n",
    "- The loop itself enforces discipline and depth.\n",
    "- Without that structure, the LLM might shortcut the process.\n",
    "\n",
    "### Memory & Scratchpad\n",
    "\n",
    "Agents can keep track of:\n",
    "- What they’ve tried\n",
    "- What the intermediate results were\n",
    "- What the user originally wanted\n",
    "- LLM alone doesn’t track history or outcomes unless explicitly given.\n",
    "\n",
    "### Tool Use\n",
    "\n",
    "- Agents can call APIs, browse docs, or query databases. LLM alone hallucinates data. An agent says: “I don’t know—let me look it up.”\n",
    "\n",
    "### Decomposition\n",
    "\n",
    "- Agents break big tasks into smaller ones.\n",
    "- LLMs can do this, but often need a prompt to do so.\n",
    "- Agents automate that “thinking out loud.”\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d35782-20e8-430b-9b5d-e2fdc63cb5f6",
   "metadata": {},
   "source": [
    "## Agent calling tools\n",
    "1. Simply demonstrates an agent using a tool.\n",
    "1. Look at the brevity of the code compared to doing a function calling all on our own.\n",
    "1. Play with the question that can be asked to agent to see how it can handle questions that may or may not require the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a8bee-781e-4f1f-a749-1fd52bbfefb7",
   "metadata": {},
   "source": [
    "First we will need to insatll the Python `agents` dependancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b5f19-3b5c-4bdf-b514-1f74186e56ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf7b3ed0-b77b-449a-9bab-4f3f18171709",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agents in /home/dev/venv/lib64/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: tensorflow in /home/dev/venv/lib64/python3.12/site-packages (from agents) (2.19.0)\n",
      "Requirement already satisfied: gym in /home/dev/venv/lib64/python3.12/site-packages (from agents) (0.26.2)\n",
      "Requirement already satisfied: ruamel.yaml in /home/dev/venv/lib64/python3.12/site-packages (from agents) (0.18.10)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/dev/venv/lib64/python3.12/site-packages (from gym->agents) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from gym->agents) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/dev/venv/lib64/python3.12/site-packages (from gym->agents) (0.0.8)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/dev/venv/lib64/python3.12/site-packages (from ruamel.yaml->agents) (0.2.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (80.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/dev/venv/lib64/python3.12/site-packages (from tensorflow->agents) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/dev/venv/lib64/python3.12/site-packages (from astunparse>=1.6.0->tensorflow->agents) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/dev/venv/lib64/python3.12/site-packages (from keras>=3.5.0->tensorflow->agents) (14.0.0)\n",
      "Requirement already satisfied: namex in /home/dev/venv/lib64/python3.12/site-packages (from keras>=3.5.0->tensorflow->agents) (0.0.9)\n",
      "Requirement already satisfied: optree in /home/dev/venv/lib64/python3.12/site-packages (from keras>=3.5.0->tensorflow->agents) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dev/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->agents) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dev/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dev/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->agents) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dev/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->agents) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dev/venv/lib64/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->agents) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dev/venv/lib64/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->agents) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dev/venv/lib64/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->agents) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dev/venv/lib64/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->agents) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dev/venv/lib64/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow->agents) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dev/venv/lib64/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow->agents) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dev/venv/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->agents) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U agents #\"agents==1.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e74024ca-e0c2-43f2-ab80-7f068df322ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# model = \"gpt-4o\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, ModelSettings, function_tool, Runner\n\u001b[32m      4\u001b[39m \u001b[38;5;129m@function_tool\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_weather\u001b[39m(latitude:\u001b[38;5;28mstr\u001b[39m, longitude:\u001b[38;5;28mstr\u001b[39m) ->\u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      6\u001b[39m     response = requests.get(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.open-meteo.com/v1/forecast?latitude=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&longitude=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlongitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib64/python3.12/site-packages/agents/__init__.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithms\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scripts\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib64/python3.12/site-packages/agents/scripts/__init__.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utility\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualize\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib64/python3.12/site-packages/agents/scripts/train.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m configs\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utility\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_environment\u001b[39m(config):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib64/python3.12/site-packages/agents/scripts/configs.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithms\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m networks\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m():\n\u001b[32m     30\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Default configuration for PPO.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib64/python3.12/site-packages/agents/scripts/networks.py:30\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m tfd = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontrib\u001b[49m.distributions\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# TensorFlow's default implementation of the KL divergence between two\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# tf.contrib.distributions.MultivariateNormalDiag instances sometimes results\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# in NaN values in the gradients (not in the forward pass). Until the default\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# implementation is fixed, we use our own KL implementation.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCustomKLDiagNormal\u001b[39;00m(tfd.MultivariateNormalDiag):\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "# model = \"gpt-4o\"\n",
    "from agents import Agent, ModelSettings, function_tool, Runner\n",
    "\n",
    "@function_tool\n",
    "def get_weather(latitude:str, longitude:str) ->str:\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "   \n",
    "agent = Agent(\n",
    "    name=\"Blaster\",\n",
    "    instructions=\"Answer the question asked very precisely. Please think before answering\",\n",
    "    model= model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"which is warmer now: Paris or Manila?\")\n",
    "print(result.final_output)\n",
    "\n",
    "#uncomment the line below to see the detailed interactions including automatic tool calling\n",
    "#pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077ab16-b9e5-4699-a46e-6b64278cbda4",
   "metadata": {},
   "source": [
    "# Tools\n",
    "- We are definining tools with an adornment here.\n",
    "- MCP Servers are formalizing this much more and everyone is adopting this.\n",
    "- This is covered in another lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ee407-2c3e-4f48-8f28-9110ba975f01",
   "metadata": {},
   "source": [
    "# Agentic Patterns\n",
    "\n",
    "\n",
    "We explore below 3 agentic paradigms which are widely used\n",
    "\n",
    "1. Agents collaborating with each other to improve the quality of the output\n",
    "   ![Collaboration Pattern](resources/images/agent_collaborate.png)\n",
    "3. Agents routing traffic to the correct agent\n",
    "   ![pattern-1](resources/images/agent_supervisor_pattern.png)  \n",
    "   ![pattern-2](resources/images/agent_hierarchical.png) \n",
    "5. Agents running a workflow\n",
    "   ![Workflow Pattern](resources/images/agent_plan_execute.png)\n",
    "\n",
    "There are other agentic patterns as well which we do not cover here. But these basic concepts should help adopting other patterns much simpler.\n",
    "\n",
    "_The graphics have been used from [langraph tutorial](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c11e8b-6396-499b-abec-a8b674bdf312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agents Collaborating\n",
    "1. Simply demonstrates an agent reviewing the work of another agent - much like a human being.\n",
    "1. This is one of the primary reasons while the agents can help increase accuracty of the answer and smaller models using agents can outperform larger models without agents.\n",
    "1. This pattern can be used in lots of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e676d7f-a94f-4add-84e2-e7d8074bfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows the agents collaborating or one agent reveiwing the work of another and giving feedback. \n",
    "The first agent generates an outline for a story.\n",
    "The second agent judges the outline and provides feedback. \n",
    "We loop until the judge is satisfied with the outline.\n",
    "\"\"\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "story_outline_generator = Agent(\n",
    "    name=\"story_outline_generator\",\n",
    "    instructions=(\n",
    "        \"You generate a very short story outline based on the user's input.\"\n",
    "        \"If there is any feedback provided, use it to improve the outline.\"\n",
    "    ),\n",
    "    model= model,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvaluationFeedback:\n",
    "    feedback: str\n",
    "    score: Literal[\"pass\", \"needs_improvement\", \"fail\"]\n",
    "\n",
    "\n",
    "evaluator = Agent(\n",
    "    name=\"evaluator\",\n",
    "    instructions=(\n",
    "        \"You evaluate a story outline and decide if it's good enough.\"\n",
    "        \"If it's not good enough, you provide feedback on what needs to be improved.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=EvaluationFeedback,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01d3ea3-ec28-447a-9fd3-41f54ecc9650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of story would you like to hear?  joyful story\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story outline generated\n",
      "Evaluator score: pass\n",
      "Story outline is good enough, exiting.\n",
      "Final story outline: Title: **The Day the Music Danced**\n",
      "\n",
      "**Outline:**\n",
      "\n",
      "1. **Introduction:**\n",
      "   - In the quaint village of Harmonia, every Sunday, the townsfolk gather for a vibrant music festival.\n",
      "   - The protagonist, Lily, a cheerful young girl with a talent for playing the violin, eagerly anticipates this day.\n",
      "\n",
      "2. **Rising Action:**\n",
      "   - This year, a surprise visitor arrives—a wise old musician named Maestro Anton, known for his magical melodies that can make anything dance.\n",
      "   - Lily is chosen to play a duet with him, feeling both excited and nervous.\n",
      "\n",
      "3. **Climax:**\n",
      "   - As they begin to play, the music comes to life, lifting everyone’s spirits.\n",
      "   - The notes swirl in the air, causing trees to sway and flowers to bloom in rhythm, creating a whimsical dance scene.\n",
      "\n",
      "4. **Falling Action:**\n",
      "   - The joyful dance envelops the village, bringing together people of all ages in harmony.\n",
      "   - Lily’s confidence soars as she realizes the true power of her music—to unite and uplift.\n",
      "\n",
      "5. **Conclusion:**\n",
      "   - The festival ends with laughter and gratitude, and Lily receives a small charm from Maestro Anton as a reminder of their special day.\n",
      "   - Lily vows to continue sharing her joyful music with the world, knowing it can paint smiles and create memories.\n",
      "\n",
      "**Feedback Improvements:**\n",
      "If needed, the outline can focus more on specific interactions between Lily and the villagers to deepen character connections or include more sensory details to enrich the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "msg = input(\"What kind of story would you like to hear? \")\n",
    "input_items: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "latest_outline: str | None = None\n",
    "\n",
    "with trace(\"Collaboration\"):\n",
    "        i = 0\n",
    "        while True:\n",
    "            story_outline_result = await Runner.run(\n",
    "                story_outline_generator,\n",
    "                input_items,\n",
    "            )\n",
    "\n",
    "            input_items = story_outline_result.to_input_list()\n",
    "            latest_outline = ItemHelpers.text_message_outputs(story_outline_result.new_items)\n",
    "            print(\"Story outline generated\")\n",
    "\n",
    "            evaluator_result = await Runner.run(evaluator, input_items)\n",
    "            result: EvaluationFeedback = evaluator_result.final_output\n",
    "\n",
    "            print(f\"Evaluator score: {result.score}\")\n",
    "\n",
    "            if result.score == \"pass\":\n",
    "                print(\"Story outline is good enough, exiting.\")\n",
    "                break\n",
    "            if i == 2:\n",
    "                print(\"Maximum number of iterations exceeded, exiting.\")\n",
    "                break\n",
    "            print(\"Re-running with feedback\")\n",
    "\n",
    "            input_items.append({\"content\": f\"Feedback: {result.feedback}\", \"role\": \"user\"})\n",
    "            i += 1\n",
    "\n",
    "print(f\"Final story outline: {latest_outline}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af63f69-2d06-40f9-9fa5-cc490cf11768",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agents routing\n",
    "1. Simply demonstrates an agent routing work to other agents.\n",
    "1. This is a very common agentic pattern.\n",
    "1. Ask the question in German and see what happens! In real life when we use a routing pattern, we must have a fallback agent that gracefully handles all things unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa28f4d9-5ab4-41f8-8658-ece1d3e31de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "\n",
    "#from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows the handoffs/routing pattern. The triage agent receives the first message, and\n",
    "then hands off to the appropriate agent based on the language of the request. Responses are\n",
    "streamed to the user.\n",
    "\"\"\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You only speak French\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English. Answer the question you recieved.\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "# experiment by removing  from the instructions the sentence below.\n",
    "#So answer in English even if you understand the language that is being used.\n",
    "#And then ask say (German) : Wie geht es dir\n",
    "know_all_agent = Agent(\n",
    "    name=\"know_all_agent\",\n",
    "    instructions=\"You only speak English. So answer in English even if you understand the language that is being used. \\\n",
    "        State that you do not understand the user question and ask them to repeat it one of the languages you understand. \\\n",
    "        Those languages are English, French and Spanish .\",\n",
    "    model = model,\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request. If you do not know what to do, hand if off to know_all.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent, know_all_agent],\n",
    "    model = model,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bbe4d0-3806-4b29-9f28-6e10361abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! We speak French, Spanish and English. How can I help?  bonjour monsieur\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Bonjour ! Comment puis-je vous aider aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "with trace(\"Router\"):\n",
    "    story_outline_result = await Runner.run(triage_agent,inputs)\n",
    "    #uncomment this to see the details\n",
    "    #pprint(story_outline_result)\n",
    "    print(\"--------------------------\")\n",
    "    print(story_outline_result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660bec5-d54d-473f-9f03-0604120fdbd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agents Deterministic Workflow\n",
    "1. Simply demonstrates agents calling other agents to complete a well defined workflow.\n",
    "1. This is a very common agentic pattern.\n",
    "1. This pattern or its variants can be put to lot of practical use and it could be combined with the collaborative pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef7aa00-e4b1-4b50-ba19-c428c6dbb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, TResponseInputItem, trace\n",
    "\n",
    "\"\"\"\n",
    "This example shows how different agents are used to compelete a deterministic workflow.\n",
    "In this case it is: \n",
    "planner agent -> writer agent -> editor agent \n",
    "Given an essay topic, the essay moves through these stages to finally produce an output.\n",
    "\"\"\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "@dataclass\n",
    "class Planner:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Writer:\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class Editor:\n",
    "    body: str\n",
    "\n",
    "\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"planner_agent\",\n",
    "    instructions=(\n",
    "        \"Take a user's theme/topic request.\"\n",
    "        \"Create a brief outline of the essay with points that need to be covered.\"\n",
    "        \"Make sure that references are given to actual source materials.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Planner,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"writer_agent\",\n",
    "    instructions=(\n",
    "        \"Take the outline given in the input.\"\n",
    "        \"Expands it into a complete essay.\"\n",
    "        \"Give adequate references and make sure things are not made up!\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Writer,\n",
    ")\n",
    "\n",
    "editor_agent = Agent(\n",
    "    name=\"editor_agent\",\n",
    "    instructions=(\n",
    "        \"You Review the draft given in the input.\"\n",
    "        \"Polish the language, fixes inconsistencies, and improve the flow.\"\n",
    "        \"And make sure it is logical coherent.\"\n",
    "        \"Give adequate references and make sure things are not made up!\"\n",
    "        \"Return the final story to the user.\"\n",
    "    ),\n",
    "    model= model,\n",
    "    output_type=Editor,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c2656ad-540c-4049-892e-a0dde674962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am AI Researcher. Give me any topic and I will write a well researched essay about it.  Model Context Protocol Servers and tools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Planner Output----------\n",
      "### Essay Outline: Model Context Protocol Servers and Tools\n",
      "\n",
      "#### Introduction\n",
      "- Define Model Context Protocol (MCP) and its significance in software development.\n",
      "- Brief introduction to protocol servers and tools.\n",
      "- Importance of context-aware computing.\n",
      "  \n",
      "#### Background of MCP\n",
      "- Origin and development of MCP.\n",
      "- Key features and functionalities.\n",
      "- Comparison with other protocols (e.g., HTTP, FTP).\n",
      "\n",
      "#### Architecture of MCP Servers\n",
      "- Overview of server architecture.\n",
      "- Role of context information in MCP.\n",
      "- How MCP servers handle context data efficiently.\n",
      "  \n",
      "#### Tools for MCP\n",
      "- Popular tools used in MCP implementation.\n",
      "  - MCP Toolkits.\n",
      "  - Libraries and frameworks.\n",
      "- Criteria for selecting appropriate tools.\n",
      "\n",
      "#### Applications\n",
      "- Use cases of MCP in various industries.\n",
      "  - Healthcare.\n",
      "  - IoT.\n",
      "- Efficiency improvements in data handling and processing.\n",
      "\n",
      "#### Challenges and Solutions\n",
      "- Common challenges faced in MCP implementation.\n",
      "- Proposed solutions.\n",
      "- Future developments and research directions.\n",
      "\n",
      "#### Conclusion\n",
      "- Summary of key points.\n",
      "- The potential impact of MCP in the future.\n",
      "\n",
      "#### References\n",
      "- **Reference 1:** [Title of the Source]. (Year). Retrieved from [URL].\n",
      "- **Reference 2:** [Author, Book/Article Title]. (Publisher, Year).\n",
      "- **Reference 3:** [Title of the Source]. (Year). Retrieved from [URL].\n",
      "\n",
      "### Additional Notes\n",
      "- Use credible sources such as academic journals, books, and verified websites.\n",
      "- Include recent developments and updates in MCP technology.\n",
      "- Ensure all references are in the correct format and easily accessible for further exploration.\n",
      "----------Writer Output----------\n",
      "### Essay: Model Context Protocol Servers and Tools\n",
      "\n",
      "#### Introduction\n",
      "In the ever-evolving landscape of software development, the Model Context Protocol (MCP) has emerged as a pivotal element in fostering context-aware computing. Its significance lies in enhancing the adaptability and intelligence of software systems to react appropriately in varied environments. Protocol servers and tools play a crucial role in managing and facilitating these interactions effectively, thereby underscoring the importance of context-aware technology in modern computing.\n",
      "\n",
      "#### Background of MCP\n",
      "The Model Context Protocol originated from the need to provide a more structured and efficient way to manage context data in complex systems. Unlike traditional protocols like HTTP and FTP, which primarily focus on facilitating data exchange, MCP emphasizes the importance of context in interpreting data meaningfully. MCP enables systems to modify their operations based on the contexts they perceive, making them inherently smarter and more responsive. Key features include the ability to seamlessly integrate with various data sources, manage contextual changes dynamically, and offer robust scalability to fit diverse applications.\n",
      "\n",
      "#### Architecture of MCP Servers\n",
      "MCP server architecture is pivotal in managing context information. Typically, these servers are designed to intake diverse context data, process it in real-time, and adapt the system’s behavior accordingly. The architecture supports distributed data sources, where context data is efficiently gathered and processed. This ensures the seamless handling of rapid context changes, which is crucial in high-stakes environments such as real-time IoT applications or healthcare systems. Efficient context data handling in MCP servers reduces latency, enhances accuracy, and optimizes resource use.\n",
      "\n",
      "#### Tools for MCP\n",
      "Numerous tools aid in the effective implementation of MCP. MCP Toolkits are immensely popular, providing developers with a framework to build, manage, and deploy context-aware systems. Libraries and frameworks such as Context Toolkit and CoBra are instrumental in offering structured approaches to managing context data. In selecting appropriate tools, criteria such as ease of integration, scalability, support for various data inputs, and real-time processing capabilities are paramount. These tools simplify the complex processes involved in managing and interpreting context data.\n",
      "\n",
      "#### Applications\n",
      "MCP finds varied applications across industries. In healthcare, MCP can dramatically improve patient care through real-time data processing and decision-making support, adjusting to vital signs and environmental factors. In the IoT sector, MCP enhances device interconnectivity, enabling devices to adapt operations based on current conditions dynamically. Such applications underscore the protocol’s capacity to substantially improve efficiency in data handling and processing, leading to profound operational improvements.\n",
      "\n",
      "#### Challenges and Solutions\n",
      "Implementing MCP is not without challenges. Common issues include managing the vast diversity of context data sources and ensuring data privacy and security. Addressing these requires robust encryption methods and flexible, scalable architectures that can accommodate future demand. Emerging research suggests adopting hybrid models that combine centralized and decentralized processing could offer viable solutions to these challenges. Ongoing advancements in artificial intelligence and machine learning are also poised to augment the capabilities of MCP, offering promising directions for future development.\n",
      "\n",
      "#### Conclusion\n",
      "In conclusion, the Model Context Protocol significantly elevates the potential of software systems to operate contextually. By enabling systems to interpret and respond to real-world data dynamically, MCP is set to redefine many aspects of technology use across industries. Its future impact, bolstered by ongoing advancements and research, promises to further revolutionize the fields of IoT, healthcare, and beyond.\n",
      "\n",
      "#### References\n",
      "- **Reference 1:** [Bettini, C., Brdiczka, O., Henricksen, K., et al.: A survey of context modelling and reasoning techniques. Pervasive and Mobile Computing 6(2), 161–180 (2010).](https://www.sciencedirect.com/science/article/abs/pii/S1574119210000159)\n",
      "- **Reference 2:** [Dey, A. K., & Abowd, G. D. (2000). Towards a better understanding of context and context-awareness. Proceedings of the 2000 Workshop on the What, Who, Where, When, and How of Context-Awareness in Pervasive Computing (CHI 2000).](https://citeseerx.ist.psu.edu/document?doi=10.1.1.110.7723)\n",
      "- **Reference 3:** [Perera, C., Zaslavsky, A., Christen, P., & Georgakopoulos, D. (2014). Context-aware computing for the internet of things: A survey. IEEE Communications Surveys & Tutorials, 16(1), 414-454.](https://ieeexplore.ieee.org/document/6704472)\n",
      "\n",
      "### Additional Notes\n",
      "Continual advancements in MCP technology require attention to contemporary research and updates. Ensuring all references adhere to proper format aids in facilitating further exploration for interested audiences. Aligning MCP developments with emerging technology trends amplifies its relevance and application potential across varied fields.\n",
      "----------Editor Output----------\n",
      "### Essay: Model Context Protocol Servers and Tools\n",
      "\n",
      "#### Introduction\n",
      "In the rapidly advancing field of software development, the Model Context Protocol (MCP) has emerged as a critical component in promoting context-aware computing. Its importance stems from its ability to enhance the intelligence and adaptability of software systems, enabling them to respond effectively in diverse environments. Protocol servers and tools are essential in managing and facilitating these interactions, highlighting the significance of context-aware technology in contemporary computing.\n",
      "\n",
      "#### Background of MCP\n",
      "The Model Context Protocol was developed to provide a more structured and efficient approach to managing context data in complex systems. Unlike traditional protocols such as HTTP and FTP, which primarily focus on data exchange, MCP emphasizes the importance of context in interpreting data meaningfully. MCP allows systems to modify their operations based on perceived contexts, making them inherently smarter and more responsive. Key features include seamless integration with various data sources, dynamic management of contextual changes, and robust scalability to accommodate diverse applications.\n",
      "\n",
      "#### Architecture of MCP Servers\n",
      "The architecture of MCP servers is crucial in managing context information. These servers are typically designed to intake diverse context data, process it in real-time, and adapt the system's behavior accordingly. The architecture supports distributed data sources, efficiently gathering and processing context data. This ensures the seamless handling of rapid context changes, which is vital in high-stakes environments such as real-time IoT applications or healthcare systems. Efficient context data management in MCP servers reduces latency, enhances accuracy, and optimizes resource use.\n",
      "\n",
      "#### Tools for MCP\n",
      "Various tools facilitate the effective implementation of MCP. MCP toolkits are popular, providing developers with frameworks to build, manage, and deploy context-aware systems. Libraries and frameworks such as the Context Toolkit and CoBra are instrumental in offering structured approaches to managing context data. Selecting appropriate tools involves considering criteria such as ease of integration, scalability, support for various data inputs, and real-time processing capabilities. These tools simplify the complex processes involved in managing and interpreting context data.\n",
      "\n",
      "#### Applications\n",
      "MCP has diverse applications across industries. In healthcare, it can significantly improve patient care through real-time data processing and decision-making support, adapting to vital signs and environmental factors. In the IoT sector, MCP enhances device interconnectivity, allowing devices to dynamically adapt operations based on current conditions. These applications highlight the protocol's capacity to improve efficiency in data handling and processing, leading to substantial operational enhancements.\n",
      "\n",
      "#### Challenges and Solutions\n",
      "Implementing MCP presents challenges, including managing the diversity of context data sources and ensuring data privacy and security. Addressing these issues requires robust encryption methods and flexible, scalable architectures that can accommodate future demand. Emerging research suggests adopting hybrid models that combine centralized and decentralized processing as viable solutions. Ongoing advancements in artificial intelligence and machine learning are also set to augment MCP's capabilities, offering promising directions for future development.\n",
      "\n",
      "#### Conclusion\n",
      "In conclusion, the Model Context Protocol significantly elevates the potential of software systems to operate contextually. By enabling systems to interpret and respond to real-world data dynamically, MCP is poised to redefine many aspects of technology use across industries. Its future impact, supported by ongoing advancements and research, promises to further transform fields like IoT, healthcare, and beyond.\n",
      "\n",
      "#### References\n",
      "- **Bettini, C., Brdiczka, O., Henricksen, K., et al.:** *A survey of context modelling and reasoning techniques.* Pervasive and Mobile Computing 6(2), 161–180 (2010). [Link](https://www.sciencedirect.com/science/article/abs/pii/S1574119210000159)\n",
      "- **Dey, A. K., & Abowd, G. D. (2000):** *Towards a better understanding of context and context-awareness.* Proceedings of the 2000 Workshop on the What, Who, Where, When, and How of Context-Awareness in Pervasive Computing (CHI 2000). [Link](https://citeseerx.ist.psu.edu/document?doi=10.1.1.110.7723)\n",
      "- **Perera, C., Zaslavsky, A., Christen, P., & Georgakopoulos, D. (2014):** *Context-aware computing for the internet of things: A survey.* IEEE Communications Surveys & Tutorials, 16(1), 414-454. [Link](https://ieeexplore.ieee.org/document/6704472)\n",
      "\n",
      "### Additional Notes\n",
      "Continuous advancements in MCP technology necessitate attention to contemporary research and updates. Ensuring all references follow the appropriate format aids exploration for interested audiences. Aligning MCP developments with emerging technology trends enhances its relevance and application potential across various fields.\n"
     ]
    }
   ],
   "source": [
    "msg = input(\"Hi! I am AI Researcher. Give me any topic and I will write a well researched essay about it. \")\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "with trace(\"Workflow\"):\n",
    "    print(\"----------Planner Output----------\")\n",
    "    planner_result = await Runner.run(planner_agent,inputs)\n",
    "    print(planner_result.final_output.body)\n",
    "    planner_output: Planner = planner_result.final_output\n",
    "    print(\"----------Writer Output----------\")\n",
    "    writer_result = await Runner.run(writer_agent,planner_output.body)\n",
    "    print(writer_result.final_output.body)\n",
    "    writer_output: Writer = writer_result.final_output\n",
    "    print(\"----------Editor Output----------\")\n",
    "    editor_result = await Runner.run(editor_agent,writer_output.body)\n",
    "    print(editor_result.final_output.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efe065-d4e6-41a6-bb4b-60ce7734f102",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Microservices\n",
    "\n",
    "There are several meaningful similarities between LLM-based AI agents and microservices:\n",
    "\n",
    "## Similarities\n",
    "#### Specialized functionality: \n",
    "Both are designed to handle specific tasks or domains. Microservices focus on particular business capabilities, while AI agents can be specialized for specific types of interactions or knowledge domains.\n",
    "### Independent operation: \n",
    "Both can operate autonomously within their defined scope. Once configured, they can process requests without requiring constant supervision.\n",
    "### Communication patterns: \n",
    "Both typically communicate via messages/APIs. Microservices use REST/gRPC/messaging protocols, while AI agents receive prompts and return responses through APIs.\n",
    "### Composability: \n",
    "Both can be combined to build larger systems. Microservices can be orchestrated to create complex applications; similarly, multiple AI agents can work together in a workflow.\n",
    "### Statelessness vs. statefulness: \n",
    "Basic implementations of both can be stateless, but more sophisticated versions maintain state. The Agent class you showed maintains conversation history, similar to how some microservices maintain session state.\n",
    "### Scaling considerations: \n",
    "Both face similar operational challenges around scaling, monitoring, and versioning.\n",
    "\n",
    "## Key differences:\n",
    "\n",
    "### Implementation: \n",
    "Microservices are traditional code with deterministic logic, while LLM agents use probabilistic models. MCP Servers which expose tools to be used by Agents could be totally traditional code with deterministic logic.\n",
    "### Predictability: \n",
    "Microservices have more predictable outputs for given inputs, while LLM responses can vary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9ab57-7246-4c17-a9c1-2ccc9a7cc487",
   "metadata": {},
   "source": [
    "# AFTERWORD\n",
    "Agents are an extremely powerful construct in the field of Generative AI:\n",
    "1. You can achieve complex tasks designing appropriate agents and tools and driving interaction between the different agents.\n",
    "1. There are known ways by which we can improve accuracy of the output. Much like human beings help check one another's work, agents can do the same.\n",
    "1. External data retrieval and queries are carried out through the tools.\n",
    "1. If agent processing needs to be vetted, make sure humans are used (human-in-the-loop) to are used to vet the agent output before it moves to the next step. Really, this is no different to how we operate in our real life with human beings - we have review and approval processes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78716910-84ca-42b6-9f2b-faa39f4df1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
